<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>StressPrompt: Does Stress Impact Large Language Models and Human Performance Similarly?</title>
    <link href="/2025/12/10/StressPrompt-Does-Stress-Impact-Large-Language-Models-and-Human-Performance-Similarly/"/>
    <url>/2025/12/10/StressPrompt-Does-Stress-Impact-Large-Language-Models-and-Human-Performance-Similarly/</url>
    
    <content type="html"><![CDATA[<p><img src="./2025-12-10-23-32-16.png" /></p><h2 id="我的评价">我的评价</h2><p>纯纯的烂文章 写作逻辑还可以，实验部分写的如同狗屎</p><ol type="1"><li><p>实验数据不完整   The models tested included Llama-3-8B-Instruct, Llama-3.1-8B-Instruct, Llama-3-70B-Instruct(AI@Meta 2024), Phi-3-mini-4k-Instruct (Abdin et al.2024), Qwen2-72B-Instruct, Qwen2-7B-Instruct (Yang et al.2024), and Mistral-7B-Instruct-v0.3 (Jiang et al. 2023). The generation temperature was set to 0, and specific dialogue tokens were used to ensure consistency.   The datasets employed in these evaluations included IFEval (Zhou et al.2023), BBH (Suzgun et al. 2022), MATH (Hendrycks et al. 2021b), GPQA (Rein et al. 2023), MuSR (Sprague et al. 2023), MMLU-P (Wang et al. 2024b), EQBench (Paech 2023), MMLU (Hendrycks et al. 2021a),TruthfulQA   然而实际上你只能看到这些Llama-3-8B-Instruct, Phi-3-mini-4k-Instruct 以及一些意义不明 明显是凑数用的数据分析(PCA T-SNE) 对于StressPrompt的作用原理也是点到为止。</p></li><li><p>如何构造的prompt也是意义不明 只是说自己套用了很多什么心理学准则提示词生成的原理也没讲，AI生成吗？</p></li><li><p>喜欢蹭心理科学，标榜自己证实了耶克斯-多德森定律。纯纯唐文</p></li></ol><h2 id="当前存在什么问题">当前存在什么问题</h2><p>  现在没有人做模型的压力测试。就像人在不同压力等级下的表现不同，模型会不会也有这种现象。此外分析压力对模型内部的影响，对模型的训练过程也有一定的启发。</p><h2 id="本文打算通过什么思路解决">本文打算通过什么思路解决</h2><p>  设计100个StressPrompt， 对prompt进行人工压力评级(0 - 10)。把StressPrompt作为System Prompt输到模型里，再让模型进行MMLU MATH GPQA等主流测试。看看模型的表现有没有变化。</p><p>  分析StressPrompt对模型内部的影响，可以把hidden state的向量拿到，然后做一个PCA，找到方差最大的那个vector。对于某个prompt，可以拿到不同layer的不同token的hidden state然后和vector相乘得到一个标量，用于表示影响。</p><p><img src="./2025-12-10-23-40-02.png" /></p><h2 id="该思路会遇到什么挑战">该思路会遇到什么挑战</h2><p>   没什么挑战。构建prompt(我猜用的是ai)；PCA和分析不同layer的hidden state的方法感觉像是ai想出来的数据分析方法。</p><h2 id="本文通过什么手段克服该挑战">本文通过什么手段克服该挑战</h2><p>   。。。</p><h2 id="本文如何通过实验论证了该方案的优越性">本文如何通过实验论证了该方案的优越性</h2><p>   跑各种主流评测数据集。但是有个问题，本文根本就是挂羊头卖狗肉，没有展示出来所有的模型的表现。而且表格画的很烂。有提升的为什么不把这里加粗（把最高的标粗），还有1-10都没有提升的也不讨论。 <img src="./2025-12-10-23-43-33.png" /></p><h2 id="本文的写作思路">本文的写作思路</h2><p>  引言 (Introduction)： 提出LLMs性能受压力影响的问题尚未被探索，阐述研究的必要性（理解LLMs与人类智能的相似性、AI的鲁棒性）。</p><p>  相关工作 (Related Works)： 回顾LLMs的进步、情感智能评估以及压力对人类的影响等研究，指出现有研究缺乏对LLMs内部状态的定量分析，引出本文的研究切入点 。</p><p>  方法 (Method)： 详细介绍核心创新点：StressPrompt 的构建：基于四大心理学框架，并通过人类评分校准 。StressPrompt 的评估框架：如何在不同压力水平下系统地评估LLMs的性能 。压力扫描器 (Stress Scanner) 的分析：如何利用表征工程（RepE）来量化压力对LLMs内部状态的影响 。</p><p>  实验 (Experiments)： 描述实验设置、测试的模型和基准任务，并对在不同压力水平下的任务性能进行详细分析，重点论证耶克斯-多德森定律的发现和对不同任务（如复杂推理、情绪智能）的影响 。</p><p>  结论与贡献 (Conclusion/Contributions)： 总结研究发现，强调StressPrompt的贡献（创新数据集、压力扫描器），并提出对未来开发更具弹性和适应性的AI系统的指导意义 。</p><h2 id="我的思考">我的思考</h2><p>这种垃圾还是少看为佳</p>]]></content>
    
    
    <categories>
      
      <category>AAAI2025</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>概率算法ppt总结</title>
    <link href="/2025/12/10/%E6%A6%82%E7%8E%87%E7%AE%97%E6%B3%95ppt%E6%80%BB%E7%BB%93/"/>
    <url>/2025/12/10/%E6%A6%82%E7%8E%87%E7%AE%97%E6%B3%95ppt%E6%80%BB%E7%BB%93/</url>
    
    <content type="html"><![CDATA[<p>计算 <span class="math inline"><em>a</em> = <em>g</em><sup><em>x</em></sup><em>m</em><em>o</em><em>d</em> <em>p</em></span> 离散对数计算的问题 最坏情况下是<span class="math inline"><em>O</em>(<em>p</em>)</span> 这里可以使用Sherwood算法引入随机性，降低进入最坏情况的概率。</p><p><img src="./2025-12-10-14-09-30.png" /></p><p>这个改写利用了随机预处理来改变求解的实例，使得原本可能在特定输入下性能不佳的确定性离散对数算法 <span class="math inline"><em>l</em><em>o</em><em>g</em><sub><em>g</em>, <em>p</em></sub></span>，能够以接近平均性能的效率求解。</p><h2 id="dlog_rh-算法工作原理分析">🔬 <span class="math inline"><em>d</em><em>l</em><em>o</em><em>g</em><sub><em>R</em><em>H</em></sub></span> 算法工作原理分析</h2><h3 id="算法目标">1. 算法目标</h3><ul><li><strong>问题</strong>: 离散对数问题。</li><li><strong>输入</strong>: 基数 <span class="math inline"><em>g</em></span>，目标值 <span class="math inline"><em>a</em></span>，模数 <span class="math inline"><em>p</em></span>。</li><li><strong>求解</strong>: 找到指数 <span class="math inline"><em>x</em></span>，使得 <span class="math inline"><em>g</em><sup><em>x</em></sup> ≡ <em>a</em> (mod  <em>p</em>)</span>。</li><li><strong>模</strong>: 运算发生在 <span class="math inline">ℤ<sub><em>p</em></sub><sup>*</sup></span> (模 <span class="math inline"><em>p</em></span> 乘法群) 中。指数 <span class="math inline"><em>x</em></span> 在 <span class="math inline">ℤ<sub><em>p</em> − 1</sub></span> (模 <span class="math inline"><em>p</em> − 1</span> 加法群) 中，即 <span class="math inline"><em>x</em> ∈ {0, 1, …, <em>p</em> − 2}</span>。</li></ul><h3 id="dlog_rh-步骤解析">2. <span class="math inline"><em>d</em><em>l</em><em>o</em><em>g</em><sub><em>R</em><em>H</em></sub></span> 步骤解析</h3><table><thead><tr class="header"><th style="text-align: left;">步骤</th><th style="text-align: left;">代码</th><th style="text-align: left;">解释</th><th style="text-align: left;">作用</th></tr></thead><tbody><tr class="odd"><td style="text-align: left;"><strong>I. 随机数</strong></td><td style="text-align: left;"><code>r ← uniform(0..p-2);</code></td><td style="text-align: left;">随机选择一个指数 <span class="math inline"><em>r</em> ∈ {0, 1, …, <em>p</em> − 2}</span>。<strong>这是随机性的来源。</strong></td><td style="text-align: left;">引入随机变量 <span class="math inline"><em>r</em></span>。</td></tr><tr class="even"><td style="text-align: left;"><strong>II. 预处理 (实例 <span class="math inline"><em>y</em></span>)</strong></td><td style="text-align: left;"><code>b ← ModularExponent(g, r, p);</code></td><td style="text-align: left;">计算 <span class="math inline"><em>b</em> = <em>g</em><sup><em>r</em></sup> (mod  <em>p</em>)</span>。</td><td style="text-align: left;"></td></tr><tr class="odd"><td style="text-align: left;"></td><td style="text-align: left;"><code>c ← b \cdot a \pmod{p};</code></td><td style="text-align: left;">计算 <span class="math inline"><em>c</em> = <em>b</em> ⋅ <em>a</em> (mod  <em>p</em>) = <em>g</em><sup><em>r</em></sup> ⋅ <em>g</em><sup><em>x</em></sup> (mod  <em>p</em>) = <em>g</em><sup><em>r</em> + <em>x</em></sup> (mod  <em>p</em>)</span>。</td><td style="text-align: left;"><strong>原实例 <span class="math inline"><em>a</em></span> 变换为随机实例 <span class="math inline"><em>c</em></span>。</strong></td></tr><tr class="even"><td style="text-align: left;"><strong>III. 确定求解 (<span class="math inline"><em>f</em></span>)</strong></td><td style="text-align: left;"><code>y ← logg,pc;</code></td><td style="text-align: left;">使用<strong>确定性算法</strong> <span class="math inline"><em>l</em><em>o</em><em>g</em><sub><em>g</em>, <em>p</em></sub></span> 求解实例 <span class="math inline"><em>c</em></span>。<strong>目标是找到 <span class="math inline"><em>y</em></span>，使得 <span class="math inline"><em>g</em><sup><em>y</em></sup> ≡ <em>c</em> (mod  <em>p</em>)</span>。</strong></td><td style="text-align: left;"><span class="math inline"><em>y</em></span> 是 <span class="math inline"><em>r</em> + <em>x</em></span> 的解。</td></tr><tr class="odd"><td style="text-align: left;"><strong>IV. 后处理 (<span class="math inline"><em>v</em></span>)</strong></td><td style="text-align: left;"><code>return (y-r) mod (p-1);</code></td><td style="text-align: left;"><span class="math inline"><em>y</em></span> 是 <span class="math inline"><em>r</em> + <em>x</em></span> 的解，所以 <span class="math inline"><em>y</em> ≡ <em>r</em> + <em>x</em> (mod  <em>p</em> − 1)</span>。因此，<span class="math inline"><em>x</em> ≡ <em>y</em> − <em>r</em> (mod  <em>p</em> − 1)</span>。<strong>这是将解 <span class="math inline"><em>y</em></span> 变回 <span class="math inline"><em>x</em></span> 的步骤。</strong></td><td style="text-align: left;">恢复原实例 <span class="math inline"><em>a</em></span> 的解 <span class="math inline"><em>x</em></span>。</td></tr></tbody></table><h3 id="u-和-v-函数的确定">3. <span class="math inline"><em>u</em></span> 和 <span class="math inline"><em>v</em></span> 函数的确定</h3><p>根据 Sherwood 算法的<strong>随机预处理一般方法</strong>：</p><ul><li><strong>原实例 <span class="math inline"><em>x</em></span></strong>: 在离散对数问题中，原实例是<strong>目标值 <span class="math inline"><em>a</em></span></strong>。</li><li><strong>随机变量 <span class="math inline"><em>r</em></span></strong>: 在 <span class="math inline">{0, 1, …, <em>p</em> − 2}</span> 中随机抽取。</li><li><strong>确定性算法 <span class="math inline"><em>f</em></span></strong>: 是 <span class="math inline"><em>l</em><em>o</em><em>g</em><sub><em>g</em>, <em>p</em></sub></span>，即 <span class="math inline"><em>f</em>(<em>a</em>) = <em>x</em></span>。</li></ul><h4 id="预处理函数-u">1. 预处理函数 <span class="math inline"><em>u</em></span></h4><p><span class="math inline"><em>u</em>(<em>a</em>, <em>r</em>)</span> 的作用是将原实例 <span class="math inline"><em>a</em></span> 变换为随机实例 <span class="math inline"><em>c</em></span>。</p><p><span class="math display">$$\text{原实例 } a \xrightarrow{u(a, r)} \text{随机实例 } c$$</span></p><p>根据代码 <span class="math inline"><em>c</em> ← (<em>g</em><sup><em>r</em></sup> (mod  <em>p</em>)) ⋅ <em>a</em> (mod  <em>p</em>)</span>：</p><p><span class="math display"><em>u</em>(<em>a</em>, <em>r</em>) = (<em>g</em><sup><em>r</em></sup> ⋅ <em>a</em>) (mod  <em>p</em>)</span></p><h4 id="后处理函数-v">2. 后处理函数 <span class="math inline"><em>v</em></span></h4><p><span class="math inline"><em>v</em>(<em>r</em>, <em>s</em>)</span> 的作用是将确定性算法的解 <span class="math inline"><em>s</em></span> (即代码中的 <span class="math inline"><em>y</em></span>) 结合随机变量 <span class="math inline"><em>r</em></span>，变换回原实例的解 <span class="math inline"><em>x</em></span>。</p><p><span class="math display">$$\text{随机变量 } r \text{ 和 解 } s \xrightarrow{v(r, s)} \text{原实例的解 } x$$</span></p><p>根据代码 <span class="math inline"><em>x</em> ← (<em>y</em> − <em>r</em>) (mod  <em>p</em> − 1)</span>：</p><p><span class="math display"><em>v</em>(<em>r</em>, <em>s</em>) = (<em>s</em> − <em>r</em>) (mod  <em>p</em> − 1)</span></p><hr /><h3 id="素数判定问题-p124">5.2 素数判定问题 p124</h3><ul><li>方法1：随机因子</li></ul><p><img src="./2025-12-10-15-52-43.png" /> 在 n = 2623 的情况下 <span class="math inline">$2 - \sqrt{2623}$</span>随机选择有98%的概率正确</p><ul><li>方法2：费马小定理的逆否命题</li></ul><p><img src="./2025-12-10-15-55-14.png" /></p><p><img src="./2025-12-10-15-57-53.png" /></p><p>显然这种判定比较不负责（只要有 mod n == 1就是素数 不等于1就不是） 满足<span class="math inline"><em>a</em><sup><em>n</em> − 1</sup><em>m</em><em>o</em><em>d</em> <em>n</em> = 1</span>的数我们称为伪素数</p><p><img src="./2025-12-10-16-00-10.png" /></p><p>也就是说，仅仅使用费马小定理，会有一些合数比较特殊，他们有很多的a做了运算后 均为1。这就迎来了我们的方法3</p><ul><li>方法3： Miller-Rabin测试</li></ul><p><img src="./2025-12-10-16-18-12.png" /></p><p><img src="./2025-12-10-16-21-17.png" /></p><p>判断一个底数 <span class="math inline"><em>a</em></span> 是否为强伪证据： 分解 <span class="math inline"><em>n</em> − 1</span>： 将 <span class="math inline"><em>n</em> − 1</span> 分解为 <span class="math inline">2<sup><em>s</em></sup><em>t</em></span>（<span class="math inline"><em>t</em></span> 为奇数）。 计算初始值： 计算 <span class="math inline"><em>x</em> ← <em>a</em><sup><em>t</em></sup> (mod  <em>n</em>)</span>。 检查条件 ① 和 <span class="math inline"><em>i</em> = 0</span> 的条件 ②： 如果 <span class="math inline"><em>x</em> = 1</span> 或 <span class="math inline"><em>x</em> = <em>n</em> − 1</span>（即 <span class="math inline"><em>a</em><sup><em>t</em></sup> ≡ 1 (mod  <em>n</em>)</span> 或 <span class="math inline"><em>a</em><sup><em>t</em></sup> ≡  − 1 (mod  <em>n</em>)</span>），则 <span class="math inline"><em>a</em></span> 满足条件，返回 <span class="math inline"><em>t</em><em>r</em><em>u</em><em>e</em></span>（<span class="math inline"><em>a</em></span> 是强伪证据）。 循环检查其余的条件 ②： 执行 <span class="math inline"><em>s</em> − 1</span> 次循环，在每次循环中计算 <span class="math inline"><em>x</em> ← <em>x</em><sup>2</sup> (mod  <em>n</em>)</span>（相当于检查 <span class="math inline"><em>a</em><sup>2<sup><em>i</em></sup><em>t</em></sup> (mod  <em>n</em>)</span>）。如果在循环中发现 <span class="math inline"><em>x</em> = <em>n</em> − 1</span>，则满足条件②，返回 <span class="math inline"><em>t</em><em>r</em><em>u</em><em>e</em></span>（<span class="math inline"><em>a</em></span> 是强伪证据）。</p><p>返回 <span class="math inline"><em>f</em><em>a</em><em>l</em><em>s</em><em>e</em></span>：如果所有检查都未通过，则 <span class="math inline"><em>a</em></span> 不是强伪证据。此时 <span class="math inline"><em>a</em></span> 是 <span class="math inline"><em>n</em></span> 是合数的强证据，所以 <span class="math inline"><em>n</em></span> 必定是合数，返回 <span class="math inline"><em>f</em><em>a</em><em>l</em><em>s</em><em>e</em></span>（测试成功）。</p><p>这种方法大大缩减了伪证据数目</p>]]></content>
    
    
    <categories>
      
      <category>course</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>GenAL: Generative Agent for Adaptive Learning</title>
    <link href="/2025/12/10/GenAL-Generative-Agent-for-Adaptive-Learning/"/>
    <url>/2025/12/10/GenAL-Generative-Agent-for-Adaptive-Learning/</url>
    
    <content type="html"><![CDATA[<p><img src="./image.png" /></p><p><img src="./2025-12-10-10-26-20.png" /></p><p><a href="https://ojs.aaai.org/index.php/AAAI/article/view/32038">论文链接</a></p><p>写在前面：</p><p>简单来说，它的核心思想是：<strong>把“推荐题目”这件事变成两个智能体（Agent）之间的配合</strong>。一个负责“宏观思考”（了解学生整体情况），另一个负责“微观教学”（具体挑哪道题）。而且，它不像以前的推荐系统只看题目 ID，它是真的去<strong>读题目的文本内容</strong>，理解题意。</p><h4 id="第一步宏观把脉-全局思考智能体-gta">第一步：宏观把脉 —— 全局思考智能体 (GTA)</h4><p>在推荐新题目之前，系统首先要搞清楚“这个学生现在是什么水平？”。</p><ol type="1"><li><strong>看病历 (Log Memory)</strong>：系统会读取学生过去的答题记录 <span class="math inline">ℋ<sub><em>t</em></sub></span>，不仅看对错，还要看之前做过的题目的<strong>文本内容</strong>。</li><li><strong>做化验 (Educational Tools)</strong>：使用传统的<strong>知识追踪模型 (如 DKT)</strong> 来计算学生对各个知识点的掌握概率（比如“函数”掌握度 60%，“几何”掌握度 80%）[cite: 110, 112]。</li><li><strong>写诊断书 (Reflector)</strong>：这是关键。LLM（大模型）会结合上面的答题记录和掌握概率，生成一份<strong>学生画像 (<span class="math inline"><em>L</em><sub><em>t</em></sub></span>)</strong>。<ul><li>画像里包含：学生的能力评估、学习偏好（比如喜欢抽象题还是应用题）。 *同时，它会反思上一轮推荐得好不好，生成一个新的<strong>推荐策略 (<span class="math inline"><em>R</em><sub><em>t</em></sub></span>)</strong>（比如：“学生基础不牢，下一题应该降低难度，复习前置知识”）。</li></ul></li></ol><h4 id="第二步缩小范围-教学工具-teaching-tools">第二步：缩小范围 —— 教学工具 (Teaching Tools)</h4><p>现在有了策略，但题库里有成千上万道题，不能瞎选。这就需要 <strong>Local Teaching Agent (LTA)</strong> 里的工具来帮忙。</p><ol type="1"><li><strong>查地图 (Knowledge Graph)</strong>：利用<strong>层级知识图谱 (<span class="math inline"><em>G</em></span>)</strong>。</li><li><strong>圈范围</strong>：根据当前要学的知识点，找出它自己以及它的<strong>直接前驱节点</strong>（即学这个知识点之前必须会的那些基础）。</li><li><strong>定候选集</strong>：系统只把属于这些知识点的题目拿出来，形成一个<strong>候选练习集 (<span class="math inline"><em>S</em><sub><em>t</em></sub></span>)</strong>。这就大大缩小了搜索范围，避免大模型产生幻觉或跑题。</li></ol><h4 id="第三步精准决策-推荐器-recommender">第三步：精准决策 —— 推荐器 (Recommender)</h4><p>这是最终做决定的环节。</p><ol type="1"><li><strong>输入信息</strong>：推荐器（也是一个 LLM）接收两个东西：<ul><li>来自第一步的<strong>推荐策略 (<span class="math inline"><em>R</em><sub><em>t</em></sub></span>)</strong>（“要降低难度”）。</li><li>来自第二步的<strong>候选练习集 (<span class="math inline"><em>S</em><sub><em>t</em></sub></span>)</strong> [cite: 169]。</li></ul></li><li><strong>预测下一题 (<span class="math inline"><em>e</em><sub><em>t</em> + 1</sub></span>)</strong>：LLM 结合策略，从候选集里挑出最合适的一道题 [cite: 172]。</li><li><strong>给出理由与预测 (<span class="math inline"><em>F</em><sub><em>t</em> + 1</sub>, <em>A</em><sub><em>t</em> + 1</sub></span>)</strong>：<ul><li>这步很有意思，LLM 不光甩出一道题，还得<strong>解释为什么选这道题</strong>（Reasoning），并且<strong>预测学生能不能做对</strong>。这为下一步的“自我反思”留下了依据 [cite: 175]。</li></ul></li></ol><h4 id="第四步闭环反馈">第四步：闭环反馈</h4><p>学生做完题后，真实结果会和 LLM 的预测结果（<span class="math inline"><em>A</em><sub><em>t</em> + 1</sub></span>）进行对比。如果 LLM 预测学生会做对，结果学生做错了，GTA（第一步那个智能体）就会在下一轮更新策略：“我高估了他，即使是基础题他也做错了，需要更基础的练习”。</p><hr /><h3 id="举个栗子小明的一次函数学习之旅">📝 举个栗子：小明的“一次函数”学习之旅</h3><p>假设现在 <strong>小明</strong> 正在学习初中数学的 <strong>“一次函数 (<span class="math inline"><em>y</em> = <em>k</em><em>x</em> + <em>b</em></span>)”</strong>。</p><p><strong>1. 初始状态 (GTA 工作):</strong> * <strong>记录：</strong> 小明刚做完一道关于“斜率 <span class="math inline"><em>k</em></span>”的题，做错了。 * <strong>工具分析：</strong> 知识追踪模型显示，他对“斜率”的掌握度只有 30%，对“坐标系”掌握度 80%。 * <strong>GTA (大模型) 思考：</strong> “小明虽然懂坐标系，但对斜率的概念很模糊。现在的策略 <span class="math inline"><em>R</em><sub><em>t</em></sub></span> 应该是：<strong>暂停新课，回退一步，先巩固斜率的几何定义。</strong>”</p><p><strong>2. 筛选题目 (Teaching Tools 工作):</strong> * <strong>目标：</strong> 巩固“斜率”。 * <strong>知识图谱：</strong> 查到“斜率”的前置知识是“两点间距离”和“坐标点”。 * <strong>候选集 <span class="math inline"><em>S</em><sub><em>t</em></sub></span>：</strong> 系统从题库里捞出了 50 道相关的题。</p><p><strong>3. 最终推荐 (Recommender 工作):</strong> * <strong>输入：</strong> 策略是“巩固定义，不要太难”，候选集有 50 道题。 * <strong>大模型选择：</strong> 既然不能太难，它排除了那些“给定图像求解析式”的复杂题，选中了一道文字题 <strong><span class="math inline"><em>e</em><sub><em>t</em> + 1</sub></span></strong>： &gt; <em>题目：已知点 A(1, 2) 和点 B(3, 4)，请计算直线 AB 的斜率。</em> * <strong>大模型解释 (<span class="math inline"><em>F</em><sub><em>t</em> + 1</sub></span>):</strong> “推荐这道题是因为它是斜率的最基本计算，直接应用公式，没有复杂的变形，适合当前基础薄弱的小明。” * <strong>预测 (<span class="math inline"><em>A</em><sub><em>t</em> + 1</sub></span>):</strong> “预测他能做对，因为这是基础计算。”</p><p><strong>4. 结果反馈:</strong> * <strong>实际情况：</strong> 小明做对了。 * <strong>下一轮循环：</strong> GTA 看到“预测正确，小明做对了”，于是更新策略：“基础已巩固，下一轮可以尝试稍微难一点的题目，比如结合截距 <span class="math inline"><em>b</em></span> 的考察。”</p><hr /><h3 id="总结">总结</h3><p>GenAL 相比传统推荐系统，最大的亮点在于它<strong>像个真人老师</strong>： 1. 它<strong>读得懂题</strong>（利用 LLM 的语义理解能力）[cite: 14, 26]。 2. 它<strong>有教学逻辑</strong>（先看前置知识，再定难度）。 3. 它<strong>会反思</strong>（每次推荐都要写理由，预测不对就自我修正）。</p><hr /><h1 id="genal-基于生成式智能体的自适应学习框架">📚 GenAL: 基于生成式智能体的自适应学习框架</h1><h2 id="一-当前教育推荐系统存在的问题">一、 当前教育推荐系统存在的问题 🚧</h2><p>论文指出，尽管自适应学习（Adaptive Learning）研究广泛，但现有模型主要依赖于对学习者和练习题的<strong>简单 ID 索引</strong>，导致以下三个核心问题：</p><table><thead><tr class="header"><th style="text-align: left;">问题点</th><th style="text-align: left;">详细描述</th></tr></thead><tbody><tr class="odd"><td style="text-align: left;"><strong>信息利用率不足</strong></td><td style="text-align: left;">传统模型（如基于序列或强化学习的模型）<strong>无法有效利用</strong>练习题的<strong>文本内容</strong>等丰富的语义信息，导致对题目理解肤浅，推荐缺乏深度。</td></tr><tr class="even"><td style="text-align: left;"><strong>泛化性差，难以适应扩展</strong></td><td style="text-align: left;">模型需要针对不同的数据集或不断<strong>扩张的题库</strong>进行重新训练。这使其难以适应在线教育场景中资源快速更新和增长的需求。</td></tr><tr class="odd"><td style="text-align: left;"><strong>稀疏环境下的不稳定</strong></td><td style="text-align: left;">基于训练的强化学习（RL）推荐范式，在学生学习记录<strong>稀疏</strong>或数据量较小时，其推荐性能往往<strong>不稳定</strong>且难以保证效果。</td></tr></tbody></table><hr /><h2 id="二-本文的解决思路与核心方案">二、 本文的解决思路与核心方案 💡</h2><p>本文提出的 <strong>GenAL</strong> 框架旨在通过引入 <strong>大型语言模型 (LLM)</strong>，模仿人类教师的认知与教学过程，从而实现语义驱动、可泛化的自适应学习推荐。</p><table><thead><tr class="header"><th style="text-align: left;">解决思路</th><th style="text-align: left;">具体机制</th><th style="text-align: left;">目标</th></tr></thead><tbody><tr class="odd"><td style="text-align: left;"><strong>分层决策架构</strong></td><td style="text-align: left;">采用<strong>双智能体（Agent）结构，将复杂的教学任务分解：<br>1. 全局思考智能体 (GTA)：制定宏观</strong>教学策略 <span class="math inline"><em>R</em><sub><em>t</em></sub></span>。<br>2. <strong>局部教学智能体 (LTA)</strong>：执行<strong>微观</strong>推荐决策 <span class="math inline"><em>e</em><sub><em>t</em> + 1</sub></span>。</td><td style="text-align: left;">实现教学策略与题目选择的有效解耦和协同。</td></tr><tr class="even"><td style="text-align: left;"><strong>语义驱动推荐</strong></td><td style="text-align: left;">LTA 中的<strong>推荐器（Recommender）是一个 LLM，它直接读取题目内容</strong>的文本信息，并根据 GTA 的策略进行语义级别的推理和选择。</td><td style="text-align: left;">克服传统模型只看 ID 的局限性，实现基于内容的理解推荐。</td></tr><tr class="odd"><td style="text-align: left;"><strong>引入外部知识</strong></td><td style="text-align: left;">LTA 中包含<strong>教学工具（Teaching Tools）</strong>，用于接入教育领域的<strong>先验知识</strong>。</td><td style="text-align: left;">解决 LLM 在特定教育领域的知识短板，避免“幻觉”。</td></tr></tbody></table><hr /><h2 id="三-该思路可能遇到的挑战">三、 该思路可能遇到的挑战 ⚔️</h2><table><thead><tr class="header"><th style="text-align: left;">挑战点</th><th style="text-align: left;">描述</th></tr></thead><tbody><tr class="odd"><td style="text-align: left;"><strong>LLM 的领域幻觉</strong></td><td style="text-align: left;">LLM 在通用领域强大，但在专业的教育知识点上可能缺乏精确性，容易产生不准确的**“幻觉”决策<strong>或</strong>不专业理由**。</td></tr><tr class="even"><td style="text-align: left;"><strong>巨大的搜索空间</strong></td><td style="text-align: left;">如果让 LLM 直接从整个题库中挑选 <span class="math inline"><em>e</em><sub><em>t</em> + 1</sub></span>，其<strong>计算和时间成本不可接受</strong>，效率极低。</td></tr><tr class="odd"><td style="text-align: left;"><strong>缺乏教学闭环与自我修正</strong></td><td style="text-align: left;">缺乏将 LLM 的推荐决策与学生的<strong>真实反馈</strong>进行对比、反思和迭代修正的机制，难以保证教学策略的<strong>长期稳定性</strong>和<strong>有效性</strong>。</td></tr></tbody></table><hr /><h2 id="四-本文克服挑战的手段">四、 本文克服挑战的手段 🛠️</h2><p>GenAL 框架通过设计精巧的工具和反思机制，系统性地解决了上述挑战：</p><table><thead><tr class="header"><th style="text-align: left;">挑战</th><th style="text-align: left;">克服手段</th><th style="text-align: left;">实现细节</th></tr></thead><tbody><tr class="odd"><td style="text-align: left;"><strong>领域幻觉与搜索空间</strong></td><td style="text-align: left;"><strong>知识图谱指导与搜索空间限制</strong></td><td style="text-align: left;"><strong>教学工具（Teaching Tools）</strong>：利用<strong>分层知识图谱</strong> <span class="math inline"><em>G</em></span> 来<strong>限制</strong>推荐范围。候选集 <span class="math inline"><em>S</em><sub><em>t</em></sub></span> 只包括当前目标知识点及其<strong>直接前驱节点</strong>相关的练习题。这既缩小了搜索空间，又用结构化知识<strong>校准了 LLM</strong>。</td></tr><tr class="even"><td style="text-align: left;"><strong>缺乏教学闭环</strong></td><td style="text-align: left;"><strong>反思与预测机制</strong></td><td style="text-align: left;"><strong>推荐器（Recommender）</strong>：强制要求 LLM 在推荐 <span class="math inline"><em>e</em><sub><em>t</em> + 1</sub></span> 的同时，生成推荐<strong>理由</strong> (<span class="math inline"><em>F</em><sub><em>t</em> + 1</sub></span>) 和对学生作答的<strong>预测</strong> (<span class="math inline"><em>A</em><sub><em>t</em> + 1</sub></span>)。<br><strong>全局思考智能体（GTA）</strong>：负责将 <span class="math inline"><em>A</em><sub><em>t</em> + 1</sub></span> 与学生<strong>实际作答</strong>进行对比，通过**反思器（Reflector）<strong>生成新的反思总结 <span class="math inline"><em>L</em><sub><em>t</em></sub></span>，并更新下一轮的教学策略 <span class="math inline"><em>R</em><sub><em>t</em> + 1</sub></span>，形成</strong>“观察-反思-规划-行动”**的闭环。</td></tr></tbody></table><hr /><h2 id="五-实验论证优越性">五、 实验论证优越性 🏆</h2><p>本文通过在实际教育数据集上的对比实验和消融实验，全面论证了 GenAL 框架的优越性：</p><ol type="1"><li><p><strong>推荐有效性 (Recommendation Effectiveness)</strong>：</p><ul><li><strong>结果：</strong> GenAL 在评估自适应推荐效率的指标（如通过更少的问题达成目标知识掌握度）上，<strong>显著优于</strong>传统的序列推荐模型和基于 RL 的推荐模型。</li><li><strong>论证：</strong> 证明了其策略制定和题目选择更高效，能加速学生的学习路径。</li></ul></li><li><p><strong>知识追踪准确性 (Knowledge Tracing Accuracy)</strong>：</p><ul><li><strong>指标：</strong> 使用 <span class="math inline">AUC</span> 和 <span class="math inline">ACC</span> 等指标评估模型对学生<strong>下一个问题作答对错的预测能力</strong>。</li><li><strong>结果：</strong> GenAL 达到了<strong>最高的预测准确率</strong>，表明其能更精确地理解学生的实时学习状态。</li></ul></li><li><p><strong>消融实验 (Ablation Study)</strong>：</p><ul><li>通过移除关键组件（如知识图谱、反思机制），实验结果显示性能大幅下降。</li><li><strong>论证：</strong> 证明了<strong>知识图谱</strong>是克服 LLM 幻觉的关键，而<strong>反思机制</strong>则是保障 GenAL 长期、稳定、高效推荐的根本保障。</li></ul></li></ol>]]></content>
    
    
    <categories>
      
      <category>AAAI2025</category>
      
    </categories>
    
    
  </entry>
  
  
  
  
</search>
