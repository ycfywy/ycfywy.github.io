<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Evals for Data Diversity</title>
    <link href="/2025/12/13/Evals-for-Data-Diversity/"/>
    <url>/2025/12/13/Evals-for-Data-Diversity/</url>
    
    <content type="html"><![CDATA[<h1 id="llm生成数据的多样性评估">LLM生成数据的多样性评估</h1><p><a href="https://amitness.com/posts/diversity-evals">link</a></p><h2 id="引言为什么合成数据需要多样性">引言：为什么合成数据需要多样性？</h2><p>使用大型语言模型（LLMs）生成合成数据已成为一种流行的方法。然而，一个常见的问题是，LLM直接生成的输出往往具有<strong>重复性</strong>。</p><p>为了提高生成数据的多样性，我们通常会采用一些技术，例如：</p><ul><li><strong>采样参数：</strong> 提高温度（temperature）、使用核采样（nucleus-sampling）或 Top-K 采样。</li><li><strong>属性生成：</strong> 预先生成各种属性（如主题、风格、长度、角色等），并将其随机插入到提示中。</li><li><strong>解码后聚类：</strong> 过量生成大量文本，然后通过聚类中心或语义哈希进行去重。</li></ul><p>这就引出了一个关键问题：<strong>我们如何系统地评估这些技术对多样性的影响</strong></p><p>本文将概述学术界已有的、用于衡量LLM生成文本<strong>Diversity</strong>的各种自动评估指标，涵盖词汇、语义和句法三个维度。</p><hr /><h2 id="一词汇多样性指标-lexical-diversity-metrics">一、词汇多样性指标 (Lexical Diversity Metrics)</h2><p>这类指标用于捕捉文本中词语、短语、主题和 N-gram 在表面上的重复程度。</p><h3 id="独特-n-gram-distinct-k">1. 独特 N-gram (Distinct-k)</h3><ul><li><strong>基本概念：</strong> 源自语言学中的“型符比”（type-token ratio）。</li><li><strong>计算方式：</strong> 计算生成的整个数据集中<strong>独特 N-gram 的数量</strong>与<strong>总 N-gram 的数量</strong>之比。</li></ul><p>例如，对于文本 “As an AI language model” 和 “As an AI model”：</p><ul><li>总 Unigram (1-gram) 数量：9</li><li>独特 Unigram 数量：5 (As, an, AI, language, model)</li><li><strong>多样性得分：</strong> <span class="math inline">5/9 ≈ 0.55</span></li></ul><p><img src="./2025-12-13-19-46-14.png" /> <img src="./2025-12-13-19-46-20.png" /></p><p>这个概念可以扩展到 Bigram (k=2)、Trigram (k=3) 等，并可以分别组合成一个分数。</p><h3 id="n-gram-熵-ent-n">2. N-gram 熵 (Ent-n)</h3><ul><li><strong>基本概念：</strong> 在理想情况下，LLM 生成的所有文本都应该是独特的，任何 N-gram 都不会重复超过一次。</li><li><strong>计算方式：</strong> 通过收集文本中所有独特的 N-gram，计算它们的频率，从而得到 N-gram 的概率分布。然后，计算该概率分布的<strong>信息熵</strong>。</li><li><strong>判断标准：</strong> 分布越均匀（重复越少），熵值越高，多样性也越高。</li></ul><p><img src="./2025-12-13-19-46-58.png" /></p><h3 id="压缩比-compression-ratio">3. 压缩比 (Compression Ratio)</h3><ul><li><strong>基本概念：</strong> 借鉴用于评估压缩算法的压缩比概念。</li><li><strong>计算方式：</strong> 使用如 Gzip 等算法压缩文本，计算<strong>压缩文件大小</strong>与<strong>原始大小</strong>之比。</li><li><strong>判断标准：</strong><ul><li><strong>比率越高</strong>（如 16.258），表明文本<strong>可压缩性越高</strong>，冗余度高，因此<strong>多样性越低</strong>。</li><li>多样性可以计算为压缩比的<strong>倒数</strong>，从而得到一个 0 到 1 之间的分数。</li></ul></li></ul><h2 id="section"><img src="./2025-12-13-19-48-01.png" /></h2><h2 id="二语义多样性指标-semantic-diversity-metrics">二、语义多样性指标 (Semantic Diversity Metrics)</h2><p>这类指标关注文本在<strong>语义</strong>上的多样性，并依赖于embeddings。它们可以处理词汇重叠为零但意义相似（例如，“Play the music” 和 “Start a song”）的情况。</p><h3 id="嵌入多样性-embedding-diversity">1. 嵌入多样性 (Embedding Diversity)</h3><ul><li><strong>计算方式：</strong><ol type="1"><li>使用编码器（如 Sentence-Transformers）计算所有生成文本的<strong>Embedding vector</strong>。</li><li>计算所有独特文本对之间的<strong>余弦相似度（Cosine Similarity）</strong>。</li><li>取这些相似度的<strong>平均值</strong>。</li></ol></li><li><strong>判断标准：</strong> 将平均相似度转换为多样性得分（如：<span class="math inline">1 − 平均余弦相似度</span>），得分越高表示多样性越高。</li></ul><p><img src="./2025-12-13-19-48-18.png" /> <img src="./2025-12-13-19-48-24.png" /></p><h3 id="dcscore">2. DCScore</h3><ul><li><strong>计算方式：</strong><ol type="1"><li>计算文本嵌入的<strong>两两相似度矩阵</strong>(做法和1相同)。</li><li>对该矩阵应用 <strong>Softmax</strong> 函数。</li><li>计算 Softmax 矩阵<strong>对角线元素的平均值</strong>。</li></ol></li><li><strong>判断标准：</strong> 对角线元素表示文本相对于所有其他文本（包括自身）与自身的相似度“概率”。平均值越接近 1，表示文本与其自身的相似度远高于与其他任何文本的相似度，从而意味着整体数据集的多样性高。</li></ul><p><img src="./2025-12-13-19-48-34.png" /> <img src="./2025-12-13-19-48-39.png" /></p><h3 id="聚类惯性-cluster-inertia">3. 聚类惯性 (Cluster Inertia)</h3><ul><li><strong>基本概念：</strong> 重用聚类算法中用于衡量聚类质量的“惯性”指标。</li><li><strong>计算方式：</strong><ol type="1"><li>将文本嵌入聚类到 <span class="math inline"><em>K</em></span> 个簇（如 <span class="math inline"><em>K</em> = 10</span>）。</li><li>计算<strong>惯性</strong> (Inertia)：即簇内所有点到其<strong>质心（centroid）</strong>的平方距离之和。</li></ol></li><li><strong>判断标准：</strong> 如果文本多样，它们会离质心更远，导致<strong>惯性更大</strong>，因此惯性被视为多样性的一个代理指标。</li></ul><p><img src="./2025-12-13-19-48-47.png" /></p><hr /><h2 id="三句法多样性指标-syntactic-diversity-metrics">三、句法多样性指标 (Syntactic Diversity Metrics)</h2><p>这类指标捕捉文本在<strong>底层语法结构</strong>上的多样性。</p><h3 id="压缩比---词性-cr-pos">1. 压缩比 - 词性 (CR-POS)</h3><ul><li><strong>基本概念：</strong> 重用“压缩比”的概念，但应用于文本的<strong>句法表示</strong>。</li><li><strong>计算方式：</strong><ol type="1"><li>使用词性标注器（POS tagger）将所有生成文本转换为其<strong>词性标签序列</strong>（即句法表示）。</li><li>将所有词性标签序列拼接成一个长字符串。</li><li>计算这个长字符串的<strong>压缩比</strong>。</li></ol></li><li><strong>判断标准：</strong> 压缩比越高，表示句法模板重复越多，<strong>多样性越低</strong>。多样性得分取压缩比的倒数。</li></ul><p><img src="./2025-12-13-19-48-57.png" /> <img src="./2025-12-13-19-49-04.png" /> <img src="./2025-12-13-19-49-10.png" /></p><hr /><h2 id="总结">总结</h2><p>我们探索了衡量LLM生成数据的语言多样性的三大类指标：</p><table><thead><tr class="header"><th style="text-align: left;">类别</th><th style="text-align: left;">关注点</th><th style="text-align: left;">关键指标</th></tr></thead><tbody><tr class="odd"><td style="text-align: left;"><strong>词汇</strong></td><td style="text-align: left;">表面词语、N-gram 的重复</td><td style="text-align: left;">N-gram (Distinct-k), N-gram 熵, 压缩比</td></tr><tr class="even"><td style="text-align: left;"><strong>语义</strong></td><td style="text-align: left;">文本在意义上的不同</td><td style="text-align: left;">嵌入多样性, DCScore, 聚类惯性</td></tr><tr class="odd"><td style="text-align: left;"><strong>句法</strong></td><td style="text-align: left;">底层语法结构的重复</td><td style="text-align: left;">压缩比 - 词性 (CR-POS)</td></tr></tbody></table><p>在实际应用中，这些自动指标快速且易于计算，可以作为评估LLM生成数据多样性的指标。</p>]]></content>
    
    
    <categories>
      
      <category>eval</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>VERBALIZED SAMPLING: HOW TO MITIGATE MODE COLLAPSE AND UNLOCK LLM DIVERSITY</title>
    <link href="/2025/12/11/VERBALIZED-SAMPLING-HOW-TO-MITIGATE-MODE-COLLAPSE-AND-UNLOCK-LLM-DIVERSITY/"/>
    <url>/2025/12/11/VERBALIZED-SAMPLING-HOW-TO-MITIGATE-MODE-COLLAPSE-AND-UNLOCK-LLM-DIVERSITY/</url>
    
    <content type="html"><![CDATA[<p><img src="./2025-12-11-22-43-23.png" /></p><h2 id="我的评价">我的评价</h2><p>   作者说LLM生成内容的多样性不好，是因为数据本身就带有人类的偏好。数据本身的偏好是模型多样性缺失的原因，是本文要证明的内容。按照这个分析，作者大概会构造一些偏好数据，然后训练模型，证明这种多样性确实源于偏好数据。</p><p>   作者改进模型数据多样性的方法，不是通过output的采样，而是使用Prompt，让模型输出多个回答并带有概率分布，这种方式很难理解为什么这么做。明明使用llm的参数temperature改变采样策略就可以做到，为什么还要这种Prompt呢？(作者标榜Prompt可以做到Training-Free 但是采样策略也是啊 而且更可控…)</p><p>  总结来说，这篇文章有点像是独立的两篇文章。前半段对Training Data的bias的分析不够深入，只是针对一个数据集做了分析，通过拟合，证明了数据确实有bias。在我看来，还应该对bias data对模型的影响进行更加细致的分析（比如通过消除bias data中的bias，重新训练，看能否消除这种diversity的缺失）。后半段则是对VERBALIZED SAMPLING（一种带有概率的Prompt）来缓解模型diversity的降低。在我看来，后半段完全可以单独弄一个文章，分析temperature / reward model / training algforithm / prompt等对模型输出diversity的影响，看看哪个更有效。</p><p>  作为一篇ICLR 2026在投的文章，从<a href="https://openreview.net/forum?id=9jQkmGunGo">OpenReview</a>上面的评论，也可以看出和评价类似的Reviewer comment。不过这确实是一篇实验非常详实，消融实验设计也很合理的好文章。</p><h2 id="当前存在什么问题">当前存在什么问题</h2><p>  在创意性的问题，比如“tell me a joke” “write a story about bear”… 场景下，我们需要 LLM 给出尽可能 diverse 的 answer。但是前人研究发现，LLM 在训练的过程中，生成内容的 diversity 会降低。过去的研究集中在算法层面，认为 trainging algorithm 存在天然的缺陷，比如单一的奖励信号，RLHF 中的 KL 正则化项等等，他们天然的就会在训练的过程中降低 model output diversity。因此，解决的方案就是从算法角度下手，尽可能优化 sft rl 的过程。</p><p>本文想要从 Data 的角度解释这种 diversity 的缺失，同时提出一些提高 diversity 的方法。</p><h2 id="本文打算通过什么思路解决">本文打算通过什么思路解决</h2><p>  本文做出假设：模型的训练数据本身是带有 bias 的。人类在标注 RLHF 数据的时候，做排序天然的就有 bias。比如更喜欢比较熟悉的语法，熟悉的结构，简单易懂的呈现方式等等。本文通过分析一个 Nvidia 团队的数据集HELPSTEER，证明这种数据bias 的存在。这里通过理论推导和拟合，发现确实存在。</p><p><span class="math display">$$r(x, y) = r_{\text{true}}(x, y) + \alpha \log \pi_{\text{ref}}(y | x) + \epsilon(x) \tag{1}$$</span></p><p>  研究人员使用了 HELPSTEER 数据集。这个数据集非常特殊，因为它对同一个回答给了两个不同的打分： - Correctness（正确性）： 对应公式中的 <span class="math inline"><em>r</em><sub>true</sub></span>（真实任务效用）。 - Helpfulness（有用性）： 对应公式中的 <span class="math inline"><em>r</em></span>（最终奖励，即人类给出的总分）</p><p>研究人员从数据集中筛选出了 6,874 对回答。这些配对有一个关键特征：“same correctness ratings” (拥有相同的正确性评分)这意味着对于每一对回答 <span class="math inline">(<em>y</em><sub>1</sub>, <em>y</em><sub>2</sub>)</span>，它们的真实效用是相等的：<span class="math display"><em>r</em><sub>true</sub>(<em>y</em><sub>1</sub>) = <em>r</em><sub>true</sub>(<em>y</em><sub>2</sub>)</span></p><p>假设有两个回答 <span class="math inline"><em>A</em></span> 和 <span class="math inline"><em>B</em></span>，它们的正确性评分一样，但人类给的总分（有用性）不一样。根据公式 (1)：回答 A 的得分： <span class="math inline"><em>r</em><sub><em>A</em></sub> = <em>r</em><sub>true</sub> + <em>α</em> ⋅ Typicality<sub><em>A</em></sub></span>回答 B 的得分： <span class="math inline"><em>r</em><sub><em>B</em></sub> = <em>r</em><sub>true</sub> + <em>α</em> ⋅ Typicality<sub><em>B</em></sub></span>当我们把这两个式子相减（比较 <span class="math inline"><em>A</em></span> 和 <span class="math inline"><em>B</em></span>）：<span class="math display"><em>r</em><sub><em>A</em></sub> − <em>r</em><sub><em>B</em></sub> = (<em>r</em><sub>true</sub> − <em>r</em><sub>true</sub>) + <em>α</em>(Typicality<sub><em>A</em></sub> − Typicality<sub><em>B</em></sub>)</span>由于正确性相同，<span class="math inline"><em>r</em><sub>true</sub></span> 互相抵消为 0，剩下的就是：<span class="math display"><em>Δ</em>Reward = <em>α</em> × <em>Δ</em>Typicality</span></p><h2 id="该思路会遇到什么挑战">该思路会遇到什么挑战</h2><ul><li>如何证明 data bias 的存在。</li><li>找到一个新的方法，能够提高模型的 diversity</li></ul><h2 id="本文通过什么手段克服该挑战">本文通过什么手段克服该挑战</h2><ul><li>本文通过理论推导 bias 公式，然后使用HELPSTEER 数据集做数据拟合的验证，表明这种数据的 bias 的存在。</li><li>前人的解决方案大多集中在 algorithm 或者 inference setting (sampling 策略)。本文提出带有概率输出的 prompt 来解决。如:“Generate 5 responses with their corresponding probabilities. Tell me a joke about coffee.”</li></ul><h2 id="本文如何通过实验论证了该方案的优越性">本文如何通过实验论证了该方案的优越性</h2><ul><li><p>实验目标：证明该 prompt 能够提高 LLM 输出的 diversity。</p></li><li><p>实验的 benchmark：诗歌续写，故事生成，讲笑话。</p></li><li><p>怎么 evaluate 模型的输出呢： 多样性：把模型的输出做 Embedding，通过相似度计算来反映输出的 diversity 输出质量：只输出多样的内容是不够的，我们还需要保证 quality。本文把 claude 模型 LLM as judge，从几个语言学上的维度，评估输出的质量。</p></li><li><p>实验设置：在下列模型上，不同的 method （看Prompt Example column）跑 benchmark，使用 evaluate 的方法，计算输出的多样性和质量，绘制图像。 Gemini-2.5-Flash, Gemini-2.5-Pro Claude Series (Claude-3.7-Sonnet, Claude-4-Sonnet) open ones like (Llama-3.1-70B-Instruct and Qwen3-235B-A22B-2507-Instruct-2507) reasoning models like (OpenAI o3 and DeepSeek R1) <img src="./2025-12-12-22-38-08.png" /> 实验结果：VS（也就是本文提出的方法）在各个 benchmark 上的表现都更优 <img src="./2025-12-12-22-38-22.png" /> <img src="./2025-12-12-22-38-27.png" /></p></li><li><p>消融实验：</p></li></ul><ol type="1"><li>llm params: temparature LLM 的 api 中可以调节 temperature 参数来调整模型输出的 diversity。因此需要消融 temperature。本文通过设置不同的 temperature 进行相同实验，消除该参数对方案有效性的影响。可以看到，VS 方案在各个 temperature 下的 diversity + quality 的表现依然是最佳的。 <img src="./2025-12-12-22-39-21.png" /></li><li>llm 不同的 traing stage 为了证明这种 VS 方法的有效性，本文在 LLM 不同的训练阶段 （SFT RLHF RLVR）都进行了 diversity 的测试，发现该方法在不同阶段都有效果。如图，随着训练的进行，Base Model 的 diversity 下降，但是 VS 方法的下降是最慢的，缓解了模型 diversity 的下降。 <img src="./2025-12-12-22-40-09.png" /></li></ol><h2 id="我的思考">我的思考</h2><p>  我在gemini-2.5-flash模型上试了一下，“Write a story about a bear.” 会得到如下结果 确实会有可能得到相似的回答： <img src="./2025-12-11-22-52-38.png" /> <img src="./2025-12-11-22-52-49.png" /></p><p>不过这里只是粗略的看，<strong>如何评估两段文字的语义相似性 也是一个值得研究的问题</strong></p><p>研究RLHF阶段的training data，分析到底什么样的数据会更优先，有没有搞头？可能需要分析排在前面的answer的通用范式（可能有总结 结构比较清晰 有各种tag分点之类的），也需要评估排在前面的answer是不是真的质量高于后面的，还是说因为human preference打分比较靠前。（这里你可能就要找一个方法 评估回答的质量–》 如果让LLM judge，那是不是就会出问题–》本身就是偏好数据RLHF训练出来的 会不会就给这里的排在前面的answer打高分呢 ）</p><p>对比现有的提升模型输出多样性的方法，找到最有效的那个，不知道算不算创新，能不能发文章</p><ul><li>本文提及的论文中，可以继续深入了解的内容：</li></ul><ol type="1"><li>了解 RLHF 相关数据集的标注格式： HelpSteer: Multi-attribute Helpfulness Dataset for SteerLM <a href="https://arxiv.org/abs/2311.09528">link</a></li><li>了解模型训练的不同阶段： Tulu 3: Pushing Frontiers in Open Language Model Post-Training <a href="https://arxiv.org/abs/2411.15124">link</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>iclr</category>
      
    </categories>
    
    
    <tags>
      
      <tag>iclr2026在投</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>COZE项目概述</title>
    <link href="/2025/12/11/COZE%E9%A1%B9%E7%9B%AE%E6%A6%82%E8%BF%B0/"/>
    <url>/2025/12/11/COZE%E9%A1%B9%E7%9B%AE%E6%A6%82%E8%BF%B0/</url>
    
    <content type="html"><![CDATA[<h2 id="我的评价">我的评价</h2><p>  </p><h2 id="当前存在什么问题">当前存在什么问题</h2><p>  </p><h2 id="本文打算通过什么思路解决">本文打算通过什么思路解决</h2><p>  </p><h2 id="该思路会遇到什么挑战">该思路会遇到什么挑战</h2><p>  </p><h2 id="本文通过什么手段克服该挑战">本文通过什么手段克服该挑战</h2><p>  </p><h2 id="本文如何通过实验论证了该方案的优越性">本文如何通过实验论证了该方案的优越性</h2><p>  </p><h2 id="本文的写作思路">本文的写作思路</h2><p>  </p><h2 id="我的思考">我的思考</h2><p>  </p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>StressPrompt: Does Stress Impact Large Language Models and Human Performance Similarly?</title>
    <link href="/2025/12/10/StressPrompt-Does-Stress-Impact-Large-Language-Models-and-Human-Performance-Similarly/"/>
    <url>/2025/12/10/StressPrompt-Does-Stress-Impact-Large-Language-Models-and-Human-Performance-Similarly/</url>
    
    <content type="html"><![CDATA[<p><img src="./2025-12-10-23-32-16.png" /></p><h2 id="我的评价">我的评价</h2><p>写作逻辑还可以，实验部分写的很差</p><ol type="1"><li>实验数据不完整   The models tested included Llama-3-8B-Instruct, Llama-3.1-8B-Instruct, Llama-3-70B-Instruct(AI@Meta 2024), Phi-3-mini-4k-Instruct (Abdin et al.2024), Qwen2-72B-Instruct, Qwen2-7B-Instruct (Yang et al.2024), and Mistral-7B-Instruct-v0.3 (Jiang et al. 2023). The generation temperature was set to 0, and specific dialogue tokens were used to ensure consistency.</li></ol><p>  The datasets employed in these evaluations included IFEval (Zhou et al.2023), BBH (Suzgun et al. 2022), MATH (Hendrycks et al. 2021b), GPQA (Rein et al. 2023), MuSR (Sprague et al. 2023), MMLU-P (Wang et al. 2024b), EQBench (Paech 2023), MMLU (Hendrycks et al. 2021a),TruthfulQA</p><p>  然而实际上你只能看到这些Llama-3-8B-Instruct, Phi-3-mini-4k-Instruct 以及一些意义不明 明显是凑数用的数据分析(PCA T-SNE) 对于StressPrompt的作用原理也是点到为止。</p><ol start="2" type="1"><li><p>如何构造的prompt也是意义不明 只是说自己套用了很多什么心理学准则提示词生成的原理也没讲，AI生成吗？</p></li><li><p>喜欢蹭心理科学，标榜自己证实了耶克斯-多德森定律。纯纯唐文</p></li></ol><h2 id="当前存在什么问题">当前存在什么问题</h2><p>  现在没有人做模型的压力测试。就像人在不同压力等级下的表现不同，模型会不会也有这种现象。此外分析压力对模型内部的影响，对模型的训练过程也有一定的启发。</p><h2 id="本文打算通过什么思路解决">本文打算通过什么思路解决</h2><p>  设计100个StressPrompt， 对prompt进行人工压力评级(0 - 10)。把StressPrompt作为System Prompt输到模型里，再让模型进行MMLU MATH GPQA等主流测试。看看模型的表现有没有变化。</p><p>  分析StressPrompt对模型内部的影响，可以把hidden state的向量拿到，然后做一个PCA，找到方差最大的那个vector。对于某个prompt，可以拿到不同layer的不同token的hidden state然后和vector相乘得到一个标量，用于表示影响。</p><p><img src="./2025-12-10-23-40-02.png" /></p><h2 id="该思路会遇到什么挑战">该思路会遇到什么挑战</h2><p>   没什么挑战。构建prompt(我猜用的是ai)；PCA和分析不同layer的hidden state的方法感觉像是ai想出来的数据分析方法。</p><h2 id="本文通过什么手段克服该挑战">本文通过什么手段克服该挑战</h2><p>   。。。</p><h2 id="本文如何通过实验论证了该方案的优越性">本文如何通过实验论证了该方案的优越性</h2><p>   跑各种主流评测数据集。但是有个问题，本文根本就是挂羊头卖狗肉，没有展示出来所有的模型的表现。而且表格画的很烂。有提升的为什么不把这里加粗（把最高的标粗），还有1-10都没有提升的也不讨论。 <img src="./2025-12-10-23-43-33.png" /></p><h2 id="本文的写作思路">本文的写作思路</h2><p>  引言 (Introduction)： 提出LLMs性能受压力影响的问题尚未被探索，阐述研究的必要性（理解LLMs与人类智能的相似性、AI的鲁棒性）。</p><p>  相关工作 (Related Works)： 回顾LLMs的进步、情感智能评估以及压力对人类的影响等研究，指出现有研究缺乏对LLMs内部状态的定量分析，引出本文的研究切入点 。</p><p>  方法 (Method)： 详细介绍核心创新点：StressPrompt 的构建：基于四大心理学框架，并通过人类评分校准 。StressPrompt 的评估框架：如何在不同压力水平下系统地评估LLMs的性能 。压力扫描器 (Stress Scanner) 的分析：如何利用表征工程（RepE）来量化压力对LLMs内部状态的影响 。</p><p>  实验 (Experiments)： 描述实验设置、测试的模型和基准任务，并对在不同压力水平下的任务性能进行详细分析，重点论证耶克斯-多德森定律的发现和对不同任务（如复杂推理、情绪智能）的影响 。</p><p>  结论与贡献 (Conclusion/Contributions)： 总结研究发现，强调StressPrompt的贡献（创新数据集、压力扫描器），并提出对未来开发更具弹性和适应性的AI系统的指导意义 。</p><h2 id="我的思考">我的思考</h2><p>这种垃圾还是少看为佳</p>]]></content>
    
    
    <categories>
      
      <category>AAAI2025</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>概率算法ppt总结</title>
    <link href="/2025/12/10/%E6%A6%82%E7%8E%87%E7%AE%97%E6%B3%95ppt%E6%80%BB%E7%BB%93/"/>
    <url>/2025/12/10/%E6%A6%82%E7%8E%87%E7%AE%97%E6%B3%95ppt%E6%80%BB%E7%BB%93/</url>
    
    <content type="html"><![CDATA[<p>计算 <span class="math inline"><em>a</em> = <em>g</em><sup><em>x</em></sup><em>m</em><em>o</em><em>d</em> <em>p</em></span> 离散对数计算的问题 最坏情况下是<span class="math inline"><em>O</em>(<em>p</em>)</span> 这里可以使用Sherwood算法引入随机性，降低进入最坏情况的概率。</p><p><img src="./2025-12-10-14-09-30.png" /></p><p>这个改写利用了随机预处理来改变求解的实例，使得原本可能在特定输入下性能不佳的确定性离散对数算法 <span class="math inline"><em>l</em><em>o</em><em>g</em><sub><em>g</em>, <em>p</em></sub></span>，能够以接近平均性能的效率求解。</p><h2 id="dlog_rh-算法工作原理分析">🔬 <span class="math inline"><em>d</em><em>l</em><em>o</em><em>g</em><sub><em>R</em><em>H</em></sub></span> 算法工作原理分析</h2><h3 id="算法目标">1. 算法目标</h3><ul><li><strong>问题</strong>: 离散对数问题。</li><li><strong>输入</strong>: 基数 <span class="math inline"><em>g</em></span>，目标值 <span class="math inline"><em>a</em></span>，模数 <span class="math inline"><em>p</em></span>。</li><li><strong>求解</strong>: 找到指数 <span class="math inline"><em>x</em></span>，使得 <span class="math inline"><em>g</em><sup><em>x</em></sup> ≡ <em>a</em> (mod  <em>p</em>)</span>。</li><li><strong>模</strong>: 运算发生在 <span class="math inline">ℤ<sub><em>p</em></sub><sup>*</sup></span> (模 <span class="math inline"><em>p</em></span> 乘法群) 中。指数 <span class="math inline"><em>x</em></span> 在 <span class="math inline">ℤ<sub><em>p</em> − 1</sub></span> (模 <span class="math inline"><em>p</em> − 1</span> 加法群) 中，即 <span class="math inline"><em>x</em> ∈ {0, 1, …, <em>p</em> − 2}</span>。</li></ul><h3 id="dlog_rh-步骤解析">2. <span class="math inline"><em>d</em><em>l</em><em>o</em><em>g</em><sub><em>R</em><em>H</em></sub></span> 步骤解析</h3><table><thead><tr class="header"><th style="text-align: left;">步骤</th><th style="text-align: left;">代码</th><th style="text-align: left;">解释</th><th style="text-align: left;">作用</th></tr></thead><tbody><tr class="odd"><td style="text-align: left;"><strong>I. 随机数</strong></td><td style="text-align: left;"><code>r ← uniform(0..p-2);</code></td><td style="text-align: left;">随机选择一个指数 <span class="math inline"><em>r</em> ∈ {0, 1, …, <em>p</em> − 2}</span>。<strong>这是随机性的来源。</strong></td><td style="text-align: left;">引入随机变量 <span class="math inline"><em>r</em></span>。</td></tr><tr class="even"><td style="text-align: left;"><strong>II. 预处理 (实例 <span class="math inline"><em>y</em></span>)</strong></td><td style="text-align: left;"><code>b ← ModularExponent(g, r, p);</code></td><td style="text-align: left;">计算 <span class="math inline"><em>b</em> = <em>g</em><sup><em>r</em></sup> (mod  <em>p</em>)</span>。</td><td style="text-align: left;"></td></tr><tr class="odd"><td style="text-align: left;"></td><td style="text-align: left;"><code>c ← b \cdot a \pmod{p};</code></td><td style="text-align: left;">计算 <span class="math inline"><em>c</em> = <em>b</em> ⋅ <em>a</em> (mod  <em>p</em>) = <em>g</em><sup><em>r</em></sup> ⋅ <em>g</em><sup><em>x</em></sup> (mod  <em>p</em>) = <em>g</em><sup><em>r</em> + <em>x</em></sup> (mod  <em>p</em>)</span>。</td><td style="text-align: left;"><strong>原实例 <span class="math inline"><em>a</em></span> 变换为随机实例 <span class="math inline"><em>c</em></span>。</strong></td></tr><tr class="even"><td style="text-align: left;"><strong>III. 确定求解 (<span class="math inline"><em>f</em></span>)</strong></td><td style="text-align: left;"><code>y ← logg,pc;</code></td><td style="text-align: left;">使用<strong>确定性算法</strong> <span class="math inline"><em>l</em><em>o</em><em>g</em><sub><em>g</em>, <em>p</em></sub></span> 求解实例 <span class="math inline"><em>c</em></span>。<strong>目标是找到 <span class="math inline"><em>y</em></span>，使得 <span class="math inline"><em>g</em><sup><em>y</em></sup> ≡ <em>c</em> (mod  <em>p</em>)</span>。</strong></td><td style="text-align: left;"><span class="math inline"><em>y</em></span> 是 <span class="math inline"><em>r</em> + <em>x</em></span> 的解。</td></tr><tr class="odd"><td style="text-align: left;"><strong>IV. 后处理 (<span class="math inline"><em>v</em></span>)</strong></td><td style="text-align: left;"><code>return (y-r) mod (p-1);</code></td><td style="text-align: left;"><span class="math inline"><em>y</em></span> 是 <span class="math inline"><em>r</em> + <em>x</em></span> 的解，所以 <span class="math inline"><em>y</em> ≡ <em>r</em> + <em>x</em> (mod  <em>p</em> − 1)</span>。因此，<span class="math inline"><em>x</em> ≡ <em>y</em> − <em>r</em> (mod  <em>p</em> − 1)</span>。<strong>这是将解 <span class="math inline"><em>y</em></span> 变回 <span class="math inline"><em>x</em></span> 的步骤。</strong></td><td style="text-align: left;">恢复原实例 <span class="math inline"><em>a</em></span> 的解 <span class="math inline"><em>x</em></span>。</td></tr></tbody></table><h3 id="u-和-v-函数的确定">3. <span class="math inline"><em>u</em></span> 和 <span class="math inline"><em>v</em></span> 函数的确定</h3><p>根据 Sherwood 算法的<strong>随机预处理一般方法</strong>：</p><ul><li><strong>原实例 <span class="math inline"><em>x</em></span></strong>: 在离散对数问题中，原实例是<strong>目标值 <span class="math inline"><em>a</em></span></strong>。</li><li><strong>随机变量 <span class="math inline"><em>r</em></span></strong>: 在 <span class="math inline">{0, 1, …, <em>p</em> − 2}</span> 中随机抽取。</li><li><strong>确定性算法 <span class="math inline"><em>f</em></span></strong>: 是 <span class="math inline"><em>l</em><em>o</em><em>g</em><sub><em>g</em>, <em>p</em></sub></span>，即 <span class="math inline"><em>f</em>(<em>a</em>) = <em>x</em></span>。</li></ul><h4 id="预处理函数-u">1. 预处理函数 <span class="math inline"><em>u</em></span></h4><p><span class="math inline"><em>u</em>(<em>a</em>, <em>r</em>)</span> 的作用是将原实例 <span class="math inline"><em>a</em></span> 变换为随机实例 <span class="math inline"><em>c</em></span>。</p><p><span class="math display">$$\text{原实例 } a \xrightarrow{u(a, r)} \text{随机实例 } c$$</span></p><p>根据代码 <span class="math inline"><em>c</em> ← (<em>g</em><sup><em>r</em></sup> (mod  <em>p</em>)) ⋅ <em>a</em> (mod  <em>p</em>)</span>：</p><p><span class="math display"><em>u</em>(<em>a</em>, <em>r</em>) = (<em>g</em><sup><em>r</em></sup> ⋅ <em>a</em>) (mod  <em>p</em>)</span></p><h4 id="后处理函数-v">2. 后处理函数 <span class="math inline"><em>v</em></span></h4><p><span class="math inline"><em>v</em>(<em>r</em>, <em>s</em>)</span> 的作用是将确定性算法的解 <span class="math inline"><em>s</em></span> (即代码中的 <span class="math inline"><em>y</em></span>) 结合随机变量 <span class="math inline"><em>r</em></span>，变换回原实例的解 <span class="math inline"><em>x</em></span>。</p><p><span class="math display">$$\text{随机变量 } r \text{ 和 解 } s \xrightarrow{v(r, s)} \text{原实例的解 } x$$</span></p><p>根据代码 <span class="math inline"><em>x</em> ← (<em>y</em> − <em>r</em>) (mod  <em>p</em> − 1)</span>：</p><p><span class="math display"><em>v</em>(<em>r</em>, <em>s</em>) = (<em>s</em> − <em>r</em>) (mod  <em>p</em> − 1)</span></p><hr /><h3 id="素数判定问题-p124">5.2 素数判定问题 p124</h3><ul><li>方法1：随机因子</li></ul><p><img src="./2025-12-10-15-52-43.png" /> 在 n = 2623 的情况下 <span class="math inline">$2 - \sqrt{2623}$</span>随机选择有98%的概率正确</p><ul><li>方法2：费马小定理的逆否命题</li></ul><p><img src="./2025-12-10-15-55-14.png" /></p><p><img src="./2025-12-10-15-57-53.png" /></p><p>显然这种判定比较不负责（只要有 mod n == 1就是素数 不等于1就不是） 满足<span class="math inline"><em>a</em><sup><em>n</em> − 1</sup><em>m</em><em>o</em><em>d</em> <em>n</em> = 1</span>的数我们称为伪素数</p><p><img src="./2025-12-10-16-00-10.png" /></p><p>也就是说，仅仅使用费马小定理，会有一些合数比较特殊，他们有很多的a做了运算后 均为1。这就迎来了我们的方法3</p><ul><li>方法3： Miller-Rabin测试</li></ul><p><img src="./2025-12-10-16-18-12.png" /></p><p><img src="./2025-12-10-16-21-17.png" /></p><p>判断一个底数 <span class="math inline"><em>a</em></span> 是否为强伪证据： 分解 <span class="math inline"><em>n</em> − 1</span>： 将 <span class="math inline"><em>n</em> − 1</span> 分解为 <span class="math inline">2<sup><em>s</em></sup><em>t</em></span>（<span class="math inline"><em>t</em></span> 为奇数）。 计算初始值： 计算 <span class="math inline"><em>x</em> ← <em>a</em><sup><em>t</em></sup> (mod  <em>n</em>)</span>。 检查条件 ① 和 <span class="math inline"><em>i</em> = 0</span> 的条件 ②： 如果 <span class="math inline"><em>x</em> = 1</span> 或 <span class="math inline"><em>x</em> = <em>n</em> − 1</span>（即 <span class="math inline"><em>a</em><sup><em>t</em></sup> ≡ 1 (mod  <em>n</em>)</span> 或 <span class="math inline"><em>a</em><sup><em>t</em></sup> ≡  − 1 (mod  <em>n</em>)</span>），则 <span class="math inline"><em>a</em></span> 满足条件，返回 <span class="math inline"><em>t</em><em>r</em><em>u</em><em>e</em></span>（<span class="math inline"><em>a</em></span> 是强伪证据）。 循环检查其余的条件 ②： 执行 <span class="math inline"><em>s</em> − 1</span> 次循环，在每次循环中计算 <span class="math inline"><em>x</em> ← <em>x</em><sup>2</sup> (mod  <em>n</em>)</span>（相当于检查 <span class="math inline"><em>a</em><sup>2<sup><em>i</em></sup><em>t</em></sup> (mod  <em>n</em>)</span>）。如果在循环中发现 <span class="math inline"><em>x</em> = <em>n</em> − 1</span>，则满足条件②，返回 <span class="math inline"><em>t</em><em>r</em><em>u</em><em>e</em></span>（<span class="math inline"><em>a</em></span> 是强伪证据）。</p><p>返回 <span class="math inline"><em>f</em><em>a</em><em>l</em><em>s</em><em>e</em></span>：如果所有检查都未通过，则 <span class="math inline"><em>a</em></span> 不是强伪证据。此时 <span class="math inline"><em>a</em></span> 是 <span class="math inline"><em>n</em></span> 是合数的强证据，所以 <span class="math inline"><em>n</em></span> 必定是合数，返回 <span class="math inline"><em>f</em><em>a</em><em>l</em><em>s</em><em>e</em></span>（测试成功）。</p><p>这种方法大大缩减了伪证据数目</p>]]></content>
    
    
    <categories>
      
      <category>course</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>GenAL: Generative Agent for Adaptive Learning</title>
    <link href="/2025/12/10/GenAL-Generative-Agent-for-Adaptive-Learning/"/>
    <url>/2025/12/10/GenAL-Generative-Agent-for-Adaptive-Learning/</url>
    
    <content type="html"><![CDATA[<p><img src="./image.png" /></p><p><img src="./2025-12-10-10-26-20.png" /></p><p><a href="https://ojs.aaai.org/index.php/AAAI/article/view/32038">论文链接</a></p><p>写在前面：</p><p>简单来说，它的核心思想是：<strong>把“推荐题目”这件事变成两个智能体（Agent）之间的配合</strong>。一个负责“宏观思考”（了解学生整体情况），另一个负责“微观教学”（具体挑哪道题）。而且，它不像以前的推荐系统只看题目 ID，它是真的去<strong>读题目的文本内容</strong>，理解题意。</p><h4 id="第一步宏观把脉-全局思考智能体-gta">第一步：宏观把脉 —— 全局思考智能体 (GTA)</h4><p>在推荐新题目之前，系统首先要搞清楚“这个学生现在是什么水平？”。</p><ol type="1"><li><strong>看病历 (Log Memory)</strong>：系统会读取学生过去的答题记录 <span class="math inline">ℋ<sub><em>t</em></sub></span>，不仅看对错，还要看之前做过的题目的<strong>文本内容</strong>。</li><li><strong>做化验 (Educational Tools)</strong>：使用传统的<strong>知识追踪模型 (如 DKT)</strong> 来计算学生对各个知识点的掌握概率（比如“函数”掌握度 60%，“几何”掌握度 80%）[cite: 110, 112]。</li><li><strong>写诊断书 (Reflector)</strong>：这是关键。LLM（大模型）会结合上面的答题记录和掌握概率，生成一份<strong>学生画像 (<span class="math inline"><em>L</em><sub><em>t</em></sub></span>)</strong>。<ul><li>画像里包含：学生的能力评估、学习偏好（比如喜欢抽象题还是应用题）。 *同时，它会反思上一轮推荐得好不好，生成一个新的<strong>推荐策略 (<span class="math inline"><em>R</em><sub><em>t</em></sub></span>)</strong>（比如：“学生基础不牢，下一题应该降低难度，复习前置知识”）。</li></ul></li></ol><h4 id="第二步缩小范围-教学工具-teaching-tools">第二步：缩小范围 —— 教学工具 (Teaching Tools)</h4><p>现在有了策略，但题库里有成千上万道题，不能瞎选。这就需要 <strong>Local Teaching Agent (LTA)</strong> 里的工具来帮忙。</p><ol type="1"><li><strong>查地图 (Knowledge Graph)</strong>：利用<strong>层级知识图谱 (<span class="math inline"><em>G</em></span>)</strong>。</li><li><strong>圈范围</strong>：根据当前要学的知识点，找出它自己以及它的<strong>直接前驱节点</strong>（即学这个知识点之前必须会的那些基础）。</li><li><strong>定候选集</strong>：系统只把属于这些知识点的题目拿出来，形成一个<strong>候选练习集 (<span class="math inline"><em>S</em><sub><em>t</em></sub></span>)</strong>。这就大大缩小了搜索范围，避免大模型产生幻觉或跑题。</li></ol><h4 id="第三步精准决策-推荐器-recommender">第三步：精准决策 —— 推荐器 (Recommender)</h4><p>这是最终做决定的环节。</p><ol type="1"><li><strong>输入信息</strong>：推荐器（也是一个 LLM）接收两个东西：<ul><li>来自第一步的<strong>推荐策略 (<span class="math inline"><em>R</em><sub><em>t</em></sub></span>)</strong>（“要降低难度”）。</li><li>来自第二步的<strong>候选练习集 (<span class="math inline"><em>S</em><sub><em>t</em></sub></span>)</strong> [cite: 169]。</li></ul></li><li><strong>预测下一题 (<span class="math inline"><em>e</em><sub><em>t</em> + 1</sub></span>)</strong>：LLM 结合策略，从候选集里挑出最合适的一道题 [cite: 172]。</li><li><strong>给出理由与预测 (<span class="math inline"><em>F</em><sub><em>t</em> + 1</sub>, <em>A</em><sub><em>t</em> + 1</sub></span>)</strong>：<ul><li>这步很有意思，LLM 不光甩出一道题，还得<strong>解释为什么选这道题</strong>（Reasoning），并且<strong>预测学生能不能做对</strong>。这为下一步的“自我反思”留下了依据 [cite: 175]。</li></ul></li></ol><h4 id="第四步闭环反馈">第四步：闭环反馈</h4><p>学生做完题后，真实结果会和 LLM 的预测结果（<span class="math inline"><em>A</em><sub><em>t</em> + 1</sub></span>）进行对比。如果 LLM 预测学生会做对，结果学生做错了，GTA（第一步那个智能体）就会在下一轮更新策略：“我高估了他，即使是基础题他也做错了，需要更基础的练习”。</p><hr /><h3 id="举个栗子小明的一次函数学习之旅">📝 举个栗子：小明的“一次函数”学习之旅</h3><p>假设现在 <strong>小明</strong> 正在学习初中数学的 <strong>“一次函数 (<span class="math inline"><em>y</em> = <em>k</em><em>x</em> + <em>b</em></span>)”</strong>。</p><p><strong>1. 初始状态 (GTA 工作):</strong> * <strong>记录：</strong> 小明刚做完一道关于“斜率 <span class="math inline"><em>k</em></span>”的题，做错了。 * <strong>工具分析：</strong> 知识追踪模型显示，他对“斜率”的掌握度只有 30%，对“坐标系”掌握度 80%。 * <strong>GTA (大模型) 思考：</strong> “小明虽然懂坐标系，但对斜率的概念很模糊。现在的策略 <span class="math inline"><em>R</em><sub><em>t</em></sub></span> 应该是：<strong>暂停新课，回退一步，先巩固斜率的几何定义。</strong>”</p><p><strong>2. 筛选题目 (Teaching Tools 工作):</strong> * <strong>目标：</strong> 巩固“斜率”。 * <strong>知识图谱：</strong> 查到“斜率”的前置知识是“两点间距离”和“坐标点”。 * <strong>候选集 <span class="math inline"><em>S</em><sub><em>t</em></sub></span>：</strong> 系统从题库里捞出了 50 道相关的题。</p><p><strong>3. 最终推荐 (Recommender 工作):</strong> * <strong>输入：</strong> 策略是“巩固定义，不要太难”，候选集有 50 道题。 * <strong>大模型选择：</strong> 既然不能太难，它排除了那些“给定图像求解析式”的复杂题，选中了一道文字题 <strong><span class="math inline"><em>e</em><sub><em>t</em> + 1</sub></span></strong>： &gt; <em>题目：已知点 A(1, 2) 和点 B(3, 4)，请计算直线 AB 的斜率。</em> * <strong>大模型解释 (<span class="math inline"><em>F</em><sub><em>t</em> + 1</sub></span>):</strong> “推荐这道题是因为它是斜率的最基本计算，直接应用公式，没有复杂的变形，适合当前基础薄弱的小明。” * <strong>预测 (<span class="math inline"><em>A</em><sub><em>t</em> + 1</sub></span>):</strong> “预测他能做对，因为这是基础计算。”</p><p><strong>4. 结果反馈:</strong> * <strong>实际情况：</strong> 小明做对了。 * <strong>下一轮循环：</strong> GTA 看到“预测正确，小明做对了”，于是更新策略：“基础已巩固，下一轮可以尝试稍微难一点的题目，比如结合截距 <span class="math inline"><em>b</em></span> 的考察。”</p><hr /><h3 id="总结">总结</h3><p>GenAL 相比传统推荐系统，最大的亮点在于它<strong>像个真人老师</strong>： 1. 它<strong>读得懂题</strong>（利用 LLM 的语义理解能力）[cite: 14, 26]。 2. 它<strong>有教学逻辑</strong>（先看前置知识，再定难度）。 3. 它<strong>会反思</strong>（每次推荐都要写理由，预测不对就自我修正）。</p><hr /><h1 id="genal-基于生成式智能体的自适应学习框架">📚 GenAL: 基于生成式智能体的自适应学习框架</h1><h2 id="一-当前教育推荐系统存在的问题">一、 当前教育推荐系统存在的问题 🚧</h2><p>论文指出，尽管自适应学习（Adaptive Learning）研究广泛，但现有模型主要依赖于对学习者和练习题的<strong>简单 ID 索引</strong>，导致以下三个核心问题：</p><table><thead><tr class="header"><th style="text-align: left;">问题点</th><th style="text-align: left;">详细描述</th></tr></thead><tbody><tr class="odd"><td style="text-align: left;"><strong>信息利用率不足</strong></td><td style="text-align: left;">传统模型（如基于序列或强化学习的模型）<strong>无法有效利用</strong>练习题的<strong>文本内容</strong>等丰富的语义信息，导致对题目理解肤浅，推荐缺乏深度。</td></tr><tr class="even"><td style="text-align: left;"><strong>泛化性差，难以适应扩展</strong></td><td style="text-align: left;">模型需要针对不同的数据集或不断<strong>扩张的题库</strong>进行重新训练。这使其难以适应在线教育场景中资源快速更新和增长的需求。</td></tr><tr class="odd"><td style="text-align: left;"><strong>稀疏环境下的不稳定</strong></td><td style="text-align: left;">基于训练的强化学习（RL）推荐范式，在学生学习记录<strong>稀疏</strong>或数据量较小时，其推荐性能往往<strong>不稳定</strong>且难以保证效果。</td></tr></tbody></table><hr /><h2 id="二-本文的解决思路与核心方案">二、 本文的解决思路与核心方案 💡</h2><p>本文提出的 <strong>GenAL</strong> 框架旨在通过引入 <strong>大型语言模型 (LLM)</strong>，模仿人类教师的认知与教学过程，从而实现语义驱动、可泛化的自适应学习推荐。</p><table><thead><tr class="header"><th style="text-align: left;">解决思路</th><th style="text-align: left;">具体机制</th><th style="text-align: left;">目标</th></tr></thead><tbody><tr class="odd"><td style="text-align: left;"><strong>分层决策架构</strong></td><td style="text-align: left;">采用<strong>双智能体（Agent）结构，将复杂的教学任务分解：<br>1. 全局思考智能体 (GTA)：制定宏观</strong>教学策略 <span class="math inline"><em>R</em><sub><em>t</em></sub></span>。<br>2. <strong>局部教学智能体 (LTA)</strong>：执行<strong>微观</strong>推荐决策 <span class="math inline"><em>e</em><sub><em>t</em> + 1</sub></span>。</td><td style="text-align: left;">实现教学策略与题目选择的有效解耦和协同。</td></tr><tr class="even"><td style="text-align: left;"><strong>语义驱动推荐</strong></td><td style="text-align: left;">LTA 中的<strong>推荐器（Recommender）是一个 LLM，它直接读取题目内容</strong>的文本信息，并根据 GTA 的策略进行语义级别的推理和选择。</td><td style="text-align: left;">克服传统模型只看 ID 的局限性，实现基于内容的理解推荐。</td></tr><tr class="odd"><td style="text-align: left;"><strong>引入外部知识</strong></td><td style="text-align: left;">LTA 中包含<strong>教学工具（Teaching Tools）</strong>，用于接入教育领域的<strong>先验知识</strong>。</td><td style="text-align: left;">解决 LLM 在特定教育领域的知识短板，避免“幻觉”。</td></tr></tbody></table><hr /><h2 id="三-该思路可能遇到的挑战">三、 该思路可能遇到的挑战 ⚔️</h2><table><thead><tr class="header"><th style="text-align: left;">挑战点</th><th style="text-align: left;">描述</th></tr></thead><tbody><tr class="odd"><td style="text-align: left;"><strong>LLM 的领域幻觉</strong></td><td style="text-align: left;">LLM 在通用领域强大，但在专业的教育知识点上可能缺乏精确性，容易产生不准确的**“幻觉”决策<strong>或</strong>不专业理由**。</td></tr><tr class="even"><td style="text-align: left;"><strong>巨大的搜索空间</strong></td><td style="text-align: left;">如果让 LLM 直接从整个题库中挑选 <span class="math inline"><em>e</em><sub><em>t</em> + 1</sub></span>，其<strong>计算和时间成本不可接受</strong>，效率极低。</td></tr><tr class="odd"><td style="text-align: left;"><strong>缺乏教学闭环与自我修正</strong></td><td style="text-align: left;">缺乏将 LLM 的推荐决策与学生的<strong>真实反馈</strong>进行对比、反思和迭代修正的机制，难以保证教学策略的<strong>长期稳定性</strong>和<strong>有效性</strong>。</td></tr></tbody></table><hr /><h2 id="四-本文克服挑战的手段">四、 本文克服挑战的手段 🛠️</h2><p>GenAL 框架通过设计精巧的工具和反思机制，系统性地解决了上述挑战：</p><table><thead><tr class="header"><th style="text-align: left;">挑战</th><th style="text-align: left;">克服手段</th><th style="text-align: left;">实现细节</th></tr></thead><tbody><tr class="odd"><td style="text-align: left;"><strong>领域幻觉与搜索空间</strong></td><td style="text-align: left;"><strong>知识图谱指导与搜索空间限制</strong></td><td style="text-align: left;"><strong>教学工具（Teaching Tools）</strong>：利用<strong>分层知识图谱</strong> <span class="math inline"><em>G</em></span> 来<strong>限制</strong>推荐范围。候选集 <span class="math inline"><em>S</em><sub><em>t</em></sub></span> 只包括当前目标知识点及其<strong>直接前驱节点</strong>相关的练习题。这既缩小了搜索空间，又用结构化知识<strong>校准了 LLM</strong>。</td></tr><tr class="even"><td style="text-align: left;"><strong>缺乏教学闭环</strong></td><td style="text-align: left;"><strong>反思与预测机制</strong></td><td style="text-align: left;"><strong>推荐器（Recommender）</strong>：强制要求 LLM 在推荐 <span class="math inline"><em>e</em><sub><em>t</em> + 1</sub></span> 的同时，生成推荐<strong>理由</strong> (<span class="math inline"><em>F</em><sub><em>t</em> + 1</sub></span>) 和对学生作答的<strong>预测</strong> (<span class="math inline"><em>A</em><sub><em>t</em> + 1</sub></span>)。<br><strong>全局思考智能体（GTA）</strong>：负责将 <span class="math inline"><em>A</em><sub><em>t</em> + 1</sub></span> 与学生<strong>实际作答</strong>进行对比，通过**反思器（Reflector）<strong>生成新的反思总结 <span class="math inline"><em>L</em><sub><em>t</em></sub></span>，并更新下一轮的教学策略 <span class="math inline"><em>R</em><sub><em>t</em> + 1</sub></span>，形成</strong>“观察-反思-规划-行动”**的闭环。</td></tr></tbody></table><hr /><h2 id="五-实验论证优越性">五、 实验论证优越性 🏆</h2><p>本文通过在实际教育数据集上的对比实验和消融实验，全面论证了 GenAL 框架的优越性：</p><ol type="1"><li><p><strong>推荐有效性 (Recommendation Effectiveness)</strong>：</p><ul><li><strong>结果：</strong> GenAL 在评估自适应推荐效率的指标（如通过更少的问题达成目标知识掌握度）上，<strong>显著优于</strong>传统的序列推荐模型和基于 RL 的推荐模型。</li><li><strong>论证：</strong> 证明了其策略制定和题目选择更高效，能加速学生的学习路径。</li></ul></li><li><p><strong>知识追踪准确性 (Knowledge Tracing Accuracy)</strong>：</p><ul><li><strong>指标：</strong> 使用 <span class="math inline">AUC</span> 和 <span class="math inline">ACC</span> 等指标评估模型对学生<strong>下一个问题作答对错的预测能力</strong>。</li><li><strong>结果：</strong> GenAL 达到了<strong>最高的预测准确率</strong>，表明其能更精确地理解学生的实时学习状态。</li></ul></li><li><p><strong>消融实验 (Ablation Study)</strong>：</p><ul><li>通过移除关键组件（如知识图谱、反思机制），实验结果显示性能大幅下降。</li><li><strong>论证：</strong> 证明了<strong>知识图谱</strong>是克服 LLM 幻觉的关键，而<strong>反思机制</strong>则是保障 GenAL 长期、稳定、高效推荐的根本保障。</li></ul></li></ol>]]></content>
    
    
    <categories>
      
      <category>AAAI2025</category>
      
    </categories>
    
    
  </entry>
  
  
  
  
</search>
