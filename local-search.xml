<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>TURNING UP THE HEAT: MIN-p SAMPLING FOR CREATIVE AND COHERENT LLM OUTPUTS</title>
    <link href="/2025/12/21/TURNING-UP-THE-HEAT-MIN-p-SAMPLING-FOR-CREATIVE-AND-COHERENT-LLM-OUTPUTS/"/>
    <url>/2025/12/21/TURNING-UP-THE-HEAT-MIN-p-SAMPLING-FOR-CREATIVE-AND-COHERENT-LLM-OUTPUTS/</url>
    
    <content type="html"><![CDATA[<h2 id="研究背景">研究背景</h2><p>  在 LLM 的文本生成过程中，核心挑战在于如何在 “创造性 ” 和 “连贯性 ” 之间取得平衡。(其实就是之前提到的 Diversity 和 Quality 只是换了个说法)</p><p>现有的采样方法：</p><ul><li>Temperature (温度系数)： 提高温度（例如 $T &gt; 1.0$）可以增加多样性，但会使概率分布变平坦；降低温度可以增加确定性，但会使概率分布变尖锐。Temperature的本质就是把原来的softmax()增加一个T的缩放因子。<br>$$P_i = \frac{\exp(Logit_i / T)}{\sum \exp(Logit_j / T)}$$</li></ul><table><thead><tr><th>场景</th><th>温度设置 ()</th><th>候选词 A (高概率词)</th><th>候选词 B (中概率词)</th><th>候选词 C (低概率词)</th></tr></thead><tbody><tr><td><strong>原始得分 (Logits)</strong></td><td>(未缩放)</td><td><strong>2.0</strong></td><td><strong>1.0</strong></td><td><strong>-1.0</strong></td></tr><tr><td><strong>低温 (保守)</strong></td><td>T = 0.1</td><td><strong>99.99%</strong></td><td><strong>0.01%</strong></td><td><strong>0.00%</strong></td></tr><tr><td><strong>标准 (默认)</strong></td><td>T = 1.0</td><td><strong>70.53%</strong></td><td><strong>25.95%</strong></td><td><strong>3.52%</strong></td></tr><tr><td><strong>高温 (创意)</strong></td><td>T = 2.0</td><td><strong>44.91%</strong></td><td><strong>27.25%</strong></td><td><strong>27.84%</strong></td></tr></tbody></table><ul><li><p>Top-p (Nucleus Sampling)： 先把所有的output概率从大到小排序，再选取累积概率达到 $p$ 的前几个词。在高温度下，由于长尾分布变平，Top-p 仍然会把许多低概率、不连贯的词纳入候选池，导致生成质量崩塌。Top-p的本质就是设置了一个累计的概率阈值：<br><img src="./2025-12-21-15-15-49.png" alt=""></p></li><li><p>Top-k： 强制只选前 $k$ 个词。这是一种静态截断，无法根据模型对当前上下文的“信心”动态调整，缺乏灵活性 。</p></li></ul><p>核心痛点： 现有的方法在高温度设置下，很难在保持逻辑连贯的同时提供高质量的创造性输出，且做不到动态调整。</p><h2 id="解决方法">解决方法</h2><p>  为了解决这些痛点，本文提出了Min-p 采样。该采样方法解决了以下问题：</p><ul><li>即使在极高温度（如 $T=3.0$）下，Min-p 也能过滤掉那些相对于“最佳候选词”概率过低的词，从而防止模型胡言乱语。</li><li>解决了 Top-k 和 Top-p 对“模型确定性”不敏感的问题。Min-p 能根据模型是“非常确定”（高置信度）还是“犹豫不决”（低置信度）来自动收缩或放宽候选词的选择范围。</li><li>计算复杂度与易用性： 相比于 Mirostat 或 $\eta$-sampling 等基于熵的复杂采样方法，Min-p 非常简单，几乎不增加推理计算成本，且易于集成 。</li></ul><p>  Min-p 的核心思想是基于模型对首选词的“信心”来进行动态截断。算法逻辑在每个解码步骤 $t$，假设模型预测的词表概率分布为 $P(x)$：找到最大概率： 找出当前最可能的那个词的概率值，记为 $p_{max}$ 。<br>$$p_{max} = \max_{v \in V} P(v|x_{1:t-1})$$</p><p>  计算截断阈值： 设定一个基础超参数 $p_{base}$（通常为 0.05 或 0.1），实际的过滤阈值 $p_{scaled}$ 是两者的乘积。<br>$$p_{scaled} = p_{base} \times p_{max}$$</p><p>  构建候选池： 只有概率值大于等于 $p_{scaled}$ 的词才会被保留，其他的全部剔除。<br>$$\mathcal{V}<em>{min} = {v \in \mathcal{V} : P(v|x</em>{1:t-1}) \ge p_{scaled}}$$</p><p>  重归一化与采样： 在剩下的候选词中进行归一化并采样 。</p><p>  如果模型觉得下一个词是“Apple”的概率是 90% ($p_{max}=0.9$)，且 $p_{base}=0.1$，那么阈值就是 $0.09$。所有概率低于 9% 的词都会被丢弃。这迫使模型专注于高概率词，保持连贯。如果模型觉得下一个词概率都很低，最高的也才 10% ($p_{max}=0.1$)，那么阈值就变成了 $0.01$。这样更多低概率的词就有机会入选，增加了创造性和多样性。</p><p>  使用一张图片解释这个采样方法的优势：如图(a, c)，在高确定性的场景下，top-p方法会引入很多小概率的token，导致low quality，但是min-p方法可以过滤掉这些小概率tokne。如图(b, d)，在低确定性的场景下，top-k方法会忽略掉很多高概率的token，导致low diversity，但是min-p方法不会忽略他们。<br><img src="./2025-12-21-15-25-48.png" alt=""></p><h2 id="实验论证">实验论证</h2><p>实验设置：</p><ul><li>测试模型： Mistral 7B, Llama 3 (8B/70B), Mistral Large (123B)</li><li>对比基线： Top-p (p=0.9/0.95), Top-k, $\eta$-sampling, Mirostat, 单纯 Temperature 采样</li><li>超参数： Min-p 设置为 $p_{base} \in {0.05, 0.1}$；Top-p 设置为 $0.9$ 或 $0.95$。</li><li>温度范围： 测试了从 $0.7$ 到 $3.0$ 甚至更高的温度范围</li></ul><h3 id="Mistral-7B在GPQA-GSM8K上的测试">Mistral 7B在GPQA GSM8K上的测试</h3><p>  Mistral 7B 在不同温度下的准确率：在常规温度（$T \le 1.0$）下，Min-p 与 Top-p 表现相当。在高温度（$T=1.5, 2.0, 3.0$）下，Top-p 的性能迅速崩溃，而 Min-p 仍然能保持较高的准确率。例如在 GSM8K CoT 任务中，当 $T=3.0$ 时，Top-p 得分为 0.00%，而 Min-p 仍有 6.21% 的得分，甚至在 $T=1.5$ 时 Min-p 还能达到 30% 以上的准确率，远超其他方法。<br><img src="./2025-12-21-15-06-36.png" alt=""></p><p>  绘制GSM8K CoT 任务中“准确率 (Accuracy)”与“多样性 (Diversity/Entropy)”的对比。图中绿色曲线（Min-p）始终位于灰色曲线（Top-p）的右上方。这说明在相同的准确率下，Min-p 能提供更高的多样性；或者在相同的多样性下，Min-p 能保持更高的准确率。<br><img src="./2025-12-21-15-07-39.png" alt=""></p><h3 id="Llama3-70B在故事生成任务上的测试-人工评估">Llama3 70B在故事生成任务上的测试 (人工评估)</h3><p>  使用 Llama 3 70B 生成故事，人类评价者根据“质量”和“多样性”打分（1-10分）。结果：在 $T=3.0$ 的极端设置下，Top-p 的质量得分跌至 ~1.2/10（完全不可读），而 Min-p 依然保持在 ~5.8/10，且多样性得分也更高 24。人类评估者在盲测中更倾向于认为 Min-p 生成的文本既有创意又逻辑通顺。<br><img src="./2025-12-21-15-09-11.png" alt=""></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>ICLR2025</title>
    <link href="/2025/12/20/ICLR2025/"/>
    <url>/2025/12/20/ICLR2025/</url>
    
    <content type="html"><![CDATA[<h3 id="iclr-2025-论文阅读总结">ICLR 2025 论文阅读总结</h3><table><thead><tr class="header"><th>标题</th><th>URL</th><th>摘要</th><th>status</th></tr></thead><tbody><tr class="odd"><td><strong>Reasoning Elicitation in Language Models via Counterfactual Feedback</strong></td><td><a href="https://papers.cool/venue/VVixJ9QavY@OpenReview">link</a></td><td>提出反事实反馈机制，通过平衡事实与反事实问题的指标来增强 LLM 的因果推理能力。</td><td></td></tr><tr class="even"><td><strong>ReGenesis: LLMs can Grow into Reasoning Generalists via Self-Improvement</strong></td><td><a href="https://papers.cool/venue/YUYJsHOf3c@OpenReview">link</a></td><td>提出 ReGenesis 框架，通过从抽象到具体的自我合成推理路径，使模型在无监督下提升泛化推理能力。</td><td></td></tr><tr class="odd"><td><strong>Trust or Escalate: LLM Judges with Provable Guarantees for Human Agreement</strong></td><td><a href="https://papers.cool/venue/UHPnqSTBPO@OpenReview">link</a></td><td>提出选择性评估框架，通过置信度估计确保 LLM 裁判与人类评价的一致性，不确定时升级到更强模型。</td><td></td></tr><tr class="even"><td><strong>Do LLMs Recognize Your Preferences? Evaluating Personalized Preference Following in LLMs</strong></td><td><a href="https://papers.cool/venue/QWunLKbBGF@OpenReview">link</a></td><td>推出 PrefEval 基准测试，评估模型在长对话中推理、记忆和遵循用户个性化偏好的能力。</td><td></td></tr><tr class="odd"><td><strong>MAP: Multi-Human-Value Alignment Palette</strong></td><td><a href="https://papers.cool/venue/NN6QHwgRrQ@OpenReview">link</a></td><td>提出多人类价值对齐调色板（MAP），利用约束优化技术解决多样化且动态的人类价值对齐问题。</td><td></td></tr><tr class="even"><td><strong>Turning Up the Heat: Min-p Sampling for Creative and Coherent LLM Outputs</strong></td><td><a href="https://papers.cool/venue/FBkpCyujtS@OpenReview">link</a></td><td>提出 min-p 采样方法，根据模型置信度动态调整阈值，在提升生成创造性的同时保持连贯性。</td><td></td></tr><tr class="odd"><td><strong>Backtracking Improves Generation Safety</strong></td><td><a href="https://papers.cool/venue/Bo62NeU6VF@OpenReview">link</a></td><td>引入 [RESET] 令牌实现回溯技术，允许模型撤销并纠正已生成的有害文本，显著提升安全性。</td><td></td></tr><tr class="even"><td><strong>From Exploration to Mastery: Enabling LLMs to Master Tools via Self-Driven Interactions</strong></td><td><a href="https://papers.cool/venue/QKBu1BOAwd@OpenReview">link</a></td><td>提出 DRAFT 框架，通过 LLM 与工具的自我驱动交互（试错与反馈）来动态优化工具文档。</td><td></td></tr><tr class="odd"><td><strong>Mind the Gap: Examining the Self-Improvement Capabilities of Large Language Models</strong></td><td><a href="https://papers.cool/venue/mtJSMcF3ek@OpenReview">link</a></td><td>研究 LLM 自我改进的数学机理，发现“生成-验证差距”与预训练算力规模之间存在单调比例关系。</td><td></td></tr><tr class="even"><td><strong>Linear Representations of Political Perspective Emerge in Large Language Models</strong></td><td><a href="https://papers.cool/venue/rwqShzb9li@OpenReview">link</a></td><td>揭示 LLM 内部存在政治立场的线性表征，并展示了如何通过干预特定注意力头来控制输出倾向。</td><td></td></tr><tr class="odd"><td><strong>Self-Improvement in Language Models: The Sharpening Mechanism</strong></td><td><a href="https://papers.cool/venue/WJaUkwci9o@OpenReview">link</a></td><td>提出“锐化”理论视角，利用模型的验证能力在后训练阶段优化生成分布，降低推理成本。</td><td></td></tr><tr class="even"><td><strong>A Decade’s Battle on Dataset Bias: Are We There Yet?</strong></td><td><a href="https://papers.cool/venue/SctfBCLmWo@OpenReview">link</a></td><td>重新审视数据集偏差，发现现代模型仍能轻易识别图像所属数据集，暗示数据偏差问题依然严峻。</td><td></td></tr><tr class="odd"><td><strong>Limits to scalable evaluation at the frontier: LLM as judge won’t beat twice the data</strong></td><td><a href="https://papers.cool/venue/NO6Tv6QcDs@OpenReview">link</a></td><td>论证了“LLM 作为裁判”的理论极限，指出当裁判能力不足时，无法通过算法手段显著减少对人工标签的需求。</td><td></td></tr></tbody></table>]]></content>
    
    
    <categories>
      
      <category>ICLR2025</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>科研想法汇总</title>
    <link href="/2025/12/20/%E7%A7%91%E7%A0%94%E6%83%B3%E6%B3%95%E6%B1%87%E6%80%BB/"/>
    <url>/2025/12/20/%E7%A7%91%E7%A0%94%E6%83%B3%E6%B3%95%E6%B1%87%E6%80%BB/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>LLM 主流测试标准调研</title>
    <link href="/2025/12/19/LLM-%E4%B8%BB%E6%B5%81%E6%B5%8B%E8%AF%95%E6%A0%87%E5%87%86%E8%B0%83%E7%A0%94/"/>
    <url>/2025/12/19/LLM-%E4%B8%BB%E6%B5%81%E6%B5%8B%E8%AF%95%E6%A0%87%E5%87%86%E8%B0%83%E7%A0%94/</url>
    
    <content type="html"><![CDATA[<h2 id="总结">总结</h2><p>  本文介绍了目前主流的测试LLM性能的benchmarks</p><table><thead><tr class="header"><th>数据集名称</th><th>测试主题</th><th>测试方法</th><th>资源链接</th></tr></thead><tbody><tr class="odd"><td><strong>GPQA</strong></td><td>专家级科学 (生物、物理、化学)</td><td>448道由博士生水平专家编写的高难度选择题。</td><td><a href="https://arxiv.org/abs/2311.12022">Paper</a> / <a href="https://huggingface.co/datasets/Idavidrein/gpqa">Dataset</a></td></tr><tr class="even"><td><strong>AIME 2025</strong></td><td>竞赛数学</td><td>包含美国邀请数学考试（AIME）2025年的真题，侧重深度数学推理。</td><td><a href="http://huggingface.co/datasets/opencompass/AIME2025">Dataset</a></td></tr><tr class="odd"><td><strong>SWE-bench</strong></td><td>软件工程 / 代码修复</td><td>给予问题描述，要求 AI 修改仓库代码并<strong>通过单元测试</strong>（Fail-to-Pass 模式）。</td><td><a href="https://huggingface.co/datasets/SWE-bench/SWE-bench">Dataset</a></td></tr><tr class="even"><td><strong>HLE</strong> (Humanity’s Last Exam)</td><td>跨学科前沿知识 (多模态)</td><td>2500道涵盖数学、人文、自然科学的<strong>前沿专家级</strong>选择题与简答题。</td><td><a href="https://huggingface.co/datasets/cais/hle">Dataset</a></td></tr><tr class="odd"><td><strong>MMLU</strong></td><td>通用世界知识 (多任务)</td><td>涵盖57个学科（人文、社科、STEM等），共11.6万道多项选择题。</td><td><a href="https://huggingface.co/datasets/cais/mmlu">Dataset</a></td></tr><tr class="even"><td><strong>Math-500</strong></td><td>高难度数学推理</td><td>从 MATH 数据集中精选出的 500 道高难度竞赛级数学题。</td><td><a href="https://huggingface.co/datasets/HuggingFaceH4/MATH-500">Dataset</a></td></tr><tr class="odd"><td><strong>IFBench</strong></td><td>指令遵循 (Instruction Following)</td><td>自动化评估模型在满足特定约束（格式、字数、语言等）下的表现。</td><td><a href="https://huggingface.co/datasets/allenai/IF_multi_constraints_upto5">Dataset</a></td></tr><tr class="even"><td><strong>GLUE</strong></td><td>通用自然语言理解 (NLU)</td><td>集合了多种基础语言任务（情感分析、文本蕴含等）的综合评价标准。</td><td><a href="https://huggingface.co/datasets/nyu-mll/glue">Dataset</a></td></tr><tr class="odd"><td><strong>GSM8K</strong></td><td>小学数学应用题</td><td>8500道需要 2-8 步<strong>多步算术推理</strong>的应用题，以自然语言解答。</td><td><a href="https://huggingface.co/datasets/openai/gsm8k">Dataset</a></td></tr><tr class="even"><td><strong>HumanEval</strong></td><td>代码生成 (Python)</td><td>164个编程问题，要求编写代码并<strong>通过自动化单元测试</strong>。</td><td><a href="https://huggingface.co/datasets/openai/openai_humaneval">Dataset</a></td></tr></tbody></table><hr /><h3 id="gpqa">GPQA</h3><p>paper: https://arxiv.org/abs/2311.12022 dataset:https://huggingface.co/datasets/Idavidrein/gpqa</p><p>  GPQA，这是一个由生物学、物理和化学领域专家编写的 448 道选择题的复杂数据集。拥有或正在攻读相关领域博士学位的专家准确率为 65%（扣除专家事后识别的明显错误后为 74%），而高技能的非专家验证者即使平均在无限制访问网络上花费超过 30 分钟。</p><ul><li>case   Two quantum states with energies E1 and E2 have a lifetime of 10^-9 sec and 10^-8 sec, respectively. We want to clearly distinguish these two energy levels. Which one of the following options could be their energy difference so that they be clearly resolved?   能量分别为 E1 和 E2 的两个量子态的寿命分别为 10^-9 秒和 10^-8 秒。我们希望能够清晰地区分这两个能级。下列哪个选项可能是它们之间的能量差，以便能够清晰地区分它们？ <img src="./2025-12-19-23-33-02.png" /></li></ul><hr /><h3 id="aime2025">AIME2025</h3><p>dataset: http://huggingface.co/datasets/opencompass/AIME2025</p><p>  该数据集包含了美国邀请数学考试（AIME）2025-I 和 II 的题目。主要测试LLM的math能力。</p><ul><li>case:   On <span class="math inline">△<em>A</em><em>B</em><em>C</em></span> points <span class="math inline"><em>A</em>, <em>D</em>, <em>E</em></span>, and <span class="math inline"><em>B</em></span> lie that order on side <span class="math inline">$\overline{AB}$</span> with <span class="math inline"><em>A</em><em>D</em> = 4, <em>D</em><em>E</em> = 16</span>, and <span class="math inline"><em>E</em><em>B</em> = 8</span>. Points <span class="math inline"><em>A</em>, <em>F</em>, <em>G</em></span>, and <span class="math inline"><em>C</em></span> lie in that order on side <span class="math inline">$\overline{AC}$</span> with <span class="math inline"><em>A</em><em>F</em> = 13, <em>F</em><em>G</em> = 52</span>, and <span class="math inline"><em>G</em><em>C</em> = 26</span>. Let <span class="math inline"><em>M</em></span> be the reflection of <span class="math inline"><em>D</em></span> through <span class="math inline"><em>F</em></span>, and let <span class="math inline"><em>N</em></span> be the reflection of <span class="math inline"><em>G</em></span> through <span class="math inline"><em>E</em></span>. Quadrilateral <span class="math inline"><em>D</em><em>E</em><em>G</em><em>F</em></span> has area 288. Find the area of heptagon <span class="math inline"><em>A</em><em>F</em><em>N</em><em>B</em><em>C</em><em>E</em><em>M</em></span>.   在三角形 ABC 上，点 A、D、E、B 按顺序位于边 AB 上，且 AD=4，DE=16，EB=8。点 A、F、G、C 按顺序位于边 AC 上，且 AF=13，FG=52，GC=26。设 M 为点 D 关于点 F 的反射，N 为点 G 关于点 E 的反射。四边形 DEGF 的面积为 288。求七边形 AFNBCEM 的面积。588 <img src="./2025-12-19-23-37-18.png" /></li></ul><h3 id="swe-bench">SWE-bench</h3><p>dataset: https://huggingface.co/datasets/SWE-bench/SWE-bench</p><p>  该数据集来自于12 个主流 Python 仓库爬取拉取请求和问题，收集了 2,294 个任务实例。每个实例基于一个拉取请求，（1）与某个问题相关，（2）修改的 1+测试相关文件。每个实例，构建一个执行环境（Docker Image），仓库在拉取请求所基于的提交处成功安装。没有拉取请求的更改，许多测试失败。拉取请求合并后，同样的测试集通过。这些“失败通过”测试是评估的主要信号。</p><p>  SWE-bench 评估的工作原理如下。每个任务实例，给 AI 系统一个问题文本。随后 AI 系统应修改代码库以解决描述的问题。当 AI 系统完成后，我们运行上述失败-通过测试，以检查问题是否成功解决。 <img src="./2025-12-19-23-39-37.png" /></p><h3 id="humanitys-last-exam">Humanity’s Last Exam</h3><p>dataset: https://huggingface.co/datasets/cais/hle</p><p>  人类最后考试（HLE）是一个位于人类知识前沿的多模态基准，旨在成为同类中最后一个封闭式学术基准，涵盖广泛学科。人类最后考试包含 2500 道题目，涵盖数十个学科，包括数学、人文学科和自然科学。HLE 由全球各学科专家开发，包含适合自动评分的选择题和简答题。他的题目分布如下： <img src="./2025-12-19-23-41-04.png" /></p><ul><li>case <img src="./2025-12-19-23-42-48.png" /></li></ul><h3 id="mmlu">MMLU</h3><p>dataset: https://huggingface.co/datasets/cais/mmlu</p><p>  这是一个庞大的多任务测试，包含来自不同知识领域的多项选择题。该考试涵盖人文学科、社会科学、理科以及其他对某些人来说重要的领域。课程涵盖57项任务，包括基础数学、美国历史、计算机科学、法律等, 一共116K道题目。为了在该测试中获得高准确性，模型必须具备广泛的世界知识和解决问题的能力。</p><ul><li>case: <img src="./2025-12-19-23-43-59.png" /></li></ul><h3 id="math500">Math500</h3><p>dataset: https://huggingface.co/datasets/HuggingFaceH4/MATH-500</p><p>  MATH-500基准测试由OpenAI于2023年推出，作为评估其最新模型（如GPT-4o）数学能力的工具。该基准测试包含500道高难度的数学竞赛题目，旨在挑战模型的极限，评估其在复杂数学问题上的推理和解题能力。</p><ul><li>case: <img src="./2025-12-19-23-44-25.png" /></li></ul><h3 id="ifbench">IFBench</h3><p>dataset: https://huggingface.co/datasets/allenai/IF_multi_constraints_upto5</p><p>  大语言模型的“指令跟随”能力，是评价模型是否能够按照人类需求输出的重要指标。与一般的问答不同，指令往往包含多种约束，例如输出字数、格式、语言、是否禁止某些词、是否必须包含特定结构等。IFBench就是通过这些约束，自动化评估LLM指令遵循能力的Benchmark。</p><ul><li>case <img src="./2025-12-19-23-46-46.png" /></li></ul><h3 id="glue">GLUE</h3><p>dataset: https://huggingface.co/datasets/nyu-mll/glue</p><p>  GLUE, the General Language Understanding Evaluation benchmark，是一套用于训练、评估和分析自然语言理解系统的资源集合。</p><ul><li>case <img src="./2025-12-19-23-52-40.png" /></li></ul><h3 id="gsm8k">GSM8K</h3><p>dataset: https://huggingface.co/datasets/openai/gsm8k</p><p>  GSM8K（Grade School Math 8K）是一个包含 8500 道高质量、语言多样化的小学数学应用题的数据集。该数据集旨在支持对需要多步骤推理的基础数学问题进行问答的任务。</p><p>  这些问题需要 2 到 8 个步骤才能解决。解决方案主要涉及使用基本算术运算（+ − ×÷）进行一系列初等计算，以得出最终答案。一个聪明的中学生应该能够解决所有问题：试卷中写道，“这些问题不需要超出初级代数水平的概念，而且绝大多数问题无需明确定义变量即可解决。”解决方案以自然语言而非纯数学表达式的形式提供。论文中写道：“我们认为这是最通用的数据格式，并期望它能揭示大型语言模型内部独白的特性。”</p><ul><li>case <img src="./2025-12-19-23-55-08.png" /></li></ul><h3 id="humaneval">HumanEval</h3><p>dataset: https://huggingface.co/datasets/openai/openai_humaneval</p><p>  OpenAI 发布的 HumanEval 数据集包含 164 个编程问题，每个问题都包含函数签名、特性、文档字符串、函数体以及若干单元测试。LLM需要根据问题编写代码，并通过单元测试。</p><ul><li>case <img src="./2025-12-19-23-56-32.png" /></li></ul>]]></content>
    
    
    <categories>
      
      <category>benchmark</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Does Reinforcement Learning Really Incentivize Reasoning Capacity in LLMs Beyond the Base Model?</title>
    <link href="/2025/12/17/Does-Reinforcement-Learning-Really-Incentivize-Reasoning-Capacity-in-LLMs-Beyond-the-Base-Model/"/>
    <url>/2025/12/17/Does-Reinforcement-Learning-Really-Incentivize-Reasoning-Capacity-in-LLMs-Beyond-the-Base-Model/</url>
    
    <content type="html"><![CDATA[<h2 id="阅读总结">阅读总结</h2><p>  本文深入分析了RLVR(LLM训练中使用的RL算法)对模型表现的真实作用，指出<strong>RL虽然提升了模型的表现，但是没有提高模型的upper bound</strong>。本文重点贡献在于做了非常详实的实验证明这一论点。实验包括：</p><ul><li>统计LLM在pass@k的情况下的表现，用数据论证</li><li>使用不同的强化学习算法训练base model对比性能</li></ul><h2 id="把avgk-变成passk">把avg@k 变成pass@k</h2><p>  过去的测试LLM performance的方式：让LLM跑1000道题目，输出正确就记1分，计算正确率。本文为了测试LLM能力的边界，采用pass@k的测试方法：模型做K次，只要有1次做对就算对吗，这代表了模型能力的边界。   把测试改成pass@k之后发现，LLM在k值比较大的时候，表现反而不如base model。进一步在各个模型(Qwen LLaMa)和各个测试的benchmark(AIME24 MATH500..)上实验，也发现类似的现象。 <img src="./2025-12-17-22-42-47.png" /> <img src="./2025-12-17-22-43-34.png" />   对base model和经过rl的model回答问题的情况做分类，分为4类：base和rl都能做对/base能做对rl做不对/base做不对rl做对/base rl都做不对。发现base能做对的rl做不对，强化学习反而降低了模型的表现。 <img src="./2025-12-17-22-45-36.png" /></p><h2 id="使用不同的强化学习算法训练">使用不同的强化学习算法训练</h2><p>  发现RL算法只能提高k比较小的情况下的表现，随着k的增大，LLM的表现有一个upper bound，而且这个upper bound和base model是一样的。用人话说就是：RL的过程没有提高LLM的upper bound，只是让LLM能够尽可能少的K次尝试，就能回答正确。(这个发现说明：RL确实能够提升模型的表现，只是提升不了模型的upper bound)。 <img src="./2025-12-17-22-59-17.png" /></p><h2 id="discussion">Discussion</h2><p>  在RL领域中，AlphaGO非常出名。作为一个使用纯强化学习训练的围棋AI，AlphaGO能够下出来人类棋手意料之外的位置。这表明AlphaGO通过强化学习拓宽了现有围棋知识的边界。   为什么RLVR不能够拓宽LLM能力的边界呢？这是因为RLVR并不等于RL，相比于RL他有一些缺陷：</p><ul><li>搜索空间很大: 相比于围棋的搜索空间，语言的搜索空间很大，模型随机采样是大概率得不到正确答案，也没有reward。这就是为什么现有的RL都依赖于一个比较强大的Pre-Train model。因为需要base model来引导，才能在广大的空间里面，输出一个正确的答案。</li><li>sparse reward: LLM只有输出正确答案的时候才有reward，其他情况都是0。假设模型在RL过程中通过探索，生成了一个answer。这个answer大概率是没有reward的，这种探索边界的行为大概率会被抑制。 <img src="./2025-12-17-23-06-43.png" /> <img src="./2025-12-17-23-06-59.png" /></li></ul>]]></content>
    
    
    <categories>
      
      <category>NeurIPS2025</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>一些工作感想</title>
    <link href="/2025/12/16/%E4%B8%80%E4%BA%9B%E5%B7%A5%E4%BD%9C%E6%84%9F%E6%83%B3/"/>
    <url>/2025/12/16/%E4%B8%80%E4%BA%9B%E5%B7%A5%E4%BD%9C%E6%84%9F%E6%83%B3/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>混合分布的概述</title>
    <link href="/2025/12/16/%E6%B7%B7%E5%90%88%E5%88%86%E5%B8%83%E7%9A%84%E6%A6%82%E8%BF%B0/"/>
    <url>/2025/12/16/%E6%B7%B7%E5%90%88%E5%88%86%E5%B8%83%E7%9A%84%E6%A6%82%E8%BF%B0/</url>
    
    <content type="html"><![CDATA[<h2 id="我的评价">我的评价</h2><p>  有时候我都在想，这么抽象的方法真的有人用吗？？</p><h2 id="什么是混合模型">什么是混合模型？</h2><p>  混合模型指的是，你的数据的分布，可能是来源于其他的分布按照一定的比例混合而成的。说人话，就是数据分布是由一组分布混合而成。如果你从里面采样一个数据，实际操作是先按照<span class="math inline"><em>π</em><sub><em>k</em></sub></span>采样一个分布，再从这个分布中采样数据。(数据只能属于一组分布之一) <span class="math display">$$p(x) = \sum_{k=1}^{K} \pi_k p(x | z=k)$$</span> <span class="math inline"><em>K</em></span> 是混合分量的数量。<span class="math inline"><em>π</em><sub><em>k</em></sub></span> 是混合权重（或先验概率），<span class="math inline">$\sum_{k=1}^{K} \pi_k = 1$</span> 且 <span class="math inline"><em>π</em><sub><em>k</em></sub> ≥ 0</span>。<span class="math inline"><em>p</em>(<em>x</em>|<em>z</em> = <em>k</em>)</span> 是第 <span class="math inline"><em>k</em></span> 个混合分量的条件概率密度函数。<span class="math inline"><em>z</em></span> 是隐变量 (Latent Variable)，表示数据点 <span class="math inline"><em>x</em></span> 来源于哪个分量 (<span class="math inline"><em>z</em> ∈ {1, 2, …, <em>K</em>}</span>)。</p><h2 id="gaussian-mixture-model-gmm">Gaussian Mixture Model (GMM)</h2><p>  顾名思义，在 GMM 中，每个分量 <span class="math inline"><em>k</em></span> 的条件概率密度函数 <span class="math inline"><em>p</em>(<em>x</em>|<em>z</em> = <em>k</em>)</span> 都是一个正态分布（根据你的data dimension可能是多维正态分布）。 <span class="math display">$$p(\mathbf{x}) = \sum_{k=1}^{K} \pi_k \mathcal{N}(\mathbf{x} | \boldsymbol{\mu}_k, \boldsymbol{\Sigma}_k)$$</span> <span class="math inline">𝒩(<strong>x</strong>|<strong>μ</strong><sub><em>k</em></sub>, <strong>Σ</strong><sub><em>k</em></sub>)</span>: 第 <span class="math inline"><em>k</em></span> 个高斯分量的概率密度函数，由其均值向量 <span class="math inline"><strong>μ</strong><sub><em>k</em></sub></span> 和协方差矩阵 <span class="math inline"><strong>Σ</strong><sub><em>k</em></sub></span> 决定。</p><p>这东西有什么用？GMM 能够近似任何形状的概率分布，学习数据的概率分布。比如我们可以做聚类，下面是一个例子。</p><p>假设我们从一个班级中随机抽取了 <span class="math inline"><em>N</em> = 5</span> 个人的身高数据（单位：厘米），我们认为这些数据可能来源于 <span class="math inline"><em>K</em> = 2</span> 个高斯分布的混合（例如，男生群体的身高分布和女生群体的身高分布）。</p><h4 id="数据集-一维">1. 数据集 (一维)</h4><table><thead><tr class="header"><th style="text-align: center;">样本 <span class="math inline"><em>i</em></span></th><th style="text-align: center;">身高 <span class="math inline"><em>x</em><sub><em>i</em></sub></span> (cm)</th></tr></thead><tbody><tr class="odd"><td style="text-align: center;">1</td><td style="text-align: center;">165</td></tr><tr class="even"><td style="text-align: center;">2</td><td style="text-align: center;">170</td></tr><tr class="odd"><td style="text-align: center;">3</td><td style="text-align: center;">175</td></tr><tr class="even"><td style="text-align: center;">4</td><td style="text-align: center;">185</td></tr><tr class="odd"><td style="text-align: center;">5</td><td style="text-align: center;">190</td></tr></tbody></table><h4 id="模型设置与初始化">2. 模型设置与初始化</h4><ul><li><strong>模型:</strong> <span class="math inline"><em>K</em> = 2</span> 个高斯分量 (簇 1 和 簇 2)。</li><li><strong>模型参数:</strong> <span class="math inline"><em>Θ</em> = {<em>π</em><sub>1</sub>, <em>μ</em><sub>1</sub>, <em>σ</em><sub>1</sub><sup>2</sup>, <em>π</em><sub>2</sub>, <em>μ</em><sub>2</sub>, <em>σ</em><sub>2</sub><sup>2</sup>}</span>。</li></ul><p>我们进行<strong>随机初始化</strong>（第 0 步迭代）：</p><table><thead><tr class="header"><th style="text-align: center;">参数</th><th style="text-align: center;">值</th><th style="text-align: center;">含义</th></tr></thead><tbody><tr class="odd"><td style="text-align: center;"><span class="math inline"><em>π</em><sub>1</sub></span></td><td style="text-align: center;">0.5</td><td style="text-align: center;">属于簇 1 的先验概率</td></tr><tr class="even"><td style="text-align: center;"><span class="math inline"><em>π</em><sub>2</sub></span></td><td style="text-align: center;">0.5</td><td style="text-align: center;">属于簇 2 的先验概率</td></tr><tr class="odd"><td style="text-align: center;"><span class="math inline"><em>μ</em><sub>1</sub></span></td><td style="text-align: center;">170</td><td style="text-align: center;">簇 1 的初始均值</td></tr><tr class="even"><td style="text-align: center;"><span class="math inline"><em>σ</em><sub>1</sub><sup>2</sup></span></td><td style="text-align: center;">25</td><td style="text-align: center;">簇 1 的初始方差 ( <span class="math inline"><em>σ</em><sub>1</sub> = 5</span> )</td></tr><tr class="odd"><td style="text-align: center;"><span class="math inline"><em>μ</em><sub>2</sub></span></td><td style="text-align: center;">185</td><td style="text-align: center;">簇 2 的初始均值</td></tr><tr class="even"><td style="text-align: center;"><span class="math inline"><em>σ</em><sub>2</sub><sup>2</sup></span></td><td style="text-align: center;">25</td><td style="text-align: center;">簇 2 的初始方差 ( <span class="math inline"><em>σ</em><sub>2</sub> = 5</span> )</td></tr></tbody></table><h4 id="em-算法迭代-第一轮">3. EM 算法迭代 (第一轮)</h4><p>我们使用一维高斯分布的概率密度函数： <span class="math display">$$\mathcal{N}(x | \mu, \sigma^2) = \frac{1}{\sqrt{2\pi\sigma^2}} e^{-\frac{(x-\mu)^2}{2\sigma^2}}$$</span></p><hr /><p>我们要计算每个数据点 <span class="math inline"><em>x</em><sub><em>i</em></sub></span> 属于每个簇 <span class="math inline"><em>k</em></span> 的后验概率 <span class="math inline"><em>γ</em>(<em>z</em><sub><em>i</em><em>k</em></sub>) = <em>p</em>(<em>z</em> = <em>k</em>|<em>x</em><sub><em>i</em></sub>, <em>Θ</em><sup>old</sup>)</span>。</p><p><strong>以 <span class="math inline"><em>x</em><sub>1</sub> = 165</span> 为例计算：</strong></p><p><strong>1. 计算似然 <span class="math inline"><em>p</em>(<em>x</em><sub>1</sub>|<em>z</em> = <em>k</em>)</span>：</strong></p><ul><li><p><strong>簇 1 似然 (<span class="math inline"><em>μ</em><sub>1</sub> = 170, <em>σ</em><sub>1</sub><sup>2</sup> = 25</span>):</strong> <span class="math display">$$p(165|z=1) \propto e^{-\frac{(165-170)^2}{2 \times 25}} = e^{-\frac{25}{50}} = e^{-0.5} \approx \mathbf{0.6065}$$</span> (注：为简化计算，我们忽略了常数项 <span class="math inline">$\frac{1}{\sqrt{2\pi\sigma^2}}$</span>，因为它在下一步的比例计算中会抵消，或者您认为 <span class="math inline"><em>σ</em><sub><em>k</em></sub></span> 相同，常数项也相同。)</p></li><li><p><strong>簇 2 似然 (<span class="math inline"><em>μ</em><sub>2</sub> = 185, <em>σ</em><sub>2</sub><sup>2</sup> = 25</span>):</strong> <span class="math display">$$p(165|z=2) \propto e^{-\frac{(165-185)^2}{2 \times 25}} = e^{-\frac{400}{50}} = e^{-8} \approx \mathbf{0.000335}$$</span></p></li></ul><p><strong>2. 计算责任 <span class="math inline"><em>γ</em>(<em>z</em><sub>1<em>k</em></sub>)</span>：</strong></p><ul><li><p><strong>分母:</strong> <span class="math inline"><em>M</em> = <em>π</em><sub>1</sub><em>p</em>(<em>x</em><sub>1</sub>|<em>z</em> = 1) + <em>π</em><sub>2</sub><em>p</em>(<em>x</em><sub>1</sub>|<em>z</em> = 2)</span> <span class="math display"><em>M</em> = 0.5 × 0.6065 + 0.5 × 0.000335 ≈ 0.30325 + 0.0001675 = <strong>0.3034</strong></span></p></li><li><p><strong><span class="math inline"><em>γ</em>(<em>z</em><sub>11</sub>)</span> (属于簇 1):</strong> <span class="math display">$$\frac{0.5 \times 0.6065}{0.3034} \approx \mathbf{0.9995}$$</span></p></li><li><p><strong><span class="math inline"><em>γ</em>(<em>z</em><sub>12</sub>)</span> (属于簇 2):</strong> <span class="math display">$$\frac{0.5 \times 0.000335}{0.3034} \approx \mathbf{0.0005}$$</span></p></li></ul><p><strong>责任矩阵 <span class="math inline"><em>γ</em></span> (所有样本的计算结果):</strong></p><table><thead><tr class="header"><th style="text-align: center;">样本 <span class="math inline"><em>i</em></span></th><th style="text-align: center;"><span class="math inline"><em>x</em><sub><em>i</em></sub></span></th><th style="text-align: center;"><span class="math inline"><em>γ</em>(<em>z</em><sub><em>i</em>1</sub>)</span> (簇 1 责任)</th><th style="text-align: center;"><span class="math inline"><em>γ</em>(<em>z</em><sub><em>i</em>2</sub>)</span> (簇 2 责任)</th></tr></thead><tbody><tr class="odd"><td style="text-align: center;">1</td><td style="text-align: center;">165</td><td style="text-align: center;">0.9995</td><td style="text-align: center;">0.0005</td></tr><tr class="even"><td style="text-align: center;">2</td><td style="text-align: center;">170</td><td style="text-align: center;">0.9999</td><td style="text-align: center;">0.0001</td></tr><tr class="odd"><td style="text-align: center;">3</td><td style="text-align: center;">175</td><td style="text-align: center;">0.9995</td><td style="text-align: center;">0.0005</td></tr><tr class="even"><td style="text-align: center;">4</td><td style="text-align: center;">185</td><td style="text-align: center;">0.0005</td><td style="text-align: center;">0.9995</td></tr><tr class="odd"><td style="text-align: center;">5</td><td style="text-align: center;">190</td><td style="text-align: center;">0.0001</td><td style="text-align: center;">0.9999</td></tr><tr class="even"><td style="text-align: center;"><strong>总和 <span class="math inline"><em>N</em><sub><em>k</em></sub></span></strong></td><td style="text-align: center;"></td><td style="text-align: center;"><strong>3.0095</strong></td><td style="text-align: center;"><strong>1.9905</strong></td></tr></tbody></table><hr /><h4 id="更新参数">4.更新参数</h4><p>我们使用责任总和 <span class="math inline"><em>N</em><sub><em>k</em></sub></span> 和加权数据来更新参数。</p><p><strong>1. 更新混合权重 <span class="math inline"><em>π</em><sub><em>k</em></sub></span></strong></p><p><span class="math display">$$N_k = \sum_{i=1}^{5} \gamma(z_{ik})$$</span> <span class="math display"><em>π</em><sub><em>k</em></sub><sup>new</sup> = <em>N</em><sub><em>k</em></sub>/<em>N</em></span></p><ul><li><span class="math inline"><em>π</em><sub>1</sub><sup>new</sup> = 3.0095/5 ≈ <strong>0.6019</strong></span></li><li><span class="math inline"><em>π</em><sub>2</sub><sup>new</sup> = 1.9905/5 ≈ <strong>0.3981</strong></span></li></ul><p><strong>2. 更新均值 <span class="math inline"><em>μ</em><sub><em>k</em></sub></span></strong></p><p><span class="math display">$$\mu_k^{\text{new}} = \frac{\sum_{i=1}^{N} \gamma(z_{ik}) x_i}{N_k}$$</span></p><ul><li><p><strong>簇 1 均值 <span class="math inline"><em>μ</em><sub>1</sub><sup>new</sup></span>:</strong> <span class="math display">$$\frac{0.9995 \times 165 + 0.9999 \times 170 + 0.9995 \times 175 + \dots}{3.0095} \approx \frac{510.015}{3.0095} \approx \mathbf{169.49}$$</span></p></li><li><p><strong>簇 2 均值 <span class="math inline"><em>μ</em><sub>2</sub><sup>new</sup></span>:</strong> <span class="math display">$$\frac{\dots + 0.0005 \times 185 + 0.9999 \times 190}{1.9905} \approx \frac{375.025}{1.9905} \approx \mathbf{188.47}$$</span></p></li></ul><p><strong>3. 更新方差 <span class="math inline"><em>σ</em><sub><em>k</em></sub><sup>2</sup></span></strong></p><p><span class="math display">$$\sigma_k^{2, \text{new}} = \frac{\sum_{i=1}^{N} \gamma(z_{ik}) (x_i - \mu_k^{\text{new}})^2}{N_k}$$</span></p><ul><li><p><strong>簇 1 方差 <span class="math inline"><em>σ</em><sub>1</sub><sup>2, new</sup></span>:</strong> <span class="math display">$$\frac{0.9995 \times (165 - 169.49)^2 + 0.9999 \times (170 - 169.49)^2 + \dots}{3.0095} \approx \mathbf{25.0}$$</span> (方差变化很小)</p></li><li><p><strong>簇 2 方差 <span class="math inline"><em>σ</em><sub>2</sub><sup>2, new</sup></span>:</strong> <span class="math display">$$\frac{\dots + 0.9999 \times (190 - 188.47)^2}{1.9905} \approx \mathbf{12.5}$$</span> (方差显著减小)</p></li></ul><h4 id="结论-一轮迭代后的结果">5. 结论 (一轮迭代后的结果)</h4><table><thead><tr class="header"><th style="text-align: center;">参数</th><th style="text-align: center;">迭代前 (初始)</th><th style="text-align: center;">迭代后 (新值)</th><th style="text-align: center;">变化</th></tr></thead><tbody><tr class="odd"><td style="text-align: center;"><span class="math inline"><em>π</em><sub>1</sub></span></td><td style="text-align: center;">0.5</td><td style="text-align: center;"><strong>0.6019</strong></td><td style="text-align: center;"><span class="math inline">↑</span></td></tr><tr class="even"><td style="text-align: center;"><span class="math inline"><em>μ</em><sub>1</sub></span></td><td style="text-align: center;">170</td><td style="text-align: center;"><strong>169.49</strong></td><td style="text-align: center;"><span class="math inline">↓</span></td></tr><tr class="odd"><td style="text-align: center;"><span class="math inline"><em>σ</em><sub>1</sub><sup>2</sup></span></td><td style="text-align: center;">25</td><td style="text-align: center;"><strong>25.0</strong></td><td style="text-align: center;"><span class="math inline">≈</span></td></tr><tr class="even"><td style="text-align: center;"><span class="math inline"><em>π</em><sub>2</sub></span></td><td style="text-align: center;">0.5</td><td style="text-align: center;"><strong>0.3981</strong></td><td style="text-align: center;"><span class="math inline">↓</span></td></tr><tr class="odd"><td style="text-align: center;"><span class="math inline"><em>μ</em><sub>2</sub></span></td><td style="text-align: center;">185</td><td style="text-align: center;"><strong>188.47</strong></td><td style="text-align: center;"><span class="math inline">↑</span></td></tr><tr class="even"><td style="text-align: center;"><span class="math inline"><em>σ</em><sub>2</sub><sup>2</sup></span></td><td style="text-align: center;">25</td><td style="text-align: center;"><strong>12.5</strong></td><td style="text-align: center;"><span class="math inline">↓</span></td></tr></tbody></table><p><strong>解释：</strong></p><ol type="1"><li><strong>聚类效果明显:</strong> 在第一轮迭代中，模型已经将 <span class="math inline">{165, 170, 175}</span> 这三个点坚定地分配给了<strong>簇 1</strong> (责任接近 1)，将 <span class="math inline">{185, 190}</span> 分配给了<strong>簇 2</strong> (责任接近 1)。</li><li><strong>参数更新合理:</strong><ul><li>簇 1 的均值从 170 调整到 169.49，更贴近它所负责的三个点 (165, 170, 175) 的平均值。</li><li>簇 2 的均值从 185 调整到 188.47，更贴近它所负责的两个点 (185, 190) 的平均值。</li></ul></li><li><strong>方差收缩:</strong> 簇 2 的方差 <span class="math inline"><em>σ</em><sub>2</sub><sup>2</sup></span> 从 25 减小到 12.5，反映了点 185 和 190 之间的距离比初始设定的要紧凑。 如果继续迭代，参数将逐渐收敛到这两个“自然簇”的统计估计值。</li></ol><p>(这是真的麻烦 想不明白谁发明的..)</p><h2 id="multinomial-mixture-model">Multinomial Mixture Model</h2><p>  多项混合分布，其实就是把分量的概率分布变为多项分布。什么是多项分布？就是用于描述有限次独立试验中，各种可能结果发生次数的一种离散概率分布。说人话：进行 <span class="math inline"><em>N</em></span> 次独立的试验。每次试验的结果只能属于 <span class="math inline"><em>D</em></span> 个互斥的类别 <span class="math inline"><em>C</em><sub>1</sub>, <em>C</em><sub>2</sub>, …, <em>C</em><sub><em>D</em></sub></span> 中的一个。多项分布给出了在 <span class="math inline"><em>N</em></span> 次试验中，类别 <span class="math inline"><em>C</em><sub>1</sub></span> 发生 <span class="math inline"><em>x</em><sub>1</sub></span> 次、类别 <span class="math inline"><em>C</em><sub>2</sub></span> 发生 <span class="math inline"><em>x</em><sub>2</sub></span> 次、…、类别 <span class="math inline"><em>C</em><sub><em>D</em></sub></span> 发生 <span class="math inline"><em>x</em><sub><em>D</em></sub></span> 次的概率 <span class="math inline"><em>P</em>(<strong>x</strong>)</span>。<span class="math display">$$P(\mathbf{x} | N, \boldsymbol{\theta}) = \frac{N!}{x_1! x_2! \dots x_D!} \prod_{j=1}^{D} \theta_j^{x_j}$$</span></p><p><span class="math inline">$\frac{N!}{x_1! x_2! \dots x_D!}$</span>其实就是组合数，总的N次实验方案（不考虑顺序）是<span class="math inline"><em>N</em>!</span>，但是我们不需要顺序，所以还要除一下消除。而<span class="math inline"><em>θ</em><sub><em>j</em></sub></span>是单次实验<span class="math inline"><em>C</em><sub><em>j</em></sub></span>发生的概率。</p><p>假设我们有 <span class="math inline"><em>N</em> = 4</span> 篇短文档，只关注 <span class="math inline"><em>D</em> = 3</span> 个词汇（A, B, C）。我们希望将文档聚类成 <span class="math inline"><em>K</em> = 2</span> 个主题（主题 1 和 主题 2）。</p><h4 id="数据集-词频计数">1. 数据集 (词频计数)</h4><table><thead><tr class="header"><th style="text-align: center;">文档 <span class="math inline"><em>i</em></span></th><th style="text-align: center;"><span class="math inline"><em>x</em><sub><em>i</em>, A</sub></span></th><th style="text-align: center;"><span class="math inline"><em>x</em><sub><em>i</em>, B</sub></span></th><th style="text-align: center;"><span class="math inline"><em>x</em><sub><em>i</em>, C</sub></span></th><th style="text-align: center;">总词数 <span class="math inline"><em>N</em><sub><em>i</em></sub></span></th></tr></thead><tbody><tr class="odd"><td style="text-align: center;">1</td><td style="text-align: center;">4</td><td style="text-align: center;">1</td><td style="text-align: center;">0</td><td style="text-align: center;">5</td></tr><tr class="even"><td style="text-align: center;">2</td><td style="text-align: center;">1</td><td style="text-align: center;">5</td><td style="text-align: center;">0</td><td style="text-align: center;">6</td></tr><tr class="odd"><td style="text-align: center;">3</td><td style="text-align: center;">0</td><td style="text-align: center;">2</td><td style="text-align: center;">3</td><td style="text-align: center;">5</td></tr><tr class="even"><td style="text-align: center;">4</td><td style="text-align: center;">0</td><td style="text-align: center;">1</td><td style="text-align: center;">4</td><td style="text-align: center;">5</td></tr></tbody></table><h4 id="模型设置和初始化">2. 模型设置和初始化</h4><table><thead><tr class="header"><th style="text-align: center;">参数</th><th style="text-align: center;">值</th><th style="text-align: center;">含义</th></tr></thead><tbody><tr class="odd"><td style="text-align: center;"><span class="math inline"><em>π</em><sub>1</sub></span></td><td style="text-align: center;">0.5</td><td style="text-align: center;">文档属于主题 1 的先验概率</td></tr><tr class="even"><td style="text-align: center;"><span class="math inline"><em>π</em><sub>2</sub></span></td><td style="text-align: center;">0.5</td><td style="text-align: center;">文档属于主题 2 的先验概率</td></tr><tr class="odd"><td style="text-align: center;"><span class="math inline"><em>θ</em><sub>1</sub></span></td><td style="text-align: center;">(0.8, 0.1, 0.1)</td><td style="text-align: center;">主题 1 下 (A, B, C) 的生成概率</td></tr><tr class="even"><td style="text-align: center;"><span class="math inline"><em>θ</em><sub>2</sub></span></td><td style="text-align: center;">(0.1, 0.4, 0.5)</td><td style="text-align: center;">主题 2 下 (A, B, C) 的生成概率</td></tr></tbody></table><hr /><h4 id="em-算法第一轮迭代">3. EM 算法第一轮迭代</h4><h4 id="计算责任-gammaz_ik">计算责任 <span class="math inline"><em>γ</em>(<em>z</em><sub><em>i</em><em>k</em></sub>)</span></h4><p>责任 <span class="math inline"><em>γ</em>(<em>z</em><sub><em>i</em><em>k</em></sub>)</span> 是文档 <span class="math inline"><em>i</em></span> 属于主题 <span class="math inline"><em>k</em></span> 的后验概率。</p><p><span class="math display">$$\gamma(z_{ik}) = \frac{\pi_k L_k}{\sum_{l=1}^{2} \pi_l L_l}$$</span></p><p>其中 <span class="math inline">$L_k = \prod_{j=\text{A}}^{\text{C}} \theta_{kj}^{x_{ij}}$</span> 是忽略多项系数的似然比例。</p><p><strong>以文档 2 (<span class="math inline"><strong>x</strong><sub>2</sub> = (1, 5, 0)</span>, <span class="math inline"><em>N</em><sub>2</sub> = 6</span>) 为例计算：</strong></p><ol type="1"><li><strong>主题 1 的似然比例 <span class="math inline"><em>L</em><sub>1</sub></span>:</strong> <span class="math display"><em>L</em><sub>1</sub> = 0.8<sup>1</sup> × 0.1<sup>5</sup> × 0.1<sup>0</sup> = 0.8 × 0.00001 × 1 = <strong>0.000008</strong></span></li><li><strong>主题 2 的似然比例 <span class="math inline"><em>L</em><sub>2</sub></span>:</strong> <span class="math display"><em>L</em><sub>2</sub> = 0.1<sup>1</sup> × 0.4<sup>5</sup> × 0.5<sup>0</sup> = 0.1 × 0.01024 × 1 = <strong>0.001024</strong></span></li><li><strong>计算 <span class="math inline"><em>γ</em>(<em>z</em><sub>21</sub>)</span>:</strong> <span class="math display">$$\gamma(z_{21}) = \frac{0.5 \times 0.000008}{0.5 \times 0.000008 + 0.5 \times 0.001024} = \frac{0.000004}{0.000004 + 0.000512} \approx \mathbf{0.0078}$$</span></li><li><strong>计算 <span class="math inline"><em>γ</em>(<em>z</em><sub>22</sub>)</span>:</strong> <span class="math display"><em>γ</em>(<em>z</em><sub>22</sub>) = 1 − 0.0078 ≈ <strong>0.9922</strong></span></li></ol><p><strong>完整的责任矩阵 <span class="math inline"><em>γ</em></span></strong></p><table><thead><tr class="header"><th style="text-align: center;">文档 <span class="math inline"><em>i</em></span></th><th style="text-align: center;"><span class="math inline"><em>N</em><sub><em>i</em></sub></span></th><th style="text-align: center;"><span class="math inline"><em>γ</em>(<em>z</em><sub><em>i</em>1</sub>)</span> (主题 1)</th><th style="text-align: center;"><span class="math inline"><em>γ</em>(<em>z</em><sub><em>i</em>2</sub>)</span> (主题 2)</th></tr></thead><tbody><tr class="odd"><td style="text-align: center;">1 (4, 1, 0)</td><td style="text-align: center;">5</td><td style="text-align: center;">0.9999</td><td style="text-align: center;">0.0001</td></tr><tr class="even"><td style="text-align: center;">2 (1, 5, 0)</td><td style="text-align: center;">6</td><td style="text-align: center;">0.0078</td><td style="text-align: center;">0.9922</td></tr><tr class="odd"><td style="text-align: center;">3 (0, 2, 3)</td><td style="text-align: center;">5</td><td style="text-align: center;">0.0000</td><td style="text-align: center;">1.0000</td></tr><tr class="even"><td style="text-align: center;">4 (0, 1, 4)</td><td style="text-align: center;">5</td><td style="text-align: center;">0.0000</td><td style="text-align: center;">1.0000</td></tr><tr class="odd"><td style="text-align: center;"><strong>总和 <span class="math inline"><em>N</em><sub><em>k</em></sub></span></strong></td><td style="text-align: center;"></td><td style="text-align: center;"><strong>1.0077</strong></td><td style="text-align: center;"><strong>2.9923</strong></td></tr></tbody></table><h4 id="更新参数-1">更新参数</h4><p><strong>1. 更新混合权重 <span class="math inline"><em>π</em><sub><em>k</em></sub></span></strong></p><p><span class="math display">$$N_k = \sum_{i=1}^{N} \gamma(z_{ik}) \quad \pi_k^{\text{new}} = N_k / N$$</span></p><ul><li><span class="math inline"><em>π</em><sub>1</sub><sup>new</sup> = 1.0077/4 ≈ <strong>0.2519</strong></span></li><li><span class="math inline"><em>π</em><sub>2</sub><sup>new</sup> = 2.9923/4 ≈ <strong>0.7481</strong></span></li></ul><p><strong>2. 更新多项概率 <span class="math inline"><em>θ</em><sub><em>k</em><em>j</em></sub></span></strong></p><p><span class="math display">$$\theta_{kj}^{\text{new}} = \frac{\sum_{i=1}^{N} \gamma(z_{ik}) x_{ij}}{\sum_{i=1}^{N} \gamma(z_{ik}) N_i} = \frac{\text{词 } j \text{ 的总加权计数}}{T_k (\text{总加权词数})}$$</span></p><p>首先计算<strong>总加权词数</strong> <span class="math inline"><em>T</em><sub><em>k</em></sub></span>: <span class="math display">$$T_k = \sum_{i=1}^{4} \gamma(z_{ik}) N_i$$</span></p><ul><li><span class="math inline"><em>T</em><sub>1</sub> = 0.9999 × 5 + 0.0078 × 6 + 0.0000 × 5 + 0.0000 × 5 ≈ <strong>5.0468</strong></span></li><li><span class="math inline"><em>T</em><sub>2</sub> = 0.0001 × 5 + 0.9922 × 6 + 1.0000 × 5 + 1.0000 × 5 ≈ <strong>15.9538</strong></span></li></ul><p><strong>计算词 A 的加权计数 <span class="math inline"><em>C</em><sub><em>k</em>, A</sub></span>:</strong> <span class="math display">$$C_{k, \text{A}} = \sum_{i=1}^{4} \gamma(z_{ik}) x_{i, \text{A}}$$</span></p><ul><li><span class="math inline"><em>C</em><sub>1, A</sub> = 0.9999 × 4 + 0.0078 × 1 + 0 + 0 ≈ <strong>4.0074</strong></span></li><li><span class="math inline"><em>C</em><sub>2, A</sub> = 0.0001 × 4 + 0.9922 × 1 + 0 + 0 ≈ <strong>0.9926</strong></span></li></ul><p><strong>更新 <span class="math inline"><em>θ</em><sub><em>k</em><em>j</em></sub></span>:</strong></p><table><thead><tr class="header"><th style="text-align: center;">参数</th><th style="text-align: center;">词 A (<span class="math inline"><em>j</em> = A</span>)</th><th style="text-align: center;">词 B (<span class="math inline"><em>j</em> = B</span>)</th><th style="text-align: center;">词 C (<span class="math inline"><em>j</em> = C</span>)</th></tr></thead><tbody><tr class="odd"><td style="text-align: center;"><strong>主题 1</strong></td><td style="text-align: center;"><span class="math inline"><em>θ</em><sub>1, A</sub><sup>new</sup> = 4.0074/5.0468 ≈ <strong>0.794</strong></span></td><td style="text-align: center;"><span class="math inline"><em>θ</em><sub>1, B</sub><sup>new</sup> = 1.0078/5.0468 ≈ <strong>0.200</strong></span></td><td style="text-align: center;"><span class="math inline"><em>θ</em><sub>1, C</sub><sup>new</sup> = 0/5.0468 ≈ <strong>0.000</strong></span></td></tr><tr class="even"><td style="text-align: center;"><strong>主题 2</strong></td><td style="text-align: center;"><span class="math inline"><em>θ</em><sub>2, A</sub><sup>new</sup> = 0.9926/15.9538 ≈ <strong>0.062</strong></span></td><td style="text-align: center;"><span class="math inline"><em>θ</em><sub>2, B</sub><sup>new</sup> = 8.0156/15.9538 ≈ <strong>0.502</strong></span></td><td style="text-align: center;"><span class="math inline"><em>θ</em><sub>2, C</sub><sup>new</sup> = 6.9456/15.9538 ≈ <strong>0.436</strong></span></td></tr></tbody></table><h3 id="结论-第一轮迭代后的结果">4. 结论 (第一轮迭代后的结果)</h3><p>经过一轮 EM 迭代，模型参数发生了显著变化：</p><ol type="1"><li><strong>主题 1 ( <span class="math inline"><em>π</em><sub>1</sub> = 0.25</span> ):</strong> 权重下降。它的核心是<strong>词 A (0.794)</strong>。</li><li><strong>主题 2 ( <span class="math inline"><em>π</em><sub>2</sub> = 0.75</span> ):</strong> 权重上升。它的核心是<strong>词 B (0.502) 和 词 C (0.436)</strong>。</li><li><strong>聚类强化:</strong> E 步的责任显示，模型已经明确地将<strong>文档 1</strong> 分配给主题 1，将<strong>文档 2, 3, 4</strong> 分配给主题 2。</li></ol><p>这个例子清晰地展示了 EM 算法如何通过<strong>责任</strong> (<span class="math inline"><em>γ</em></span>) 来软分配数据点，并使用这些分配的权重来重新计算每个主题的<strong>生成概率</strong> (<span class="math inline"><em>θ</em></span>)，从而迭代优化主题模型。</p><h2 id="bernoulli-mixture-model">Bernoulli Mixture Model</h2><p>  BMM 适用于建模 <span class="math inline"><em>D</em></span> 维的二元特征向量 <span class="math inline"><strong>x</strong> = (<em>x</em><sub>1</sub>, <em>x</em><sub>2</sub>, …, <em>x</em><sub><em>D</em></sub>)</span>，其中每个特征 <span class="math inline"><em>x</em><sub><em>j</em></sub> ∈ {0, 1}</span>。应用场景: 用户是否点击了某个广告 (1/0)、一个基因是否表达 (1/0)、文档中某个词汇是否出现 (1/0)。</p><p>每个分量 <span class="math inline"><em>k</em></span> 的条件概率 <span class="math inline"><em>p</em>(<strong>x</strong>|<em>z</em> = <em>k</em>)</span> 是 <span class="math inline"><em>D</em></span> 个伯努利分布的乘积。说人话就是：每个分量都是D维数据，而且每一个feature都是伯努利分布。 <span class="math display">$$p(\mathbf{x} | z=k) = \prod_{j=1}^{D} p(x_j | z=k) = \prod_{j=1}^{D} \theta_{kj}^{x_j} (1 - \theta_{kj})^{1 - x_j}$$</span> 整体的分布就是要乘上一个<span class="math inline"><em>π</em><sub><em>k</em></sub></span> 求和 <span class="math display">$$p(\mathbf{x}) = \sum_{k=1}^{K} \pi_k p(\mathbf{x} | z=k) = \sum_{k=1}^{K} \pi_k \left[ \prod_{j=1}^{D} \theta_{kj}^{x_j} (1 - \theta_{kj})^{1 - x_j} \right]$$</span></p><p><span class="math display">$$\gamma(z_{ik}) = p(z_i=k | \mathbf{x}_i, \Theta^{\text{old}}) = \frac{p(\mathbf{x}_i | z_i=k, \Theta^{\text{old}}) p(z_i=k)}{\sum_{l=1}^{K} p(\mathbf{x}_i | z_i=l, \Theta^{\text{old}}) p(z_i=l)}$$</span></p><p><span class="math display">$$\gamma(z_{ik}) = \frac{\pi_k^{\text{old}} \left[ \prod_{j=1}^{D} (\theta_{kj}^{\text{old}})^{x_{ij}} (1 - \theta_{kj}^{\text{old}})^{1 - x_{ij}} \right]}{\sum_{l=1}^{K} \pi_l^{\text{old}} \left[ \prod_{j=1}^{D} (\theta_{lj}^{\text{old}})^{x_{ij}} (1 - \theta_{lj}^{\text{old}})^{1 - x_{ij}} \right]}$$</span></p><p><span class="math display">$$N_k = \sum_{i=1}^{N} \gamma(z_{ik})$$</span></p><p><span class="math display">$$\pi_k^{\text{new}} = \frac{N_k}{N} = \frac{\sum_{i=1}^{N} \gamma(z_{ik})}{N}$$</span></p><p><span class="math display">$$\sum_{i=1}^{N} \gamma(z_{ik}) x_{ij}$$</span></p><p><span class="math display">$$\theta_{kj}^{\text{new}} = \frac{\sum_{i=1}^{N} \gamma(z_{ik}) x_{ij}}{N_k}$$</span></p><p>假设我们有 <span class="math inline"><em>N</em> = 5</span> 位客户，记录了他们在 <span class="math inline"><em>D</em> = 3</span> 种行为上的二元（<span class="math inline">0/1</span>）数据。目标是将他们聚类成 <span class="math inline"><em>K</em> = 2</span> 个客户群体（簇 1 和 簇 2）。</p><h4 id="数据集-二元数据-mathbfx_i">1. 数据集 (二元数据 <span class="math inline"><strong>x</strong><sub><em>i</em></sub></span>)</h4><table><thead><tr class="header"><th style="text-align: center;">客户 <span class="math inline"><em>i</em></span></th><th style="text-align: center;"><span class="math inline"><em>x</em><sub><em>i</em>1</sub></span> (浏览商品)</th><th style="text-align: center;"><span class="math inline"><em>x</em><sub><em>i</em>2</sub></span> (加入购物车)</th><th style="text-align: center;"><span class="math inline"><em>x</em><sub><em>i</em>3</sub></span> (最终购买)</th></tr></thead><tbody><tr class="odd"><td style="text-align: center;">1</td><td style="text-align: center;">1</td><td style="text-align: center;">1</td><td style="text-align: center;">1</td></tr><tr class="even"><td style="text-align: center;">2</td><td style="text-align: center;">1</td><td style="text-align: center;">0</td><td style="text-align: center;">0</td></tr><tr class="odd"><td style="text-align: center;">3</td><td style="text-align: center;">0</td><td style="text-align: center;">1</td><td style="text-align: center;">0</td></tr><tr class="even"><td style="text-align: center;">4</td><td style="text-align: center;">0</td><td style="text-align: center;">0</td><td style="text-align: center;">1</td></tr><tr class="odd"><td style="text-align: center;">5</td><td style="text-align: center;">1</td><td style="text-align: center;">1</td><td style="text-align: center;">0</td></tr></tbody></table><h4 id="模型设置和初始化-第-0-轮迭代">2. 模型设置和初始化 (第 0 轮迭代)</h4><p>我们初始化 <span class="math inline"><em>K</em> = 2</span> 个簇的参数 <span class="math inline"><em>Θ</em> = {<em>π</em><sub><em>k</em></sub>, <em>θ</em><sub><em>k</em></sub>}<sub><em>k</em> = 1</sub><sup>2</sup></span>：</p><table><thead><tr class="header"><th style="text-align: center;">参数</th><th style="text-align: center;">值</th><th style="text-align: center;">含义</th></tr></thead><tbody><tr class="odd"><td style="text-align: center;"><span class="math inline"><em>π</em><sub>1</sub></span></td><td style="text-align: center;">0.5</td><td style="text-align: center;">客户属于簇 1 的先验概率</td></tr><tr class="even"><td style="text-align: center;"><span class="math inline"><em>π</em><sub>2</sub></span></td><td style="text-align: center;">0.5</td><td style="text-align: center;">客户属于簇 2 的先验概率</td></tr><tr class="odd"><td style="text-align: center;"><span class="math inline"><em>θ</em><sub>1</sub></span></td><td style="text-align: center;">(0.8, 0.4, 0.1)</td><td style="text-align: center;">簇 1 中 3 种行为发生的概率</td></tr><tr class="even"><td style="text-align: center;"><span class="math inline"><em>θ</em><sub>2</sub></span></td><td style="text-align: center;">(0.2, 0.6, 0.9)</td><td style="text-align: center;">簇 2 中 3 种行为发生的概率</td></tr></tbody></table><hr /><h4 id="em-算法第一轮迭代-1">3. EM 算法第一轮迭代</h4><h4 id="a.-e-步-期望步骤计算责任-gammaz_ik">A. E 步 (期望步骤：计算责任 <span class="math inline"><em>γ</em>(<em>z</em><sub><em>i</em><em>k</em></sub>)</span>)</h4><p>责任是 <span class="math inline"><strong>x</strong><sub><em>i</em></sub></span> 属于 <span class="math inline"><em>k</em></span> 簇的后验概率 <span class="math inline"><em>γ</em>(<em>z</em><sub><em>i</em><em>k</em></sub>) = <em>p</em>(<em>z</em> = <em>k</em>|<strong>x</strong><sub><em>i</em></sub>)</span>。</p><p><strong>以客户 1 (<span class="math inline"><strong>x</strong><sub>1</sub> = (1, 1, 1)</span>) 为例计算：</strong></p><ol type="1"><li><p><strong>簇 1 的似然 <span class="math inline"><em>p</em>(<strong>x</strong><sub>1</sub>|<em>z</em> = 1)</span>:</strong> <span class="math display">0.8<sup>1</sup>(1 − 0.8)<sup>0</sup> × 0.4<sup>1</sup>(1 − 0.4)<sup>0</sup> × 0.1<sup>1</sup>(1 − 0.1)<sup>0</sup> = 0.8 × 0.4 × 0.1 = <strong>0.032</strong></span></p></li><li><p><strong>簇 2 的似然 <span class="math inline"><em>p</em>(<strong>x</strong><sub>1</sub>|<em>z</em> = 2)</span>:</strong> <span class="math display">0.2<sup>1</sup>(1 − 0.2)<sup>0</sup> × 0.6<sup>1</sup>(1 − 0.6)<sup>0</sup> × 0.9<sup>1</sup>(1 − 0.9)<sup>0</sup> = 0.2 × 0.6 × 0.9 = <strong>0.108</strong></span></p></li><li><p><strong>计算责任 <span class="math inline"><em>γ</em>(<em>z</em><sub>11</sub>)</span> (客户 1 属于簇 1 的概率):</strong> <span class="math display">$$\gamma(z_{11}) = \frac{0.5 \times 0.032}{0.5 \times 0.032 + 0.5 \times 0.108} = \frac{0.016}{0.070} \approx \mathbf{0.2286}$$</span></p></li><li><p><strong>计算责任 <span class="math inline"><em>γ</em>(<em>z</em><sub>12</sub>)</span> (客户 1 属于簇 2 的概率):</strong> <span class="math display"><em>γ</em>(<em>z</em><sub>12</sub>) = 1 − 0.2286 ≈ <strong>0.7714</strong></span></p></li></ol><p><strong>完整的责任矩阵 <span class="math inline"><em>γ</em></span> (所有客户的计算结果):</strong></p><table><thead><tr class="header"><th style="text-align: center;">客户 <span class="math inline"><em>i</em></span></th><th style="text-align: center;"><span class="math inline"><strong>x</strong><sub><em>i</em></sub></span></th><th style="text-align: center;"><span class="math inline"><em>γ</em>(<em>z</em><sub><em>i</em>1</sub>)</span> (属于簇 1)</th><th style="text-align: center;"><span class="math inline"><em>γ</em>(<em>z</em><sub><em>i</em>2</sub>)</span> (属于簇 2)</th></tr></thead><tbody><tr class="odd"><td style="text-align: center;">1</td><td style="text-align: center;">(1, 1, 1)</td><td style="text-align: center;">0.2286</td><td style="text-align: center;">0.7714</td></tr><tr class="even"><td style="text-align: center;">2</td><td style="text-align: center;">(1, 0, 0)</td><td style="text-align: center;">0.9855</td><td style="text-align: center;">0.0145</td></tr><tr class="odd"><td style="text-align: center;">3</td><td style="text-align: center;">(0, 1, 0)</td><td style="text-align: center;">0.1379</td><td style="text-align: center;">0.8621</td></tr><tr class="even"><td style="text-align: center;">4</td><td style="text-align: center;">(0, 0, 1)</td><td style="text-align: center;">0.0033</td><td style="text-align: center;">0.9967</td></tr><tr class="odd"><td style="text-align: center;">5</td><td style="text-align: center;">(1, 1, 0)</td><td style="text-align: center;">0.8351</td><td style="text-align: center;">0.1649</td></tr><tr class="even"><td style="text-align: center;"><strong>总和 <span class="math inline"><em>N</em><sub><em>k</em></sub></span></strong></td><td style="text-align: center;"></td><td style="text-align: center;"><strong>2.1904</strong></td><td style="text-align: center;"><strong>2.8096</strong></td></tr></tbody></table><hr /><h4 id="更新参数-2">更新参数</h4><p><strong>1. 更新混合权重 <span class="math inline"><em>π</em><sub><em>k</em></sub></span></strong></p><p><span class="math display"><em>π</em><sub><em>k</em></sub><sup>new</sup> = <em>N</em><sub><em>k</em></sub>/<em>N</em></span></p><ul><li><span class="math inline"><em>π</em><sub>1</sub><sup>new</sup> = 2.1904/5 ≈ <strong>0.4381</strong></span></li><li><span class="math inline"><em>π</em><sub>2</sub><sup>new</sup> = 2.8096/5 ≈ <strong>0.5619</strong></span></li></ul><p><strong>2. 更新伯努利参数 <span class="math inline"><em>θ</em><sub><em>k</em><em>j</em></sub></span></strong></p><p><span class="math display">$$\theta_{kj}^{\text{new}} = \frac{\sum_{i=1}^{N} \gamma(z_{ik}) x_{ij}}{N_k}$$</span></p><p>计算分子 <span class="math inline">$\sum_{i=1}^{N} \gamma(z_{ik}) x_{ij}$</span> (特征 <span class="math inline"><em>j</em></span> 的加权计数，只需对 <span class="math inline"><em>x</em><sub><em>i</em><em>j</em></sub> = 1</span> 的客户进行求和)：</p><table><thead><tr class="header"><th style="text-align: center;">特征 <span class="math inline"><em>j</em></span></th><th style="text-align: center;"><strong>分子 <span class="math inline"><em>C</em><sub>1<em>j</em></sub></span> (簇 1 加权计数)</strong></th><th style="text-align: center;"><strong>分子 <span class="math inline"><em>C</em><sub>2<em>j</em></sub></span> (簇 2 加权计数)</strong></th></tr></thead><tbody><tr class="odd"><td style="text-align: center;"><strong><span class="math inline"><em>x</em><sub><em>j</em> = 1</sub></span> (浏览)</strong></td><td style="text-align: center;"><span class="math inline"><em>γ</em>(<em>z</em><sub>11</sub>) + <em>γ</em>(<em>z</em><sub>21</sub>) + <em>γ</em>(<em>z</em><sub>51</sub>) ≈ <strong>2.0492</strong></span></td><td style="text-align: center;"><span class="math inline"><em>γ</em>(<em>z</em><sub>12</sub>) + <em>γ</em>(<em>z</em><sub>22</sub>) + <em>γ</em>(<em>z</em><sub>52</sub>) ≈ <strong>0.9508</strong></span></td></tr><tr class="even"><td style="text-align: center;"><strong><span class="math inline"><em>x</em><sub><em>j</em> = 2</sub></span> (购物车)</strong></td><td style="text-align: center;"><span class="math inline"><em>γ</em>(<em>z</em><sub>11</sub>) + <em>γ</em>(<em>z</em><sub>31</sub>) + <em>γ</em>(<em>z</em><sub>51</sub>) ≈ <strong>1.2016</strong></span></td><td style="text-align: center;"><span class="math inline"><em>γ</em>(<em>z</em><sub>12</sub>) + <em>γ</em>(<em>z</em><sub>32</sub>) + <em>γ</em>(<em>z</em><sub>52</sub>) ≈ <strong>1.7984</strong></span></td></tr><tr class="odd"><td style="text-align: center;"><strong><span class="math inline"><em>x</em><sub><em>j</em> = 3</sub></span> (购买)</strong></td><td style="text-align: center;"><span class="math inline"><em>γ</em>(<em>z</em><sub>11</sub>) + <em>γ</em>(<em>z</em><sub>41</sub>) ≈ <strong>0.2319</strong></span></td><td style="text-align: center;"><span class="math inline"><em>γ</em>(<em>z</em><sub>12</sub>) + <em>γ</em>(<em>z</em><sub>42</sub>) ≈ <strong>1.7681</strong></span></td></tr></tbody></table><p>最后，除以各自的 <span class="math inline"><em>N</em><sub><em>k</em></sub></span>：</p><table><thead><tr class="header"><th style="text-align: center;">簇 <span class="math inline"><em>k</em></span></th><th style="text-align: center;"><span class="math inline"><em>x</em><sub>1</sub></span> (浏览)</th><th style="text-align: center;"><span class="math inline"><em>x</em><sub>2</sub></span> (购物车)</th><th style="text-align: center;"><span class="math inline"><em>x</em><sub>3</sub></span> (购买)</th></tr></thead><tbody><tr class="odd"><td style="text-align: center;"><strong><span class="math inline"><em>θ</em><sub>1</sub><sup>new</sup></span></strong></td><td style="text-align: center;"><span class="math inline">2.0492/2.1904 ≈ <strong>0.936</strong></span></td><td style="text-align: center;"><span class="math inline">1.2016/2.1904 ≈ <strong>0.548</strong></span></td><td style="text-align: center;"><span class="math inline">0.2319/2.1904 ≈ <strong>0.106</strong></span></td></tr><tr class="even"><td style="text-align: center;"><strong><span class="math inline"><em>θ</em><sub>2</sub><sup>new</sup></span></strong></td><td style="text-align: center;"><span class="math inline">0.9508/2.8096 ≈ <strong>0.339</strong></span></td><td style="text-align: center;"><span class="math inline">1.7984/2.8096 ≈ <strong>0.640</strong></span></td><td style="text-align: center;"><span class="math inline">1.7681/2.8096 ≈ <strong>0.629</strong></span></td></tr></tbody></table><h4 id="结论-一轮迭代后的特征解读">4. 结论 (一轮迭代后的特征解读)</h4><p>迭代后的参数清晰地定义了两个不同的客户群体：</p><table style="width:100%;"><thead><tr class="header"><th style="text-align: center;">簇 <span class="math inline"><em>k</em></span></th><th style="text-align: center;"><span class="math inline"><em>π</em><sub><em>k</em></sub></span></th><th style="text-align: center;"><span class="math inline"><em>θ</em><sub>浏览</sub></span></th><th style="text-align: center;"><span class="math inline"><em>θ</em><sub>购物车</sub></span></th><th style="text-align: center;"><span class="math inline"><em>θ</em><sub>购买</sub></span></th><th style="text-align: center;"><strong>客户群体特征</strong></th></tr></thead><tbody><tr class="odd"><td style="text-align: center;"><strong>簇 1</strong></td><td style="text-align: center;"><span class="math inline"> ≈ 44%</span></td><td style="text-align: center;"><strong>高 (0.936)</strong></td><td style="text-align: center;">中 (0.548)</td><td style="text-align: center;">低 (0.106)</td><td style="text-align: center;"><strong>“浏览型客户”</strong>: 非常活跃地浏览商品，但购买意愿/转化率较低。</td></tr><tr class="even"><td style="text-align: center;"><strong>簇 2</strong></td><td style="text-align: center;"><span class="math inline"> ≈ 56%</span></td><td style="text-align: center;">低 (0.339)</td><td style="text-align: center;">中高 (0.640)</td><td style="text-align: center;"><strong>高 (0.629)</strong></td><td style="text-align: center;"><strong>“高转化客户”</strong>: 可能直接搜索目标商品，购买转化率极高。</td></tr></tbody></table>]]></content>
    
    
    <categories>
      
      <category>course</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>DS杂谈25346期</title>
    <link href="/2025/12/15/DS%E6%9D%82%E8%B0%8825346%E6%9C%9F/"/>
    <url>/2025/12/15/DS%E6%9D%82%E8%B0%8825346%E6%9C%9F/</url>
    
    <content type="html"><![CDATA[<p><a href="https://www.youtube.com/watch?v=ACT6oaPyO7o">link</a></p><p>（25346）林彪的头号爱将刘亚楼专门干丈母娘的事被周恩来知道了！柯庆施和刘亚楼的地位和作用是无可替代的！</p>]]></content>
    
    
    <categories>
      
      <category>history</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>图像/音频生成的套路概述</title>
    <link href="/2025/12/15/%E5%9B%BE%E5%83%8F-%E9%9F%B3%E9%A2%91%E7%94%9F%E6%88%90%E7%9A%84%E7%AD%96%E7%95%A5%E6%A6%82%E8%BF%B0/"/>
    <url>/2025/12/15/%E5%9B%BE%E5%83%8F-%E9%9F%B3%E9%A2%91%E7%94%9F%E6%88%90%E7%9A%84%E7%AD%96%E7%95%A5%E6%A6%82%E8%BF%B0/</url>
    
    <content type="html"><![CDATA[<p><a href="https://speech.ee.ntu.edu.tw/~hylee/GenAI-ML/2025-fall-course-data/Generation.pdf">PPT link</a></p><h2 id="自回归的生成套路">自回归的生成套路</h2><p>  Image/Sound的生成可以借鉴LLM的套路，变为Next token prediction。我们只需要预测下一个token是什么，然后拼在一起就构成了输出。这里有一个问题：LLM的token是一个个的词组，那Image/Sound生成的token单元对应什么？</p><p>在实操中，我们可以认为Image就是由很多的token构成的一个矩阵。我们要训练的Image generation model的工作很简单：把Image tokenized / 从token还原Image。 <img src="./2025-12-15-21-17-32.png" /> <img src="./2025-12-15-21-19-49.png" /></p><p>上面举得例子token呈现二维排列，其实我们可以直接把image token当成one dimension。这样的话就和LLM预测下一个token一样了。 <img src="./2025-12-15-21-20-59.png" /></p><p>继续深入，LLM生成文字天然有顺序，从左到右。但图像生成我们可不可以扩展一下，乱序生成呢？MaskGIT就是这样做的，每次随机mask一些token，让model尝试预测这些token。 <img src="./2025-12-15-21-32-51.png" /> 在Inference的时候，如果token同时产生，因为不同token没有协调，可能会生成乱的图片（第一个token想生成动物的head 第3个也想 这样就乱了）。因此可以每次只保留K个token，运行多轮直到完全生成。 <img src="./2025-12-15-21-34-20.png" /> <img src="./2025-12-15-21-36-09.png" /> 如下图，由于随机mask，生成的顺序是不固定的。 <img src="./2025-12-15-21-36-23.png" /></p><h2 id="training中怎么评估图片的close">Training中怎么评估图片的close?</h2><p>  上述的训练由tokenizer和detokenizer构成，需要一起训练让图片尽可能接近。那么如何评估图片/音频之间的接近呢？</p><ol type="1"><li>绝对数值的接近 对音频来说，每个采样的音频点的绝对数值要接近，那就可以算一个Regression Loss。直接相减平方和；对图像来说，每个pixel要接近，也可以直接算平方和。 <img src="./2025-12-15-21-26-33.png" /></li><li>perceptual loss 可以让一个能够理解Image/Sound的模型，输入两个数据，把模型的中间向量抽出来，然后比较两个向量的距离。(理论上来说，两个近似的图片，含义类似，在特征空间里的距离也应该比较接近 这种做法和Text Embedding差不多) <img src="./2025-12-15-21-28-40.png" /></li><li>借鉴GAN的思路，让判别器判定 <img src="./2025-12-15-21-30-50.png" /></li></ol><h2 id="token的极限">Token的极限</h2><p>  采用自回归的方式，predict next token是有一些极限的。token对信息的高度压缩会导致我们损失很多信息。（<strong>为什么语言模型就可以呢？我觉得language本身就是对信息的高度压缩，天然是一个个token。而且实操中，LLM也是先把token映射到Embedding dim然后再predict next token。显然这也是因为token损失了太多的信息，导致反而要先扩展再predict</strong>）</p><p>举个例子，16*16的pixel用8192个token代替，这里还原之后的效果很差。token限制了我们的信息压缩和解压。 <img src="./2025-12-15-21-41-59.png" /></p><p>我们可以考虑用continuous token(其实就是vector)来做图像生成。 但是这里会遇到一些问题，对于图像生成，我们不需要vector和目标vector完全一样，而是只要在一个分布就可以（奔跑的狗 可以在街上也可以在草地，都不是错误的target）。 <img src="./2025-12-15-23-04-51.png" /> <img src="./2025-12-15-23-05-33.png" /> 这个问题在Language model里面有没有？没有。因为LLM采用的是离散的token，我们会根据概率分布采样一个token。而连续的token会产生两个target的mixture。</p><p>正因如此，产生了新的图像生成范式（VAE GAN Diffusion…）请看next charpter</p><h2 id="新的图像生成思路">新的图像生成思路</h2><p>  我们想要产生连续的token(vector)，可以考虑生成一个概率分布，然后再从这个概率分布中采样token。 <img src="./2025-12-15-23-11-33.png" /> 一开始的研究认为，可以生成概率分布相关的参数，比如假设是一个多变量的Gauss distribution，我们可以预测均值和协方差。但是有个问题，就是没办法拟合一些复杂的分布（Gauss distribution怎么样都是椭圆） <img src="./2025-12-15-23-13-58.png" /> 后面的研究统称为“Generative Model”。他们的考虑是，既然没办法直接拟合分布，我可以拟合从一个分布到另一个分布的Transform Method。也就是说，我先从一个已知的分布中采样，然后想办法把他变换成目标分布。Model的作用就是实现这种变换。 <img src="./2025-12-15-23-17-00.png" /></p><h2 id="一些可以继续深入学习的参考资料">一些可以继续深入学习的参考资料</h2><table><thead><tr class="header"><th style="text-align: left;">主题</th><th style="text-align: left;">标题</th><th style="text-align: left;">URL</th><th style="text-align: left;">课程/年份</th></tr></thead><tbody><tr class="odd"><td style="text-align: left;"><strong>VAE (变分自编码器)</strong></td><td style="text-align: left;">VAE / Unsupervised Deep Learning - Deep Generative Models (Part I)</td><td style="text-align: left;"><code>https://youtu.be/8zomhgKrsMQ</code></td><td style="text-align: left;">2016 机器学习</td></tr><tr class="even"><td style="text-align: left;"><strong>GAN (生成对抗网络)</strong></td><td style="text-align: left;">Introduction of Generative Adversarial Network (GAN) / 李宏毅</td><td style="text-align: left;"><code>https://www.youtube.com/watch?v=DQNNMIAp5lw&amp;list=PLJV_eL3UvTsMq6JEFPW35BCiOQTsoQwNw</code></td><td style="text-align: left;">2018 机器学习及其深层与结构化</td></tr><tr class="odd"><td style="text-align: left;"><strong>Normalizing Flow (归一化流)</strong></td><td style="text-align: left;">Normalizing Flow / Flow-based Generation Model / Coupling Layer</td><td style="text-align: left;"><code>https://youtu.be/uXY18nzdSsM</code></td><td style="text-align: left;">2019 机器学习</td></tr><tr class="even"><td style="text-align: left;"><strong>Diffusion Model (扩散模型)</strong></td><td style="text-align: left;">Diffusion Model / Denoising Diffusion Probabilistic Models (DDPM)</td><td style="text-align: left;"><code>https://www.youtube.com/watch?v=a2BugJzmz-o&amp;list=PLJV_eL3UvTsNi7PgeKEUFSYVJIAJXRsP-</code></td><td style="text-align: left;">2023 机器学习</td></tr><tr class="odd"><td style="text-align: left;"><strong>Flow matching</strong></td><td style="text-align: left;"></td><td style="text-align: left;">https://www.youtube.com/watch?v=ccqCDD9LqCA</td><td style="text-align: left;">生成式人工智慧與機器學習導論2025</td></tr></tbody></table>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>云服务器租赁和配置</title>
    <link href="/2025/12/15/%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%A7%9F%E8%B5%81%E5%92%8C%E9%85%8D%E7%BD%AE/"/>
    <url>/2025/12/15/%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%A7%9F%E8%B5%81%E5%92%8C%E9%85%8D%E7%BD%AE/</url>
    
    <content type="html"><![CDATA[<p><a href="https://www.autodl.com/console/instance/list?tag_id=">link</a></p><h2 id="aliyun服务器定价">aliyun服务器定价</h2><p>一方面，卡的定价比较贵，24GB的A10要8.5元/h 而且还没有计算服务器的网费。另一方面显卡型号不全，便宜的卡如5090这种都没有。 <img src="./2025-12-17-10-45-30.png" /> <img src="./2025-12-17-10-46-02.png" /></p><h2 id="autodl服务器定价">AutoDL服务器定价</h2><p>价格便宜得多，而且支持0.1元/h的无GPU模式启动，这个模式下可以编写一些代码逻辑，很便宜。 <img src="./2025-12-17-10-51-11.png" /></p><h2 id="购买服务器并进行一些配置">购买服务器，并进行一些配置</h2><p>这里选择32GB的5090服务器，并进行一些LLM相关配置： - 选好cuda版本 12.8 - 下载对应版本的vllm 用于测试GPU - 配置镜像的链接（AutoDL是国内的服务器 需要配置一下镜像） - vllm下载Qwen3-8B 测试GPU</p><p><img src="./2025-12-15-13-35-31.png" /> <img src="./2025-12-15-13-37-26.png" /></p><p>配置好vllm (中间发现了一个<a href="https://github.com/vllm-project/vllm/issues/23517">bug</a>) 下载了Qwen3-8B 运行做测试，模型跑起来的GPU使用情况25GB/32GB <img src="./2025-12-15-13-39-39.png" /></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Tülu 3: Pushing Frontiers in Open Language Model Post-Training</title>
    <link href="/2025/12/14/Tulu-3-Pushing-Frontiers-in-Open-Language-Model-Post-Training/"/>
    <url>/2025/12/14/Tulu-3-Pushing-Frontiers-in-Open-Language-Model-Post-Training/</url>
    
    <content type="html"><![CDATA[<h2 id="我的评价">我的评价</h2><p>  </p><h2 id="当前存在什么问题">当前存在什么问题</h2><p>  </p><h2 id="本文打算通过什么思路解决">本文打算通过什么思路解决</h2><p>  </p><h2 id="该思路会遇到什么挑战">该思路会遇到什么挑战</h2><p>  </p><h2 id="本文通过什么手段克服该挑战">本文通过什么手段克服该挑战</h2><p>  </p><h2 id="本文如何通过实验论证了该方案的优越性">本文如何通过实验论证了该方案的优越性</h2><p>  </p><h2 id="本文的写作思路">本文的写作思路</h2><p>  </p><h2 id="我的思考">我的思考</h2><p>  </p>]]></content>
    
    
    <categories>
      
      <category>COLM2025</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Evals for Data Diversity</title>
    <link href="/2025/12/13/Evals-for-Data-Diversity/"/>
    <url>/2025/12/13/Evals-for-Data-Diversity/</url>
    
    <content type="html"><![CDATA[<h1 id="llm生成数据的多样性评估">LLM生成数据的多样性评估</h1><p><a href="https://amitness.com/posts/diversity-evals">link</a></p><h2 id="引言为什么合成数据需要多样性">引言：为什么合成数据需要多样性？</h2><p>使用大型语言模型（LLMs）生成合成数据已成为一种流行的方法。然而，一个常见的问题是，LLM直接生成的输出往往具有<strong>重复性</strong>。</p><p>为了提高生成数据的多样性，我们通常会采用一些技术，例如：</p><ul><li><strong>采样参数：</strong> 提高温度（temperature）、使用核采样（nucleus-sampling）或 Top-K 采样。</li><li><strong>属性生成：</strong> 预先生成各种属性（如主题、风格、长度、角色等），并将其随机插入到提示中。</li><li><strong>解码后聚类：</strong> 过量生成大量文本，然后通过聚类中心或语义哈希进行去重。</li></ul><p>这就引出了一个关键问题：<strong>我们如何系统地评估这些技术对多样性的影响</strong></p><p>本文将概述学术界已有的、用于衡量LLM生成文本<strong>Diversity</strong>的各种自动评估指标，涵盖词汇、语义和句法三个维度。</p><hr /><h2 id="一词汇多样性指标-lexical-diversity-metrics">一、词汇多样性指标 (Lexical Diversity Metrics)</h2><p>这类指标用于捕捉文本中词语、短语、主题和 N-gram 在表面上的重复程度。</p><h3 id="独特-n-gram-distinct-k">1. 独特 N-gram (Distinct-k)</h3><ul><li><strong>基本概念：</strong> 源自语言学中的“型符比”（type-token ratio）。</li><li><strong>计算方式：</strong> 计算生成的整个数据集中<strong>独特 N-gram 的数量</strong>与<strong>总 N-gram 的数量</strong>之比。</li></ul><p>例如，对于文本 “As an AI language model” 和 “As an AI model”：</p><ul><li>总 Unigram (1-gram) 数量：9</li><li>独特 Unigram 数量：5 (As, an, AI, language, model)</li><li><strong>多样性得分：</strong> <span class="math inline">5/9 ≈ 0.55</span></li></ul><p><img src="./2025-12-13-19-46-14.png" /> <img src="./2025-12-13-19-46-20.png" /></p><p>这个概念可以扩展到 Bigram (k=2)、Trigram (k=3) 等，并可以分别组合成一个分数。</p><h3 id="n-gram-熵-ent-n">2. N-gram 熵 (Ent-n)</h3><ul><li><strong>基本概念：</strong> 在理想情况下，LLM 生成的所有文本都应该是独特的，任何 N-gram 都不会重复超过一次。</li><li><strong>计算方式：</strong> 通过收集文本中所有独特的 N-gram，计算它们的频率，从而得到 N-gram 的概率分布。然后，计算该概率分布的<strong>信息熵</strong>。</li><li><strong>判断标准：</strong> 分布越均匀（重复越少），熵值越高，多样性也越高。</li></ul><p><img src="./2025-12-13-19-46-58.png" /></p><h3 id="压缩比-compression-ratio">3. 压缩比 (Compression Ratio)</h3><ul><li><strong>基本概念：</strong> 借鉴用于评估压缩算法的压缩比概念。</li><li><strong>计算方式：</strong> 使用如 Gzip 等算法压缩文本，计算<strong>压缩文件大小</strong>与<strong>原始大小</strong>之比。</li><li><strong>判断标准：</strong><ul><li><strong>比率越高</strong>（如 16.258），表明文本<strong>可压缩性越高</strong>，冗余度高，因此<strong>多样性越低</strong>。</li><li>多样性可以计算为压缩比的<strong>倒数</strong>，从而得到一个 0 到 1 之间的分数。</li></ul></li></ul><h2 id="section"><img src="./2025-12-13-19-48-01.png" /></h2><h2 id="二语义多样性指标-semantic-diversity-metrics">二、语义多样性指标 (Semantic Diversity Metrics)</h2><p>这类指标关注文本在<strong>语义</strong>上的多样性，并依赖于embeddings。它们可以处理词汇重叠为零但意义相似（例如，“Play the music” 和 “Start a song”）的情况。</p><h3 id="嵌入多样性-embedding-diversity">1. 嵌入多样性 (Embedding Diversity)</h3><ul><li><strong>计算方式：</strong><ol type="1"><li>使用编码器（如 Sentence-Transformers）计算所有生成文本的<strong>Embedding vector</strong>。</li><li>计算所有独特文本对之间的<strong>余弦相似度（Cosine Similarity）</strong>。</li><li>取这些相似度的<strong>平均值</strong>。</li></ol></li><li><strong>判断标准：</strong> 将平均相似度转换为多样性得分（如：<span class="math inline">1 − 平均余弦相似度</span>），得分越高表示多样性越高。</li></ul><p><img src="./2025-12-13-19-48-18.png" /> <img src="./2025-12-13-19-48-24.png" /></p><h3 id="dcscore">2. DCScore</h3><ul><li><strong>计算方式：</strong><ol type="1"><li>计算文本嵌入的<strong>两两相似度矩阵</strong>(做法和1相同)。</li><li>对该矩阵应用 <strong>Softmax</strong> 函数。</li><li>计算 Softmax 矩阵<strong>对角线元素的平均值</strong>。</li></ol></li><li><strong>判断标准：</strong> 对角线元素表示文本相对于所有其他文本（包括自身）与自身的相似度“概率”。平均值越接近 1，表示文本与其自身的相似度远高于与其他任何文本的相似度，从而意味着整体数据集的多样性高。</li></ul><p><img src="./2025-12-13-19-48-34.png" /> <img src="./2025-12-13-19-48-39.png" /></p><h3 id="聚类惯性-cluster-inertia">3. 聚类惯性 (Cluster Inertia)</h3><ul><li><strong>基本概念：</strong> 重用聚类算法中用于衡量聚类质量的“惯性”指标。</li><li><strong>计算方式：</strong><ol type="1"><li>将文本嵌入聚类到 <span class="math inline"><em>K</em></span> 个簇（如 <span class="math inline"><em>K</em> = 10</span>）。</li><li>计算<strong>惯性</strong> (Inertia)：即簇内所有点到其<strong>质心（centroid）</strong>的平方距离之和。</li></ol></li><li><strong>判断标准：</strong> 如果文本多样，它们会离质心更远，导致<strong>惯性更大</strong>，因此惯性被视为多样性的一个代理指标。</li></ul><p><img src="./2025-12-13-19-48-47.png" /></p><hr /><h2 id="三句法多样性指标-syntactic-diversity-metrics">三、句法多样性指标 (Syntactic Diversity Metrics)</h2><p>这类指标捕捉文本在<strong>底层语法结构</strong>上的多样性。</p><h3 id="压缩比---词性-cr-pos">1. 压缩比 - 词性 (CR-POS)</h3><ul><li><strong>基本概念：</strong> 重用“压缩比”的概念，但应用于文本的<strong>句法表示</strong>。</li><li><strong>计算方式：</strong><ol type="1"><li>使用词性标注器（POS tagger）将所有生成文本转换为其<strong>词性标签序列</strong>（即句法表示）。</li><li>将所有词性标签序列拼接成一个长字符串。</li><li>计算这个长字符串的<strong>压缩比</strong>。</li></ol></li><li><strong>判断标准：</strong> 压缩比越高，表示句法模板重复越多，<strong>多样性越低</strong>。多样性得分取压缩比的倒数。</li></ul><p><img src="./2025-12-13-19-48-57.png" /> <img src="./2025-12-13-19-49-04.png" /> <img src="./2025-12-13-19-49-10.png" /></p><hr /><h2 id="总结">总结</h2><p>我们探索了衡量LLM生成数据的语言多样性的三大类指标：</p><table><thead><tr class="header"><th style="text-align: left;">类别</th><th style="text-align: left;">关注点</th><th style="text-align: left;">关键指标</th></tr></thead><tbody><tr class="odd"><td style="text-align: left;"><strong>词汇</strong></td><td style="text-align: left;">表面词语、N-gram 的重复</td><td style="text-align: left;">N-gram (Distinct-k), N-gram 熵, 压缩比</td></tr><tr class="even"><td style="text-align: left;"><strong>语义</strong></td><td style="text-align: left;">文本在意义上的不同</td><td style="text-align: left;">嵌入多样性, DCScore, 聚类惯性</td></tr><tr class="odd"><td style="text-align: left;"><strong>句法</strong></td><td style="text-align: left;">底层语法结构的重复</td><td style="text-align: left;">压缩比 - 词性 (CR-POS)</td></tr></tbody></table><p>在实际应用中，这些自动指标快速且易于计算，可以作为评估LLM生成数据多样性的指标。</p>]]></content>
    
    
    <categories>
      
      <category>eval</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>VERBALIZED SAMPLING: HOW TO MITIGATE MODE COLLAPSE AND UNLOCK LLM DIVERSITY</title>
    <link href="/2025/12/11/VERBALIZED-SAMPLING-HOW-TO-MITIGATE-MODE-COLLAPSE-AND-UNLOCK-LLM-DIVERSITY/"/>
    <url>/2025/12/11/VERBALIZED-SAMPLING-HOW-TO-MITIGATE-MODE-COLLAPSE-AND-UNLOCK-LLM-DIVERSITY/</url>
    
    <content type="html"><![CDATA[<p><img src="./2025-12-11-22-43-23.png" /></p><h2 id="我的评价">我的评价</h2><p>   作者说LLM生成内容的多样性不好，是因为数据本身就带有人类的偏好。数据本身的偏好是模型多样性缺失的原因，是本文要证明的内容。按照这个分析，作者大概会构造一些偏好数据，然后训练模型，证明这种多样性确实源于偏好数据。</p><p>   作者改进模型数据多样性的方法，不是通过output的采样，而是使用Prompt，让模型输出多个回答并带有概率分布，这种方式很难理解为什么这么做。明明使用llm的参数temperature改变采样策略就可以做到，为什么还要这种Prompt呢？(作者标榜Prompt可以做到Training-Free 但是采样策略也是啊 而且更可控…)</p><p>  总结来说，这篇文章有点像是独立的两篇文章。前半段对Training Data的bias的分析不够深入，只是针对一个数据集做了分析，通过拟合，证明了数据确实有bias。在我看来，还应该对bias data对模型的影响进行更加细致的分析（比如通过消除bias data中的bias，重新训练，看能否消除这种diversity的缺失）。后半段则是对VERBALIZED SAMPLING（一种带有概率的Prompt）来缓解模型diversity的降低。在我看来，后半段完全可以单独弄一个文章，分析temperature / reward model / training algforithm / prompt等对模型输出diversity的影响，看看哪个更有效。</p><p>  作为一篇ICLR 2026在投的文章，从<a href="https://openreview.net/forum?id=9jQkmGunGo">OpenReview</a>上面的评论，也可以看出和评价类似的Reviewer comment。不过这确实是一篇实验非常详实，消融实验设计也很合理的好文章。</p><h2 id="当前存在什么问题">当前存在什么问题</h2><p>  在创意性的问题，比如“tell me a joke” “write a story about bear”… 场景下，我们需要 LLM 给出尽可能 diverse 的 answer。但是前人研究发现，LLM 在训练的过程中，生成内容的 diversity 会降低。过去的研究集中在算法层面，认为 trainging algorithm 存在天然的缺陷，比如单一的奖励信号，RLHF 中的 KL 正则化项等等，他们天然的就会在训练的过程中降低 model output diversity。因此，解决的方案就是从算法角度下手，尽可能优化 sft rl 的过程。</p><p>本文想要从 Data 的角度解释这种 diversity 的缺失，同时提出一些提高 diversity 的方法。</p><h2 id="本文打算通过什么思路解决">本文打算通过什么思路解决</h2><p>  本文做出假设：模型的训练数据本身是带有 bias 的。人类在标注 RLHF 数据的时候，做排序天然的就有 bias。比如更喜欢比较熟悉的语法，熟悉的结构，简单易懂的呈现方式等等。本文通过分析一个 Nvidia 团队的数据集HELPSTEER，证明这种数据bias 的存在。这里通过理论推导和拟合，发现确实存在。</p><p><span class="math display">$$r(x, y) = r_{\text{true}}(x, y) + \alpha \log \pi_{\text{ref}}(y | x) + \epsilon(x) \tag{1}$$</span></p><p>  研究人员使用了 HELPSTEER 数据集。这个数据集非常特殊，因为它对同一个回答给了两个不同的打分： - Correctness（正确性）： 对应公式中的 <span class="math inline"><em>r</em><sub>true</sub></span>（真实任务效用）。 - Helpfulness（有用性）： 对应公式中的 <span class="math inline"><em>r</em></span>（最终奖励，即人类给出的总分）</p><p>研究人员从数据集中筛选出了 6,874 对回答。这些配对有一个关键特征：“same correctness ratings” (拥有相同的正确性评分)这意味着对于每一对回答 <span class="math inline">(<em>y</em><sub>1</sub>, <em>y</em><sub>2</sub>)</span>，它们的真实效用是相等的：<span class="math display"><em>r</em><sub>true</sub>(<em>y</em><sub>1</sub>) = <em>r</em><sub>true</sub>(<em>y</em><sub>2</sub>)</span></p><p>假设有两个回答 <span class="math inline"><em>A</em></span> 和 <span class="math inline"><em>B</em></span>，它们的正确性评分一样，但人类给的总分（有用性）不一样。根据公式 (1)：回答 A 的得分： <span class="math inline"><em>r</em><sub><em>A</em></sub> = <em>r</em><sub>true</sub> + <em>α</em> ⋅ Typicality<sub><em>A</em></sub></span>回答 B 的得分： <span class="math inline"><em>r</em><sub><em>B</em></sub> = <em>r</em><sub>true</sub> + <em>α</em> ⋅ Typicality<sub><em>B</em></sub></span>当我们把这两个式子相减（比较 <span class="math inline"><em>A</em></span> 和 <span class="math inline"><em>B</em></span>）：<span class="math display"><em>r</em><sub><em>A</em></sub> − <em>r</em><sub><em>B</em></sub> = (<em>r</em><sub>true</sub> − <em>r</em><sub>true</sub>) + <em>α</em>(Typicality<sub><em>A</em></sub> − Typicality<sub><em>B</em></sub>)</span>由于正确性相同，<span class="math inline"><em>r</em><sub>true</sub></span> 互相抵消为 0，剩下的就是：<span class="math display"><em>Δ</em>Reward = <em>α</em> × <em>Δ</em>Typicality</span></p><h2 id="该思路会遇到什么挑战">该思路会遇到什么挑战</h2><ul><li>如何证明 data bias 的存在。</li><li>找到一个新的方法，能够提高模型的 diversity</li></ul><h2 id="本文通过什么手段克服该挑战">本文通过什么手段克服该挑战</h2><ul><li>本文通过理论推导 bias 公式，然后使用HELPSTEER 数据集做数据拟合的验证，表明这种数据的 bias 的存在。</li><li>前人的解决方案大多集中在 algorithm 或者 inference setting (sampling 策略)。本文提出带有概率输出的 prompt 来解决。如:“Generate 5 responses with their corresponding probabilities. Tell me a joke about coffee.”</li></ul><h2 id="本文如何通过实验论证了该方案的优越性">本文如何通过实验论证了该方案的优越性</h2><ul><li><p>实验目标：证明该 prompt 能够提高 LLM 输出的 diversity。</p></li><li><p>实验的 benchmark：诗歌续写，故事生成，讲笑话。</p></li><li><p>怎么 evaluate 模型的输出呢： 多样性：把模型的输出做 Embedding，通过相似度计算来反映输出的 diversity 输出质量：只输出多样的内容是不够的，我们还需要保证 quality。本文把 claude 模型 LLM as judge，从几个语言学上的维度，评估输出的质量。</p></li><li><p>实验设置：在下列模型上，不同的 method （看Prompt Example column）跑 benchmark，使用 evaluate 的方法，计算输出的多样性和质量，绘制图像。 Gemini-2.5-Flash, Gemini-2.5-Pro Claude Series (Claude-3.7-Sonnet, Claude-4-Sonnet) open ones like (Llama-3.1-70B-Instruct and Qwen3-235B-A22B-2507-Instruct-2507) reasoning models like (OpenAI o3 and DeepSeek R1) <img src="./2025-12-12-22-38-08.png" /> 实验结果：VS（也就是本文提出的方法）在各个 benchmark 上的表现都更优 <img src="./2025-12-12-22-38-22.png" /> <img src="./2025-12-12-22-38-27.png" /></p></li><li><p>消融实验：</p></li></ul><ol type="1"><li>llm params: temparature LLM 的 api 中可以调节 temperature 参数来调整模型输出的 diversity。因此需要消融 temperature。本文通过设置不同的 temperature 进行相同实验，消除该参数对方案有效性的影响。可以看到，VS 方案在各个 temperature 下的 diversity + quality 的表现依然是最佳的。 <img src="./2025-12-12-22-39-21.png" /></li><li>llm 不同的 traing stage 为了证明这种 VS 方法的有效性，本文在 LLM 不同的训练阶段 （SFT RLHF RLVR）都进行了 diversity 的测试，发现该方法在不同阶段都有效果。如图，随着训练的进行，Base Model 的 diversity 下降，但是 VS 方法的下降是最慢的，缓解了模型 diversity 的下降。 <img src="./2025-12-12-22-40-09.png" /></li></ol><h2 id="我的思考">我的思考</h2><p>  我在gemini-2.5-flash模型上试了一下，“Write a story about a bear.” 会得到如下结果 确实会有可能得到相似的回答： <img src="./2025-12-11-22-52-38.png" /> <img src="./2025-12-11-22-52-49.png" /></p><p>不过这里只是粗略的看，<strong>如何评估两段文字的语义相似性 也是一个值得研究的问题</strong></p><p>研究RLHF阶段的training data，分析到底什么样的数据会更优先，有没有搞头？可能需要分析排在前面的answer的通用范式（可能有总结 结构比较清晰 有各种tag分点之类的），也需要评估排在前面的answer是不是真的质量高于后面的，还是说因为human preference打分比较靠前。（这里你可能就要找一个方法 评估回答的质量–》 如果让LLM judge，那是不是就会出问题–》本身就是偏好数据RLHF训练出来的 会不会就给这里的排在前面的answer打高分呢 ）</p><p>对比现有的提升模型输出多样性的方法，找到最有效的那个，不知道算不算创新，能不能发文章</p><ul><li>本文提及的论文中，可以继续深入了解的内容：</li></ul><ol type="1"><li>了解 RLHF 相关数据集的标注格式： HelpSteer: Multi-attribute Helpfulness Dataset for SteerLM <a href="https://arxiv.org/abs/2311.09528">link</a></li><li>了解模型训练的不同阶段： Tulu 3: Pushing Frontiers in Open Language Model Post-Training <a href="https://arxiv.org/abs/2411.15124">link</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>iclr</category>
      
    </categories>
    
    
    <tags>
      
      <tag>iclr2026在投</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>COZE项目概述</title>
    <link href="/2025/12/11/COZE%E9%A1%B9%E7%9B%AE%E6%A6%82%E8%BF%B0/"/>
    <url>/2025/12/11/COZE%E9%A1%B9%E7%9B%AE%E6%A6%82%E8%BF%B0/</url>
    
    <content type="html"><![CDATA[<h2 id="我的评价">我的评价</h2><p>  </p><h2 id="当前存在什么问题">当前存在什么问题</h2><p>  </p><h2 id="本文打算通过什么思路解决">本文打算通过什么思路解决</h2><p>  </p><h2 id="该思路会遇到什么挑战">该思路会遇到什么挑战</h2><p>  </p><h2 id="本文通过什么手段克服该挑战">本文通过什么手段克服该挑战</h2><p>  </p><h2 id="本文如何通过实验论证了该方案的优越性">本文如何通过实验论证了该方案的优越性</h2><p>  </p><h2 id="本文的写作思路">本文的写作思路</h2><p>  </p><h2 id="我的思考">我的思考</h2><p>  </p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>StressPrompt: Does Stress Impact Large Language Models and Human Performance Similarly?</title>
    <link href="/2025/12/10/StressPrompt-Does-Stress-Impact-Large-Language-Models-and-Human-Performance-Similarly/"/>
    <url>/2025/12/10/StressPrompt-Does-Stress-Impact-Large-Language-Models-and-Human-Performance-Similarly/</url>
    
    <content type="html"><![CDATA[<p><img src="./2025-12-10-23-32-16.png" /></p><h2 id="我的评价">我的评价</h2><p>写作逻辑还可以，实验部分写的很差</p><ol type="1"><li>实验数据不完整   The models tested included Llama-3-8B-Instruct, Llama-3.1-8B-Instruct, Llama-3-70B-Instruct(AI@Meta 2024), Phi-3-mini-4k-Instruct (Abdin et al.2024), Qwen2-72B-Instruct, Qwen2-7B-Instruct (Yang et al.2024), and Mistral-7B-Instruct-v0.3 (Jiang et al. 2023). The generation temperature was set to 0, and specific dialogue tokens were used to ensure consistency.</li></ol><p>  The datasets employed in these evaluations included IFEval (Zhou et al.2023), BBH (Suzgun et al. 2022), MATH (Hendrycks et al. 2021b), GPQA (Rein et al. 2023), MuSR (Sprague et al. 2023), MMLU-P (Wang et al. 2024b), EQBench (Paech 2023), MMLU (Hendrycks et al. 2021a),TruthfulQA</p><p>  然而实际上你只能看到这些Llama-3-8B-Instruct, Phi-3-mini-4k-Instruct 以及一些意义不明 明显是凑数用的数据分析(PCA T-SNE) 对于StressPrompt的作用原理也是点到为止。</p><ol start="2" type="1"><li><p>如何构造的prompt也是意义不明 只是说自己套用了很多什么心理学准则提示词生成的原理也没讲，AI生成吗？</p></li><li><p>喜欢蹭心理科学，标榜自己证实了耶克斯-多德森定律。纯纯唐文</p></li></ol><h2 id="当前存在什么问题">当前存在什么问题</h2><p>  现在没有人做模型的压力测试。就像人在不同压力等级下的表现不同，模型会不会也有这种现象。此外分析压力对模型内部的影响，对模型的训练过程也有一定的启发。</p><h2 id="本文打算通过什么思路解决">本文打算通过什么思路解决</h2><p>  设计100个StressPrompt， 对prompt进行人工压力评级(0 - 10)。把StressPrompt作为System Prompt输到模型里，再让模型进行MMLU MATH GPQA等主流测试。看看模型的表现有没有变化。</p><p>  分析StressPrompt对模型内部的影响，可以把hidden state的向量拿到，然后做一个PCA，找到方差最大的那个vector。对于某个prompt，可以拿到不同layer的不同token的hidden state然后和vector相乘得到一个标量，用于表示影响。</p><p><img src="./2025-12-10-23-40-02.png" /></p><h2 id="该思路会遇到什么挑战">该思路会遇到什么挑战</h2><p>   没什么挑战。构建prompt(我猜用的是ai)；PCA和分析不同layer的hidden state的方法感觉像是ai想出来的数据分析方法。</p><h2 id="本文通过什么手段克服该挑战">本文通过什么手段克服该挑战</h2><p>   。。。</p><h2 id="本文如何通过实验论证了该方案的优越性">本文如何通过实验论证了该方案的优越性</h2><p>   跑各种主流评测数据集。但是有个问题，本文根本就是挂羊头卖狗肉，没有展示出来所有的模型的表现。而且表格画的很烂。有提升的为什么不把这里加粗（把最高的标粗），还有1-10都没有提升的也不讨论。 <img src="./2025-12-10-23-43-33.png" /></p><h2 id="本文的写作思路">本文的写作思路</h2><p>  引言 (Introduction)： 提出LLMs性能受压力影响的问题尚未被探索，阐述研究的必要性（理解LLMs与人类智能的相似性、AI的鲁棒性）。</p><p>  相关工作 (Related Works)： 回顾LLMs的进步、情感智能评估以及压力对人类的影响等研究，指出现有研究缺乏对LLMs内部状态的定量分析，引出本文的研究切入点 。</p><p>  方法 (Method)： 详细介绍核心创新点：StressPrompt 的构建：基于四大心理学框架，并通过人类评分校准 。StressPrompt 的评估框架：如何在不同压力水平下系统地评估LLMs的性能 。压力扫描器 (Stress Scanner) 的分析：如何利用表征工程（RepE）来量化压力对LLMs内部状态的影响 。</p><p>  实验 (Experiments)： 描述实验设置、测试的模型和基准任务，并对在不同压力水平下的任务性能进行详细分析，重点论证耶克斯-多德森定律的发现和对不同任务（如复杂推理、情绪智能）的影响 。</p><p>  结论与贡献 (Conclusion/Contributions)： 总结研究发现，强调StressPrompt的贡献（创新数据集、压力扫描器），并提出对未来开发更具弹性和适应性的AI系统的指导意义 。</p><h2 id="我的思考">我的思考</h2><p>这种垃圾还是少看为佳</p>]]></content>
    
    
    <categories>
      
      <category>AAAI2025</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>概率算法ppt总结</title>
    <link href="/2025/12/10/%E6%A6%82%E7%8E%87%E7%AE%97%E6%B3%95ppt%E6%80%BB%E7%BB%93/"/>
    <url>/2025/12/10/%E6%A6%82%E7%8E%87%E7%AE%97%E6%B3%95ppt%E6%80%BB%E7%BB%93/</url>
    
    <content type="html"><![CDATA[<p>计算 <span class="math inline"><em>a</em> = <em>g</em><sup><em>x</em></sup><em>m</em><em>o</em><em>d</em> <em>p</em></span> 离散对数计算的问题 最坏情况下是<span class="math inline"><em>O</em>(<em>p</em>)</span> 这里可以使用Sherwood算法引入随机性，降低进入最坏情况的概率。</p><p><img src="./2025-12-10-14-09-30.png" /></p><p>这个改写利用了随机预处理来改变求解的实例，使得原本可能在特定输入下性能不佳的确定性离散对数算法 <span class="math inline"><em>l</em><em>o</em><em>g</em><sub><em>g</em>, <em>p</em></sub></span>，能够以接近平均性能的效率求解。</p><h2 id="dlog_rh-算法工作原理分析">🔬 <span class="math inline"><em>d</em><em>l</em><em>o</em><em>g</em><sub><em>R</em><em>H</em></sub></span> 算法工作原理分析</h2><h3 id="算法目标">1. 算法目标</h3><ul><li><strong>问题</strong>: 离散对数问题。</li><li><strong>输入</strong>: 基数 <span class="math inline"><em>g</em></span>，目标值 <span class="math inline"><em>a</em></span>，模数 <span class="math inline"><em>p</em></span>。</li><li><strong>求解</strong>: 找到指数 <span class="math inline"><em>x</em></span>，使得 <span class="math inline"><em>g</em><sup><em>x</em></sup> ≡ <em>a</em> (mod  <em>p</em>)</span>。</li><li><strong>模</strong>: 运算发生在 <span class="math inline">ℤ<sub><em>p</em></sub><sup>*</sup></span> (模 <span class="math inline"><em>p</em></span> 乘法群) 中。指数 <span class="math inline"><em>x</em></span> 在 <span class="math inline">ℤ<sub><em>p</em> − 1</sub></span> (模 <span class="math inline"><em>p</em> − 1</span> 加法群) 中，即 <span class="math inline"><em>x</em> ∈ {0, 1, …, <em>p</em> − 2}</span>。</li></ul><h3 id="dlog_rh-步骤解析">2. <span class="math inline"><em>d</em><em>l</em><em>o</em><em>g</em><sub><em>R</em><em>H</em></sub></span> 步骤解析</h3><table><thead><tr class="header"><th style="text-align: left;">步骤</th><th style="text-align: left;">代码</th><th style="text-align: left;">解释</th><th style="text-align: left;">作用</th></tr></thead><tbody><tr class="odd"><td style="text-align: left;"><strong>I. 随机数</strong></td><td style="text-align: left;"><code>r ← uniform(0..p-2);</code></td><td style="text-align: left;">随机选择一个指数 <span class="math inline"><em>r</em> ∈ {0, 1, …, <em>p</em> − 2}</span>。<strong>这是随机性的来源。</strong></td><td style="text-align: left;">引入随机变量 <span class="math inline"><em>r</em></span>。</td></tr><tr class="even"><td style="text-align: left;"><strong>II. 预处理 (实例 <span class="math inline"><em>y</em></span>)</strong></td><td style="text-align: left;"><code>b ← ModularExponent(g, r, p);</code></td><td style="text-align: left;">计算 <span class="math inline"><em>b</em> = <em>g</em><sup><em>r</em></sup> (mod  <em>p</em>)</span>。</td><td style="text-align: left;"></td></tr><tr class="odd"><td style="text-align: left;"></td><td style="text-align: left;"><code>c ← b \cdot a \pmod{p};</code></td><td style="text-align: left;">计算 <span class="math inline"><em>c</em> = <em>b</em> ⋅ <em>a</em> (mod  <em>p</em>) = <em>g</em><sup><em>r</em></sup> ⋅ <em>g</em><sup><em>x</em></sup> (mod  <em>p</em>) = <em>g</em><sup><em>r</em> + <em>x</em></sup> (mod  <em>p</em>)</span>。</td><td style="text-align: left;"><strong>原实例 <span class="math inline"><em>a</em></span> 变换为随机实例 <span class="math inline"><em>c</em></span>。</strong></td></tr><tr class="even"><td style="text-align: left;"><strong>III. 确定求解 (<span class="math inline"><em>f</em></span>)</strong></td><td style="text-align: left;"><code>y ← logg,pc;</code></td><td style="text-align: left;">使用<strong>确定性算法</strong> <span class="math inline"><em>l</em><em>o</em><em>g</em><sub><em>g</em>, <em>p</em></sub></span> 求解实例 <span class="math inline"><em>c</em></span>。<strong>目标是找到 <span class="math inline"><em>y</em></span>，使得 <span class="math inline"><em>g</em><sup><em>y</em></sup> ≡ <em>c</em> (mod  <em>p</em>)</span>。</strong></td><td style="text-align: left;"><span class="math inline"><em>y</em></span> 是 <span class="math inline"><em>r</em> + <em>x</em></span> 的解。</td></tr><tr class="odd"><td style="text-align: left;"><strong>IV. 后处理 (<span class="math inline"><em>v</em></span>)</strong></td><td style="text-align: left;"><code>return (y-r) mod (p-1);</code></td><td style="text-align: left;"><span class="math inline"><em>y</em></span> 是 <span class="math inline"><em>r</em> + <em>x</em></span> 的解，所以 <span class="math inline"><em>y</em> ≡ <em>r</em> + <em>x</em> (mod  <em>p</em> − 1)</span>。因此，<span class="math inline"><em>x</em> ≡ <em>y</em> − <em>r</em> (mod  <em>p</em> − 1)</span>。<strong>这是将解 <span class="math inline"><em>y</em></span> 变回 <span class="math inline"><em>x</em></span> 的步骤。</strong></td><td style="text-align: left;">恢复原实例 <span class="math inline"><em>a</em></span> 的解 <span class="math inline"><em>x</em></span>。</td></tr></tbody></table><h3 id="u-和-v-函数的确定">3. <span class="math inline"><em>u</em></span> 和 <span class="math inline"><em>v</em></span> 函数的确定</h3><p>根据 Sherwood 算法的<strong>随机预处理一般方法</strong>：</p><ul><li><strong>原实例 <span class="math inline"><em>x</em></span></strong>: 在离散对数问题中，原实例是<strong>目标值 <span class="math inline"><em>a</em></span></strong>。</li><li><strong>随机变量 <span class="math inline"><em>r</em></span></strong>: 在 <span class="math inline">{0, 1, …, <em>p</em> − 2}</span> 中随机抽取。</li><li><strong>确定性算法 <span class="math inline"><em>f</em></span></strong>: 是 <span class="math inline"><em>l</em><em>o</em><em>g</em><sub><em>g</em>, <em>p</em></sub></span>，即 <span class="math inline"><em>f</em>(<em>a</em>) = <em>x</em></span>。</li></ul><h4 id="预处理函数-u">1. 预处理函数 <span class="math inline"><em>u</em></span></h4><p><span class="math inline"><em>u</em>(<em>a</em>, <em>r</em>)</span> 的作用是将原实例 <span class="math inline"><em>a</em></span> 变换为随机实例 <span class="math inline"><em>c</em></span>。</p><p><span class="math display">$$\text{原实例 } a \xrightarrow{u(a, r)} \text{随机实例 } c$$</span></p><p>根据代码 <span class="math inline"><em>c</em> ← (<em>g</em><sup><em>r</em></sup> (mod  <em>p</em>)) ⋅ <em>a</em> (mod  <em>p</em>)</span>：</p><p><span class="math display"><em>u</em>(<em>a</em>, <em>r</em>) = (<em>g</em><sup><em>r</em></sup> ⋅ <em>a</em>) (mod  <em>p</em>)</span></p><h4 id="后处理函数-v">2. 后处理函数 <span class="math inline"><em>v</em></span></h4><p><span class="math inline"><em>v</em>(<em>r</em>, <em>s</em>)</span> 的作用是将确定性算法的解 <span class="math inline"><em>s</em></span> (即代码中的 <span class="math inline"><em>y</em></span>) 结合随机变量 <span class="math inline"><em>r</em></span>，变换回原实例的解 <span class="math inline"><em>x</em></span>。</p><p><span class="math display">$$\text{随机变量 } r \text{ 和 解 } s \xrightarrow{v(r, s)} \text{原实例的解 } x$$</span></p><p>根据代码 <span class="math inline"><em>x</em> ← (<em>y</em> − <em>r</em>) (mod  <em>p</em> − 1)</span>：</p><p><span class="math display"><em>v</em>(<em>r</em>, <em>s</em>) = (<em>s</em> − <em>r</em>) (mod  <em>p</em> − 1)</span></p><hr /><h3 id="素数判定问题-p124">5.2 素数判定问题 p124</h3><ul><li>方法1：随机因子</li></ul><p><img src="./2025-12-10-15-52-43.png" /> 在 n = 2623 的情况下 <span class="math inline">$2 - \sqrt{2623}$</span>随机选择有98%的概率正确</p><ul><li>方法2：费马小定理的逆否命题</li></ul><p><img src="./2025-12-10-15-55-14.png" /></p><p><img src="./2025-12-10-15-57-53.png" /></p><p>显然这种判定比较不负责（只要有 mod n == 1就是素数 不等于1就不是） 满足<span class="math inline"><em>a</em><sup><em>n</em> − 1</sup><em>m</em><em>o</em><em>d</em> <em>n</em> = 1</span>的数我们称为伪素数</p><p><img src="./2025-12-10-16-00-10.png" /></p><p>也就是说，仅仅使用费马小定理，会有一些合数比较特殊，他们有很多的a做了运算后 均为1。这就迎来了我们的方法3</p><ul><li>方法3： Miller-Rabin测试</li></ul><p><img src="./2025-12-10-16-18-12.png" /></p><p><img src="./2025-12-10-16-21-17.png" /></p><p>判断一个底数 <span class="math inline"><em>a</em></span> 是否为强伪证据： 分解 <span class="math inline"><em>n</em> − 1</span>： 将 <span class="math inline"><em>n</em> − 1</span> 分解为 <span class="math inline">2<sup><em>s</em></sup><em>t</em></span>（<span class="math inline"><em>t</em></span> 为奇数）。 计算初始值： 计算 <span class="math inline"><em>x</em> ← <em>a</em><sup><em>t</em></sup> (mod  <em>n</em>)</span>。 检查条件 ① 和 <span class="math inline"><em>i</em> = 0</span> 的条件 ②： 如果 <span class="math inline"><em>x</em> = 1</span> 或 <span class="math inline"><em>x</em> = <em>n</em> − 1</span>（即 <span class="math inline"><em>a</em><sup><em>t</em></sup> ≡ 1 (mod  <em>n</em>)</span> 或 <span class="math inline"><em>a</em><sup><em>t</em></sup> ≡  − 1 (mod  <em>n</em>)</span>），则 <span class="math inline"><em>a</em></span> 满足条件，返回 <span class="math inline"><em>t</em><em>r</em><em>u</em><em>e</em></span>（<span class="math inline"><em>a</em></span> 是强伪证据）。 循环检查其余的条件 ②： 执行 <span class="math inline"><em>s</em> − 1</span> 次循环，在每次循环中计算 <span class="math inline"><em>x</em> ← <em>x</em><sup>2</sup> (mod  <em>n</em>)</span>（相当于检查 <span class="math inline"><em>a</em><sup>2<sup><em>i</em></sup><em>t</em></sup> (mod  <em>n</em>)</span>）。如果在循环中发现 <span class="math inline"><em>x</em> = <em>n</em> − 1</span>，则满足条件②，返回 <span class="math inline"><em>t</em><em>r</em><em>u</em><em>e</em></span>（<span class="math inline"><em>a</em></span> 是强伪证据）。</p><p>返回 <span class="math inline"><em>f</em><em>a</em><em>l</em><em>s</em><em>e</em></span>：如果所有检查都未通过，则 <span class="math inline"><em>a</em></span> 不是强伪证据。此时 <span class="math inline"><em>a</em></span> 是 <span class="math inline"><em>n</em></span> 是合数的强证据，所以 <span class="math inline"><em>n</em></span> 必定是合数，返回 <span class="math inline"><em>f</em><em>a</em><em>l</em><em>s</em><em>e</em></span>（测试成功）。</p><p>这种方法大大缩减了伪证据数目</p>]]></content>
    
    
    <categories>
      
      <category>course</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>GenAL: Generative Agent for Adaptive Learning</title>
    <link href="/2025/12/10/GenAL-Generative-Agent-for-Adaptive-Learning/"/>
    <url>/2025/12/10/GenAL-Generative-Agent-for-Adaptive-Learning/</url>
    
    <content type="html"><![CDATA[<p><img src="./image.png" /></p><p><img src="./2025-12-10-10-26-20.png" /></p><p><a href="https://ojs.aaai.org/index.php/AAAI/article/view/32038">论文链接</a></p><p>写在前面：</p><p>简单来说，它的核心思想是：<strong>把“推荐题目”这件事变成两个智能体（Agent）之间的配合</strong>。一个负责“宏观思考”（了解学生整体情况），另一个负责“微观教学”（具体挑哪道题）。而且，它不像以前的推荐系统只看题目 ID，它是真的去<strong>读题目的文本内容</strong>，理解题意。</p><h4 id="第一步宏观把脉-全局思考智能体-gta">第一步：宏观把脉 —— 全局思考智能体 (GTA)</h4><p>在推荐新题目之前，系统首先要搞清楚“这个学生现在是什么水平？”。</p><ol type="1"><li><strong>看病历 (Log Memory)</strong>：系统会读取学生过去的答题记录 <span class="math inline">ℋ<sub><em>t</em></sub></span>，不仅看对错，还要看之前做过的题目的<strong>文本内容</strong>。</li><li><strong>做化验 (Educational Tools)</strong>：使用传统的<strong>知识追踪模型 (如 DKT)</strong> 来计算学生对各个知识点的掌握概率（比如“函数”掌握度 60%，“几何”掌握度 80%）[cite: 110, 112]。</li><li><strong>写诊断书 (Reflector)</strong>：这是关键。LLM（大模型）会结合上面的答题记录和掌握概率，生成一份<strong>学生画像 (<span class="math inline"><em>L</em><sub><em>t</em></sub></span>)</strong>。<ul><li>画像里包含：学生的能力评估、学习偏好（比如喜欢抽象题还是应用题）。 *同时，它会反思上一轮推荐得好不好，生成一个新的<strong>推荐策略 (<span class="math inline"><em>R</em><sub><em>t</em></sub></span>)</strong>（比如：“学生基础不牢，下一题应该降低难度，复习前置知识”）。</li></ul></li></ol><h4 id="第二步缩小范围-教学工具-teaching-tools">第二步：缩小范围 —— 教学工具 (Teaching Tools)</h4><p>现在有了策略，但题库里有成千上万道题，不能瞎选。这就需要 <strong>Local Teaching Agent (LTA)</strong> 里的工具来帮忙。</p><ol type="1"><li><strong>查地图 (Knowledge Graph)</strong>：利用<strong>层级知识图谱 (<span class="math inline"><em>G</em></span>)</strong>。</li><li><strong>圈范围</strong>：根据当前要学的知识点，找出它自己以及它的<strong>直接前驱节点</strong>（即学这个知识点之前必须会的那些基础）。</li><li><strong>定候选集</strong>：系统只把属于这些知识点的题目拿出来，形成一个<strong>候选练习集 (<span class="math inline"><em>S</em><sub><em>t</em></sub></span>)</strong>。这就大大缩小了搜索范围，避免大模型产生幻觉或跑题。</li></ol><h4 id="第三步精准决策-推荐器-recommender">第三步：精准决策 —— 推荐器 (Recommender)</h4><p>这是最终做决定的环节。</p><ol type="1"><li><strong>输入信息</strong>：推荐器（也是一个 LLM）接收两个东西：<ul><li>来自第一步的<strong>推荐策略 (<span class="math inline"><em>R</em><sub><em>t</em></sub></span>)</strong>（“要降低难度”）。</li><li>来自第二步的<strong>候选练习集 (<span class="math inline"><em>S</em><sub><em>t</em></sub></span>)</strong> [cite: 169]。</li></ul></li><li><strong>预测下一题 (<span class="math inline"><em>e</em><sub><em>t</em> + 1</sub></span>)</strong>：LLM 结合策略，从候选集里挑出最合适的一道题 [cite: 172]。</li><li><strong>给出理由与预测 (<span class="math inline"><em>F</em><sub><em>t</em> + 1</sub>, <em>A</em><sub><em>t</em> + 1</sub></span>)</strong>：<ul><li>这步很有意思，LLM 不光甩出一道题，还得<strong>解释为什么选这道题</strong>（Reasoning），并且<strong>预测学生能不能做对</strong>。这为下一步的“自我反思”留下了依据 [cite: 175]。</li></ul></li></ol><h4 id="第四步闭环反馈">第四步：闭环反馈</h4><p>学生做完题后，真实结果会和 LLM 的预测结果（<span class="math inline"><em>A</em><sub><em>t</em> + 1</sub></span>）进行对比。如果 LLM 预测学生会做对，结果学生做错了，GTA（第一步那个智能体）就会在下一轮更新策略：“我高估了他，即使是基础题他也做错了，需要更基础的练习”。</p><hr /><h3 id="举个栗子小明的一次函数学习之旅">📝 举个栗子：小明的“一次函数”学习之旅</h3><p>假设现在 <strong>小明</strong> 正在学习初中数学的 <strong>“一次函数 (<span class="math inline"><em>y</em> = <em>k</em><em>x</em> + <em>b</em></span>)”</strong>。</p><p><strong>1. 初始状态 (GTA 工作):</strong> * <strong>记录：</strong> 小明刚做完一道关于“斜率 <span class="math inline"><em>k</em></span>”的题，做错了。 * <strong>工具分析：</strong> 知识追踪模型显示，他对“斜率”的掌握度只有 30%，对“坐标系”掌握度 80%。 * <strong>GTA (大模型) 思考：</strong> “小明虽然懂坐标系，但对斜率的概念很模糊。现在的策略 <span class="math inline"><em>R</em><sub><em>t</em></sub></span> 应该是：<strong>暂停新课，回退一步，先巩固斜率的几何定义。</strong>”</p><p><strong>2. 筛选题目 (Teaching Tools 工作):</strong> * <strong>目标：</strong> 巩固“斜率”。 * <strong>知识图谱：</strong> 查到“斜率”的前置知识是“两点间距离”和“坐标点”。 * <strong>候选集 <span class="math inline"><em>S</em><sub><em>t</em></sub></span>：</strong> 系统从题库里捞出了 50 道相关的题。</p><p><strong>3. 最终推荐 (Recommender 工作):</strong> * <strong>输入：</strong> 策略是“巩固定义，不要太难”，候选集有 50 道题。 * <strong>大模型选择：</strong> 既然不能太难，它排除了那些“给定图像求解析式”的复杂题，选中了一道文字题 <strong><span class="math inline"><em>e</em><sub><em>t</em> + 1</sub></span></strong>： &gt; <em>题目：已知点 A(1, 2) 和点 B(3, 4)，请计算直线 AB 的斜率。</em> * <strong>大模型解释 (<span class="math inline"><em>F</em><sub><em>t</em> + 1</sub></span>):</strong> “推荐这道题是因为它是斜率的最基本计算，直接应用公式，没有复杂的变形，适合当前基础薄弱的小明。” * <strong>预测 (<span class="math inline"><em>A</em><sub><em>t</em> + 1</sub></span>):</strong> “预测他能做对，因为这是基础计算。”</p><p><strong>4. 结果反馈:</strong> * <strong>实际情况：</strong> 小明做对了。 * <strong>下一轮循环：</strong> GTA 看到“预测正确，小明做对了”，于是更新策略：“基础已巩固，下一轮可以尝试稍微难一点的题目，比如结合截距 <span class="math inline"><em>b</em></span> 的考察。”</p><hr /><h3 id="总结">总结</h3><p>GenAL 相比传统推荐系统，最大的亮点在于它<strong>像个真人老师</strong>： 1. 它<strong>读得懂题</strong>（利用 LLM 的语义理解能力）[cite: 14, 26]。 2. 它<strong>有教学逻辑</strong>（先看前置知识，再定难度）。 3. 它<strong>会反思</strong>（每次推荐都要写理由，预测不对就自我修正）。</p><hr /><h1 id="genal-基于生成式智能体的自适应学习框架">📚 GenAL: 基于生成式智能体的自适应学习框架</h1><h2 id="一-当前教育推荐系统存在的问题">一、 当前教育推荐系统存在的问题 🚧</h2><p>论文指出，尽管自适应学习（Adaptive Learning）研究广泛，但现有模型主要依赖于对学习者和练习题的<strong>简单 ID 索引</strong>，导致以下三个核心问题：</p><table><thead><tr class="header"><th style="text-align: left;">问题点</th><th style="text-align: left;">详细描述</th></tr></thead><tbody><tr class="odd"><td style="text-align: left;"><strong>信息利用率不足</strong></td><td style="text-align: left;">传统模型（如基于序列或强化学习的模型）<strong>无法有效利用</strong>练习题的<strong>文本内容</strong>等丰富的语义信息，导致对题目理解肤浅，推荐缺乏深度。</td></tr><tr class="even"><td style="text-align: left;"><strong>泛化性差，难以适应扩展</strong></td><td style="text-align: left;">模型需要针对不同的数据集或不断<strong>扩张的题库</strong>进行重新训练。这使其难以适应在线教育场景中资源快速更新和增长的需求。</td></tr><tr class="odd"><td style="text-align: left;"><strong>稀疏环境下的不稳定</strong></td><td style="text-align: left;">基于训练的强化学习（RL）推荐范式，在学生学习记录<strong>稀疏</strong>或数据量较小时，其推荐性能往往<strong>不稳定</strong>且难以保证效果。</td></tr></tbody></table><hr /><h2 id="二-本文的解决思路与核心方案">二、 本文的解决思路与核心方案 💡</h2><p>本文提出的 <strong>GenAL</strong> 框架旨在通过引入 <strong>大型语言模型 (LLM)</strong>，模仿人类教师的认知与教学过程，从而实现语义驱动、可泛化的自适应学习推荐。</p><table><thead><tr class="header"><th style="text-align: left;">解决思路</th><th style="text-align: left;">具体机制</th><th style="text-align: left;">目标</th></tr></thead><tbody><tr class="odd"><td style="text-align: left;"><strong>分层决策架构</strong></td><td style="text-align: left;">采用<strong>双智能体（Agent）结构，将复杂的教学任务分解：<br>1. 全局思考智能体 (GTA)：制定宏观</strong>教学策略 <span class="math inline"><em>R</em><sub><em>t</em></sub></span>。<br>2. <strong>局部教学智能体 (LTA)</strong>：执行<strong>微观</strong>推荐决策 <span class="math inline"><em>e</em><sub><em>t</em> + 1</sub></span>。</td><td style="text-align: left;">实现教学策略与题目选择的有效解耦和协同。</td></tr><tr class="even"><td style="text-align: left;"><strong>语义驱动推荐</strong></td><td style="text-align: left;">LTA 中的<strong>推荐器（Recommender）是一个 LLM，它直接读取题目内容</strong>的文本信息，并根据 GTA 的策略进行语义级别的推理和选择。</td><td style="text-align: left;">克服传统模型只看 ID 的局限性，实现基于内容的理解推荐。</td></tr><tr class="odd"><td style="text-align: left;"><strong>引入外部知识</strong></td><td style="text-align: left;">LTA 中包含<strong>教学工具（Teaching Tools）</strong>，用于接入教育领域的<strong>先验知识</strong>。</td><td style="text-align: left;">解决 LLM 在特定教育领域的知识短板，避免“幻觉”。</td></tr></tbody></table><hr /><h2 id="三-该思路可能遇到的挑战">三、 该思路可能遇到的挑战 ⚔️</h2><table><thead><tr class="header"><th style="text-align: left;">挑战点</th><th style="text-align: left;">描述</th></tr></thead><tbody><tr class="odd"><td style="text-align: left;"><strong>LLM 的领域幻觉</strong></td><td style="text-align: left;">LLM 在通用领域强大，但在专业的教育知识点上可能缺乏精确性，容易产生不准确的**“幻觉”决策<strong>或</strong>不专业理由**。</td></tr><tr class="even"><td style="text-align: left;"><strong>巨大的搜索空间</strong></td><td style="text-align: left;">如果让 LLM 直接从整个题库中挑选 <span class="math inline"><em>e</em><sub><em>t</em> + 1</sub></span>，其<strong>计算和时间成本不可接受</strong>，效率极低。</td></tr><tr class="odd"><td style="text-align: left;"><strong>缺乏教学闭环与自我修正</strong></td><td style="text-align: left;">缺乏将 LLM 的推荐决策与学生的<strong>真实反馈</strong>进行对比、反思和迭代修正的机制，难以保证教学策略的<strong>长期稳定性</strong>和<strong>有效性</strong>。</td></tr></tbody></table><hr /><h2 id="四-本文克服挑战的手段">四、 本文克服挑战的手段 🛠️</h2><p>GenAL 框架通过设计精巧的工具和反思机制，系统性地解决了上述挑战：</p><table><thead><tr class="header"><th style="text-align: left;">挑战</th><th style="text-align: left;">克服手段</th><th style="text-align: left;">实现细节</th></tr></thead><tbody><tr class="odd"><td style="text-align: left;"><strong>领域幻觉与搜索空间</strong></td><td style="text-align: left;"><strong>知识图谱指导与搜索空间限制</strong></td><td style="text-align: left;"><strong>教学工具（Teaching Tools）</strong>：利用<strong>分层知识图谱</strong> <span class="math inline"><em>G</em></span> 来<strong>限制</strong>推荐范围。候选集 <span class="math inline"><em>S</em><sub><em>t</em></sub></span> 只包括当前目标知识点及其<strong>直接前驱节点</strong>相关的练习题。这既缩小了搜索空间，又用结构化知识<strong>校准了 LLM</strong>。</td></tr><tr class="even"><td style="text-align: left;"><strong>缺乏教学闭环</strong></td><td style="text-align: left;"><strong>反思与预测机制</strong></td><td style="text-align: left;"><strong>推荐器（Recommender）</strong>：强制要求 LLM 在推荐 <span class="math inline"><em>e</em><sub><em>t</em> + 1</sub></span> 的同时，生成推荐<strong>理由</strong> (<span class="math inline"><em>F</em><sub><em>t</em> + 1</sub></span>) 和对学生作答的<strong>预测</strong> (<span class="math inline"><em>A</em><sub><em>t</em> + 1</sub></span>)。<br><strong>全局思考智能体（GTA）</strong>：负责将 <span class="math inline"><em>A</em><sub><em>t</em> + 1</sub></span> 与学生<strong>实际作答</strong>进行对比，通过**反思器（Reflector）<strong>生成新的反思总结 <span class="math inline"><em>L</em><sub><em>t</em></sub></span>，并更新下一轮的教学策略 <span class="math inline"><em>R</em><sub><em>t</em> + 1</sub></span>，形成</strong>“观察-反思-规划-行动”**的闭环。</td></tr></tbody></table><hr /><h2 id="五-实验论证优越性">五、 实验论证优越性 🏆</h2><p>本文通过在实际教育数据集上的对比实验和消融实验，全面论证了 GenAL 框架的优越性：</p><ol type="1"><li><p><strong>推荐有效性 (Recommendation Effectiveness)</strong>：</p><ul><li><strong>结果：</strong> GenAL 在评估自适应推荐效率的指标（如通过更少的问题达成目标知识掌握度）上，<strong>显著优于</strong>传统的序列推荐模型和基于 RL 的推荐模型。</li><li><strong>论证：</strong> 证明了其策略制定和题目选择更高效，能加速学生的学习路径。</li></ul></li><li><p><strong>知识追踪准确性 (Knowledge Tracing Accuracy)</strong>：</p><ul><li><strong>指标：</strong> 使用 <span class="math inline">AUC</span> 和 <span class="math inline">ACC</span> 等指标评估模型对学生<strong>下一个问题作答对错的预测能力</strong>。</li><li><strong>结果：</strong> GenAL 达到了<strong>最高的预测准确率</strong>，表明其能更精确地理解学生的实时学习状态。</li></ul></li><li><p><strong>消融实验 (Ablation Study)</strong>：</p><ul><li>通过移除关键组件（如知识图谱、反思机制），实验结果显示性能大幅下降。</li><li><strong>论证：</strong> 证明了<strong>知识图谱</strong>是克服 LLM 幻觉的关键，而<strong>反思机制</strong>则是保障 GenAL 长期、稳定、高效推荐的根本保障。</li></ul></li></ol>]]></content>
    
    
    <categories>
      
      <category>AAAI2025</category>
      
    </categories>
    
    
  </entry>
  
  
  
  
</search>
