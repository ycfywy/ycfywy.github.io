

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">

  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="ycf">
  <meta name="keywords" content="">
  
    <meta name="description" content="Codeforces 读 txt 井字棋（3×3），判断当前玩家是否获胜 比较简单，直接读取文件然后行遍历、列遍历、对角线遍历。反而是C++和Python的文件读取API不是很熟悉。C++要使用input file stream 1234567891011121314151617181920int main()&#123;  vector&lt;vector&lt;char&gt;&gt;">
<meta property="og:type" content="article">
<meta property="og:title" content="260301">
<meta property="og:url" content="https://ycfywy.github.io/2026/02/28/260301/index.html">
<meta property="og:site_name" content="ycf blog">
<meta property="og:description" content="Codeforces 读 txt 井字棋（3×3），判断当前玩家是否获胜 比较简单，直接读取文件然后行遍历、列遍历、对角线遍历。反而是C++和Python的文件读取API不是很熟悉。C++要使用input file stream 1234567891011121314151617181920int main()&#123;  vector&lt;vector&lt;char&gt;&gt;">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2026-02-28T03:45:14.000Z">
<meta property="article:modified_time" content="2026-03-01T13:59:38.112Z">
<meta property="article:author" content="ycf">
<meta name="twitter:card" content="summary_large_image">
  
  
  
  <title>260301 - ycf blog</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css">



<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1736178_k526ubmyhba.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"ycfywy.github.io","root":"/","version":"1.9.8","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false},"umami":{"src":null,"website_id":null,"domains":null,"start_time":"2024-01-01T00:00:00.000Z","token":null,"api_server":null}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 8.1.1"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>ycf blog</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/images/index.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="260301"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2026-02-28 11:45" pubdate>
          2026年2月28日 中午
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          2.9k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          24 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">260301</h1>
            
            
              <div class="markdown-body">
                
                <h2 id="codeforces">Codeforces</h2>
<h3 id="读-txt-井字棋33判断当前玩家是否获胜">读 txt 井字棋（3×3），判断当前玩家是否获胜</h3>
<p>比较简单，直接读取文件然后行遍历、列遍历、对角线遍历。反而是C++和Python的文件读取API不是很熟悉。C++要使用input file stream</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span>&#123;<br>  vector&lt;vector&lt;<span class="hljs-type">char</span>&gt;&gt; <span class="hljs-built_in">board</span>(<span class="hljs-number">3</span>, <span class="hljs-built_in">vector</span>&lt;<span class="hljs-type">char</span>&gt;(<span class="hljs-number">3</span>));<br>  <span class="hljs-function">ifstream <span class="hljs-title">file</span><span class="hljs-params">(filename)</span></span>;<br><br>  <span class="hljs-keyword">if</span>(!file.<span class="hljs-built_in">isopen</span>())&#123;<br>    <br>  &#125;<br>  <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">3</span>; ++i) &#123;<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> j = <span class="hljs-number">0</span>; j &lt; <span class="hljs-number">3</span>; ++j) &#123;<br>        <span class="hljs-comment">// &gt;&gt; 会自动过滤空格和换行</span><br>        <span class="hljs-keyword">if</span> (!(file &gt;&gt; board[i][j])) &#123;<br>            <span class="hljs-keyword">break</span>; <br>        &#125;<br>    &#125;<br>  &#125;<br>    file.<span class="hljs-built_in">close</span>();<br>&#125;<br><br><br></code></pre></td></tr></table></figure>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs py"><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">read_board</span>(<span class="hljs-params">filename</span>):<br>  board = []<br>  <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(filename, <span class="hljs-string">&#x27;r&#x27;</span>)  <span class="hljs-keyword">as</span> f:<br>    <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> f:<br>      row = line.strip().split() <span class="hljs-comment"># 会根据空格划分成list</span><br>      <span class="hljs-keyword">if</span> row:<br>        board.append(row)<br><br></code></pre></td></tr></table></figure>
<h3 id="b">2189B</h3>
<p><a target="_blank" rel="noopener" href="https://codeforces.com/problemset/problem/2189/B">The Curse of the Frog</a></p>
<p>这个问题等效于最小化“回退（rollback）”的次数，直到青蛙到达一个 <span class="math inline"> ≥ <em>x</em></span> 的点。（这是因为在最后一次跳跃时，青蛙不需要跳满 <span class="math inline"><em>a</em><sub><em>i</em></sub></span> 的长度，只要能刚好踩到 <span class="math inline"><em>x</em></span> 即可）。我们假设青蛙每次使用第 <span class="math inline"><em>i</em></span> 种跳跃时，总是向前跳足 <span class="math inline"><em>a</em><sub><em>i</em></sub></span> 单位。</p>
<p>第一阶段：消耗“免费”次数首先，青蛙可以利用第 <span class="math inline"><em>i</em></span> 种跳跃方式跳 <span class="math inline"><em>b</em><sub><em>i</em></sub> − 1</span> 次，而不需要承担任何回退代价。为了走得最远，我们计算所有跳跃方式中能达到的最大“免费距离”：<span class="math inline">max (<em>a</em><sub><em>i</em></sub> ⋅ (<em>b</em><sub><em>i</em></sub> − 1))</span>。令 <span class="math inline"><em>r</em></span> 为达到目标 <span class="math inline"><em>x</em></span> 还剩下的剩余距离。逻辑判定 1：如果 <span class="math inline">max (<em>a</em><sub><em>i</em></sub> ⋅ (<em>b</em><sub><em>i</em></sub> − 1)) ≥ <em>x</em></span>，那么剩余距离 <span class="math inline"><em>r</em> ≤ 0</span>，意味着回退次数为 0。</p>
<p>第二阶段：进入“回退循环”当免费次数用完后，任何后续的跳跃都会触发回退。循环机制：注意，一旦我们为了使用第 <span class="math inline"><em>i</em></span> 种跳跃而承担了一次 <span class="math inline"><em>c</em><sub><em>i</em></sub></span> 的回退，我们接下来又可以连续使用该跳跃 <span class="math inline"><em>b</em><sub><em>i</em></sub></span> 次（包含触发回退的那次及其后的 <span class="math inline"><em>b</em><sub><em>i</em></sub> − 1</span> 次免费跳跃）。净位移（Net Gain）：完成这一个“回退周期”后，青蛙的位置实际上前进了：<span class="math display"><em>m</em><sub><em>i</em></sub> = (<em>a</em><sub><em>i</em></sub> ⋅ <em>b</em><sub><em>i</em></sub>) − <em>c</em><sub><em>i</em></sub></span>贪心策略：既然每次回退的代价都是 1，那么我们显然应该选择那个能提供最大净位移的跳跃方式。</p>
<p>第三阶段：最终判定与计算设 <span class="math inline"><em>m</em> = max (<em>a</em><sub><em>i</em></sub> ⋅ <em>b</em><sub><em>i</em></sub> − <em>c</em><sub><em>i</em></sub>)</span> 为所有跳跃方式中最大的净位移。无法到达判定：如果 <span class="math inline"><em>m</em> ≤ 0</span>，说明即使发生回退并跳满次数，青蛙也无法继续向前推进（甚至可能倒退）。此时由于第一阶段也没能到达 <span class="math inline"><em>x</em></span>，结论是无法到达，输出 -1。计算最小回退次数：如果 <span class="math inline"><em>m</em> &gt; 0</span>，我们需要通过回退来填补剩下的距离 <span class="math inline"><em>r</em></span>。所需的总回退次数为：<span class="math display">$$\lceil \frac{r}{m} \rceil$$</span>（即 <span class="math inline"><em>r</em>/<em>m</em></span> 的向上取整）。</p>
<h3 id="leetcode-1689">Leetcode 1689</h3>
<p>https://leetcode.cn/problems/partitioning-into-minimum-number-of-deci-binary-numbers/description/?envType=daily-question&amp;envId=2026-03-01</p>
<p>比较简单就不写了</p>
<h2 id="ai-learning">AI Learning</h2>
<h3 id="flashattention-跟普通-attention-的差异实现里-qktsoftmaxpv-这几步怎么落">FlashAttention 跟普通 attention 的差异？实现里 QK^T、softmax、PV 这几步怎么落</h3>
<p>通过数学优化，流式计算。</p>
<h3 id="d-并行里-dpddp-你怎么理解实际落地时通信瓶颈一般卡在哪些环节">3D 并行里 DP/DDP 你怎么理解；实际落地时通信瓶颈一般卡在哪些环节</h3>
<p>先讲解一下并行：</p>
<ul>
<li>数据并行Data Parallelism, DP：模型不动，数据拆分，各跑各的，最后对答案。每一张参与训练的显卡（GPU）里，都装入一个一模一样的模型副本。把一个 Batch 的训练数据均匀切开。例如：你设置的 Batch Size 是 128，有 4 张显卡。那么每张卡只拿其中的 32 个样本。并行计算然后汇总梯度。</li>
<li>张量并行Tensor Parallelism, TP： 它直接解决了单张显卡塞不下单个巨大层（Layer）的问题。把神经网络里的矩阵乘法拆分到多张显卡上并行计算。</li>
<li>流水线并行：当你的模型太大（比如 175B 的 GPT-3），单张显卡甚至 8 张显卡的显存加起来都装不下整个模型的所有层时，你就必须跨机器。假设你的 14B 模型有 40 层 Transformer：GPU 0：负责第 1 到 10 层。GPU 1：负责第 11 到 20 层。GPU 2：负责第 21 到 30 层。GPU 3：负责第 31 到 40 层。</li>
<li>分布式数据并行 DDP (DistributedDataParallel)：再DP中GPU 像个保姆：它要把数据分给所有卡，等大家算完梯度后，所有卡再把梯度传回给主卡。主卡的网络/总线带宽瞬间被塞满，而其他卡在闲着等主卡汇总。这种“一对多”的模式随着显卡增加，效率会线性下降。因此改进DP，Ring All-Reduce通信，平衡了带宽压力。</li>
</ul>
<p>讲解一下DP 、 DDP在传输上的不同：</p>
<p>DP 采用的是“主从模式” (Master-Slave)。GPU 0 是“班长”，负责所有的杂活。</p>
<ul>
<li>分发数据 (Scatter)：GPU 0 读取 128 条数据，自己留 32 条，把剩下的 <span class="math inline">32 × 3</span> 条通过 PCIe 总线分给 GPU 1, 2, 3。</li>
<li>分发模型 (Replicate)：GPU 0 把自己最新的模型参数，完整地复制三份，分给其他三张卡。（每一步都要复制，非常耗时）。</li>
<li>并行计算 (Forward)：4 张卡同时做前向传播，算出各自的输出。</li>
<li>收集输出 (Gather)：GPU 1, 2, 3 把计算结果传回给 GPU 0。GPU 0 汇总后计算总的 Loss。</li>
<li>反向传播 (Backward)：GPU 0 把 Loss 散发给各卡，各卡算出各自的梯度 <span class="math inline"><em>g</em><sub>0</sub>, <em>g</em><sub>1</sub>, <em>g</em><sub>2</sub>, <em>g</em><sub>3</sub></span>。</li>
<li>梯度汇总 (Reduce)：GPU 1, 2, 3 把梯度全部传回给 GPU 0。</li>
<li>参数更新 (Update)：GPU 0 在自己身上算出平均梯度，更新自己的权重 <span class="math inline"><em>W</em></span>。</li>
</ul>
<p>瓶颈在哪里？通信压力：所有的流量都挤在 GPU 0 的带宽上。GPU 利用率：GPU 1, 2, 3 在等待 GPU 0 汇总梯度和分发模型时，只能“干等”。显存不均：GPU 0 额外承担了汇总、更新的任务，显存占用远高于其他卡。</p>
<p>DDP (DistributedDataParallel) 的计算与通信过程DDP 采用的是“去中心化模式”(Multi-Process)。每张卡都是独立的“老板”。</p>
<ul>
<li>独立读数：4 个进程同时启动。利用 DistributedSampler，GPU 0 直接从硬盘读前 32 条，GPU 1 读次 32 条……（无需主卡分发）。</li>
<li>并行计算 (Forward)：每张卡直接用本地的模型算前向传播。</li>
<li>边算边传 (Backward &amp; Ring All-Reduce)：这是 DDP 的杀手锏。当反向传播算完最后一层 <span class="math inline"><em>L</em><sub>3</sub></span> 的梯度时，GPU 0 不需要等 <span class="math inline"><em>L</em><sub>1</sub></span> 算完。它立刻把 <span class="math inline"><em>L</em><sub>3</sub></span> 的梯度传给邻居 GPU 1，同时接收来自 GPU 3 的梯度。通过这个“环形接力”（Ring All-Reduce），当第一层 <span class="math inline"><em>L</em><sub>1</sub></span> 算完时，最后一层的梯度可能已经同步完成了。</li>
<li>本地更新：通信结束后，每张卡手里的梯度都是全量平均梯度，各自更新本地参数。</li>
</ul>
<h3 id="bfp16-权重大概多大训练还要加哪些int8-大概能省多少">14B：FP16 权重大概多大；训练还要加哪些；INT8 大概能省多少</h3>
<p>先来讲讲LLM训练的时候显存有哪些内容：</p>
<ul>
<li>模型权重： 必须常驻内存</li>
<li>激活值 (Activations)： 在算出来Loss之后，需要反向传播计算每一层weight的gradient，因此必须保留activations。model的layer/hidden_dim, input的batch_size / seq_length越大，占用的内存越大。</li>
<li>梯度 (Gradients)：大小与weight一样。</li>
<li>优化器状态 (Optimizer States)：现在主流的optimizer是AdamW：基于二阶动量的优化器。他们的参数量和weight一样，但是一般来说精度更高，使用FP32。</li>
</ul>
<p>这里再具体讲解两点内容：</p>
<ul>
<li>Activations的计算：</li>
</ul>
<table>
<thead>
<tr class="header">
<th>模块组件</th>
<th>激活值计算方式</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>LayerNorm</td>
<td><span class="math inline">2 × <em>b</em> × <em>s</em> × <em>h</em></span></td>
</tr>
<tr class="even">
<td>MLP</td>
<td><span class="math inline">2 × <em>b</em> × <em>s</em> × <em>h</em></span></td>
</tr>
<tr class="odd">
<td>Attention</td>
<td><span class="math inline">2 × <em>b</em> × <em>s</em><sup>2</sup> × heads</span> (因为有score矩阵)</td>
</tr>
<tr class="even">
<td>激活函数</td>
<td><span class="math inline"><em>b</em> × <em>s</em> × <em>h</em></span></td>
</tr>
</tbody>
</table>
<ul>
<li>一个实际的14B FP16 例子来讲解显存：</li>
</ul>
<table>

<thead>
<tr class="header">
<th>类型</th>
<th>大小</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>weight</td>
<td><span class="math inline">14 × 10<sup>9</sup> 参数 × 2 字节 ≈ 28 GB</span></td>
</tr>
<tr class="even">
<td>Activations</td>
<td>不定</td>
</tr>
<tr class="odd">
<td>Gradients</td>
<td>28GB</td>
</tr>
<tr class="even">
<td>Optimizer States</td>
<td>112GB ( <span class="math inline">14<em>B</em> × 8</span> 字节) FP32精度</td>
</tr>
</tbody>
</table>
<p>显然按照这种说法，我们几乎不可能训练一个模型了，太天文数字了。事实上有很多很有用的优化方法，帮我们降低显存占用：</p>
<ul>
<li>Gradient Checkpointing / Activation Checkpointing：时间换空间，前向传播时不保存所有层的激活值，只保存一部分。等到反向传播需要某层数据时，临时重新计算一遍。</li>
<li>Flash Attention： 专门针对 Attention 矩阵的 <span class="math inline"><em>s</em><sup>2</sup></span> 爆炸问题。它通过分块计算，不需要在显存里显式存储那个巨大的 <span class="math inline"><em>s</em> × <em>s</em></span> 矩阵。 ==关于flash attention的介绍看上面的讨论==</li>
<li>混合精度训练 (FP16/BF16)： 将每个激活值从 4 字节（FP32）降到 2 字节（FP16），直接节省 50%</li>
</ul>
<h3 id="torch.contiguous-干嘛的推理为什么在意连续性">torch.contiguous() 干嘛的？推理为什么在意连续性</h3>
<ul>
<li>Transpose: 它不会移动内存里的任何数据，只是修改了tensor的Metadata: stride(a, b)。a代表进入下一行需要走几步，b代表进入下一列需要走几步。一旦 Stride 的顺序不再是递减的（即：大维度的步长 &lt; 小维度的步长），PyTorch 就会把这个 Tensor 标记为 is_contiguous = False。</li>
<li>View: 改变tensor观察的方式，把一段连续的存储重新划分。View默认tensor存储是连续的。因此如果你做了transpose之后坐view，需要执行transpose().contiguous().view()来把原来的tensor拷贝一下，保证存储的连续。</li>
<li>Reshape: 如果张量是连续的，reshape 效果等同于 view; 如果张量是不连续的（比如刚转置完），reshape 会自动帮你调用 .contiguous()，把数据拷贝一份排好序，再进行重塑。</li>
</ul>
<p>举个例子：</p>
<p>在内存里，它是水平排开的：[0, 1, 2, 3, 4, 5]。Contiguous</p>
<p><span class="math display">$$\begin{bmatrix}
0 &amp; 1 &amp; 2 \\
3 &amp; 4 &amp; 5
\end{bmatrix}$$</span></p>
<p>transpose(0, 1)</p>
<p><span class="math display">$$\begin{bmatrix}
0 &amp; 3 \\
1 &amp; 4 \\
2 &amp; 5
\end{bmatrix}$$</span></p>
<p>内存里的顺序依然是 [0, 1, 2, 3, 4, 5]。但是变得不连续了，逻辑上的存储03连续，但是物理上不连续。</p>
<p>reshape(-1)</p>
<p>reshape 发现数据不连续，先偷偷调用了 .contiguous()。 内存里重新开辟空间，把数据排成 [0, 3, 1, 4, 2, 5]</p>
<ul>
<li>pytorch关于contigous的定义：</li>
</ul>
<p>对于一个 <span class="math inline"><em>n</em></span> 维张量，其每一个维度的步长 <span class="math inline"><em>s</em><em>t</em><em>r</em><em>i</em><em>d</em><em>e</em>[<em>i</em>]</span> 必须等于后一个维度的步长乘以该维度的长度，即 <span class="math inline"><em>s</em><em>t</em><em>r</em><em>i</em><em>d</em><em>e</em>[<em>i</em>] = <em>s</em><em>t</em><em>r</em><em>i</em><em>d</em><em>e</em>[<em>i</em> + 1] × <em>s</em><em>i</em><em>z</em><em>e</em>[<em>i</em> + 1]</span>。</p>
<p>举个例子：创建一个 Shape = (2, 3, 4) 的张量。Size (Shape): (d0=2, d1=3, d2=4)。最内层的stride = 1,然后依次计算得到：Stride = (12, 4, 1)</p>
<h3 id="交叉熵损失解释怎么写">交叉熵损失：解释/怎么写</h3>
<p><span class="math display">$$L = -\sum_{i=1}^{C} y_i \log(\hat{y}_i)$$</span></p>
<p>积分形式：</p>
<p><span class="math display"><em>H</em>(<em>p</em>, <em>q</em>) =  − ∫<sub><em>X</em></sub><em>p</em>(<em>x</em>)log <em>q</em>(<em>x</em>)<em>d</em><em>x</em></span></p>
<p>在真实分布为 <span class="math inline"><em>p</em></span> 的情况下，使用不完美的分布 <span class="math inline"><em>q</em></span> 来编码信息所需的平均长度。</p>
<p>对于分类任务，只有一个label是1，因此L退化为<span class="math inline"><em>L</em> =  − log (<em>ŷ</em><sub><em>c</em><em>o</em><em>r</em><em>r</em><em>e</em><em>c</em><em>t</em></sub>)</span> Pytorch中的nn.CrossEntropyLoss()包装了LogSoftmax + NLLLoss。</p>
<p><span class="math display">$$\text{LogSoftmax}(x_i) = \log \left( \frac{e^{x_i}}{\sum_{j} e^{x_j}} \right)$$</span></p>
<p>Negative Log-Likelihood Loss：是根据标签，把对应位置的那个预测值“抠”出来，然后加个负号。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs py"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><br>log_softmax = nn.LogSoftmax(dim=<span class="hljs-number">1</span>)<br>nll_loss = nn.NLLLoss()<br><br>logits = torch.tensor([[<span class="hljs-number">2.0</span>, <span class="hljs-number">1.0</span>, <span class="hljs-number">0.1</span>]]) <span class="hljs-comment"># 原始输出</span><br>target = torch.tensor([<span class="hljs-number">0</span>])              <span class="hljs-comment"># 真实类别是索引0</span><br><br><span class="hljs-comment"># 先取log_softmax，再算nll_loss</span><br>output = nll_loss(log_softmax(logits), target)<br><span class="hljs-built_in">print</span>(output) <span class="hljs-comment"># tensor(0.4170)</span><br><br></code></pre></td></tr></table></figure>
<h3 id="线性回归用-sgd更新公式怎么推怎么写">线性回归用 SGD：更新公式怎么推/怎么写</h3>
<p>SGD其实比较简单，就是随机梯度下降。选出来1个或者一个batch样本，算出来loss，然后更新参数，没了。相比于Adam之类的 还需要计算动量来做修正，加速梯度下降。如此朴实无华。</p>
<p><span class="math display"><em>θ</em><sub><em>t</em> + 1</sub> = <em>θ</em><sub><em>t</em></sub> − <em>η</em> ⋅ ∇<em>J</em>(<em>θ</em><sub><em>t</em></sub>; <em>x</em><sup>(<em>i</em>)</sup>, <em>y</em><sup>(<em>i</em>)</sup>)</span></p>
<p>考虑一个线性回归的模型，feature_num = 1的最简单案例：</p>
<p><span class="math display"><em>ŷ</em> = <em>w</em> ⋅ <em>x</em> + <em>b</em></span></p>
<p>对单个样本，有： <span class="math display">$$L = \frac{1}{2}(\hat{y}_i - y_i)^2 = \frac{1}{2}(w \cdot x_i + b - y_i)^2$$</span></p>
<p><span class="math display">$$\frac{\partial L}{\partial w} = \frac{\partial L}{\partial \hat{y}_i} \cdot \frac{\partial \hat{y}_i}{\partial w}$$</span></p>
<p><span class="math display">$$\frac{\partial L}{\partial b} = (\hat{y}_i - y_i) \cdot 1$$</span></p>
<p><span class="math inline">$\frac{\partial L}{\partial \hat{y}_i} = (\hat{y}_i - y_i)$</span> <span class="math inline">$\frac{\partial \hat{y}_i}{\partial w} = x_i$</span>结果：<span class="math inline"><em>g</em><sub><em>w</em></sub> = (<em>ŷ</em><sub><em>i</em></sub> − <em>y</em><sub><em>i</em></sub>) ⋅ <em>x</em><sub><em>i</em></sub></span></p>
<p><span class="math display"><em>w</em><sub><em>n</em><em>e</em><em>w</em></sub> = <em>w</em><sub><em>o</em><em>l</em><em>d</em></sub> − <em>η</em> ⋅ (<em>ŷ</em><sub><em>i</em></sub> − <em>y</em><sub><em>i</em></sub>) ⋅ <em>x</em><sub><em>i</em></sub></span><span class="math display"><em>b</em><sub><em>n</em><em>e</em><em>w</em></sub> = <em>b</em><sub><em>o</em><em>l</em><em>d</em></sub> − <em>η</em> ⋅ (<em>ŷ</em><sub><em>i</em></sub> − <em>y</em><sub><em>i</em></sub>)</span></p>
<h2 id="english">English</h2>
<h2 id="ds杂谈">DS杂谈</h2>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%97%A5%E8%AE%B0/" class="category-chain-item">日记</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>260301</div>
      <div>https://ycfywy.github.io/2026/02/28/260301/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>ycf</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2026年2月28日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-cc-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2026/03/01/260302/" title="260302">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">260302</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2026/02/28/260228/" title="260228">
                        <span class="hidden-mobile">260228</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  









    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/5.0.0/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        if (!window.MathJax) {
          window.MathJax = {
            tex    : {
              inlineMath: { '[+]': [['$', '$']] }
            },
            loader : {
              load: ['ui/lazy']
            },
            options: {
              renderActions: {
                insertedScript: [200, () => {
                  document.querySelectorAll('mjx-container').forEach(node => {
                    let target = node.parentNode;
                    if (target.nodeName.toLowerCase() === 'li') {
                      target.parentNode.classList.add('has-jax');
                    }
                  });
                }, '', false]
              }
            }
          };
        } else {
          MathJax.startup.document.state(0);
          MathJax.texReset();
          MathJax.typeset();
          MathJax.typesetPromise();
        }

        Fluid.events.registerRefreshCallback(function() {
          if ('MathJax' in window && MathJax.startup.document && typeof MathJax.startup.document.state === 'function') {
            MathJax.startup.document.state(0);
            MathJax.texReset();
            MathJax.typeset();
            MathJax.typesetPromise();
          }
        });
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js" ></script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
