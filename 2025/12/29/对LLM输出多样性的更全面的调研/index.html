

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">

  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="ycf">
  <meta name="keywords" content="">
  
    <meta name="description" content="阅读总结   这是一篇来自NeurIPS2025的Best paper。该文章系统地讨论了LLM输出多样性的问题，提出Artificial Hivemind现象：在开放式问题中，同类模型的回答具有相似性；不同模型之间也有相似性。这种LLM同质化的现象值得我们警惕和研究。   更重要的是，作者在oral talk中对LLM diversity这个领域做了很全面的综述，包括 具有多样性的数据、多样">
<meta property="og:type" content="article">
<meta property="og:title" content="对LLM输出多样性的更全面的调研">
<meta property="og:url" content="https://ycfywy.github.io/2025/12/29/%E5%AF%B9LLM%E8%BE%93%E5%87%BA%E5%A4%9A%E6%A0%B7%E6%80%A7%E7%9A%84%E6%9B%B4%E5%85%A8%E9%9D%A2%E7%9A%84%E8%B0%83%E7%A0%94/index.html">
<meta property="og:site_name" content="ycf blog">
<meta property="og:description" content="阅读总结   这是一篇来自NeurIPS2025的Best paper。该文章系统地讨论了LLM输出多样性的问题，提出Artificial Hivemind现象：在开放式问题中，同类模型的回答具有相似性；不同模型之间也有相似性。这种LLM同质化的现象值得我们警惕和研究。   更重要的是，作者在oral talk中对LLM diversity这个领域做了很全面的综述，包括 具有多样性的数据、多样">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://ycfywy.github.io/2025/12/29/%E5%AF%B9LLM%E8%BE%93%E5%87%BA%E5%A4%9A%E6%A0%B7%E6%80%A7%E7%9A%84%E6%9B%B4%E5%85%A8%E9%9D%A2%E7%9A%84%E8%B0%83%E7%A0%94/xxx.png">
<meta property="og:image" content="https://ycfywy.github.io/2025/12/29/%E5%AF%B9LLM%E8%BE%93%E5%87%BA%E5%A4%9A%E6%A0%B7%E6%80%A7%E7%9A%84%E6%9B%B4%E5%85%A8%E9%9D%A2%E7%9A%84%E8%B0%83%E7%A0%94/2025-12-30-18-34-00.png">
<meta property="og:image" content="https://ycfywy.github.io/2025/12/29/%E5%AF%B9LLM%E8%BE%93%E5%87%BA%E5%A4%9A%E6%A0%B7%E6%80%A7%E7%9A%84%E6%9B%B4%E5%85%A8%E9%9D%A2%E7%9A%84%E8%B0%83%E7%A0%94/2025-12-30-18-41-12.png">
<meta property="og:image" content="https://ycfywy.github.io/2025/12/29/%E5%AF%B9LLM%E8%BE%93%E5%87%BA%E5%A4%9A%E6%A0%B7%E6%80%A7%E7%9A%84%E6%9B%B4%E5%85%A8%E9%9D%A2%E7%9A%84%E8%B0%83%E7%A0%94/2025-12-30-18-43-53.png">
<meta property="og:image" content="https://ycfywy.github.io/2025/12/29/%E5%AF%B9LLM%E8%BE%93%E5%87%BA%E5%A4%9A%E6%A0%B7%E6%80%A7%E7%9A%84%E6%9B%B4%E5%85%A8%E9%9D%A2%E7%9A%84%E8%B0%83%E7%A0%94/2025-12-30-19-05-52.png">
<meta property="og:image" content="https://ycfywy.github.io/2025/12/29/%E5%AF%B9LLM%E8%BE%93%E5%87%BA%E5%A4%9A%E6%A0%B7%E6%80%A7%E7%9A%84%E6%9B%B4%E5%85%A8%E9%9D%A2%E7%9A%84%E8%B0%83%E7%A0%94/2025-12-30-16-56-48.png">
<meta property="og:image" content="https://ycfywy.github.io/2025/12/29/%E5%AF%B9LLM%E8%BE%93%E5%87%BA%E5%A4%9A%E6%A0%B7%E6%80%A7%E7%9A%84%E6%9B%B4%E5%85%A8%E9%9D%A2%E7%9A%84%E8%B0%83%E7%A0%94/2025-12-30-16-59-12.png">
<meta property="og:image" content="https://ycfywy.github.io/2025/12/29/%E5%AF%B9LLM%E8%BE%93%E5%87%BA%E5%A4%9A%E6%A0%B7%E6%80%A7%E7%9A%84%E6%9B%B4%E5%85%A8%E9%9D%A2%E7%9A%84%E8%B0%83%E7%A0%94/2025-12-30-17-35-17.png">
<meta property="og:image" content="https://ycfywy.github.io/2025/12/29/%E5%AF%B9LLM%E8%BE%93%E5%87%BA%E5%A4%9A%E6%A0%B7%E6%80%A7%E7%9A%84%E6%9B%B4%E5%85%A8%E9%9D%A2%E7%9A%84%E8%B0%83%E7%A0%94/2025-12-30-17-36-45.png">
<meta property="og:image" content="https://ycfywy.github.io/2025/12/29/%E5%AF%B9LLM%E8%BE%93%E5%87%BA%E5%A4%9A%E6%A0%B7%E6%80%A7%E7%9A%84%E6%9B%B4%E5%85%A8%E9%9D%A2%E7%9A%84%E8%B0%83%E7%A0%94/2025-12-30-18-01-02.png">
<meta property="og:image" content="https://ycfywy.github.io/2025/12/29/%E5%AF%B9LLM%E8%BE%93%E5%87%BA%E5%A4%9A%E6%A0%B7%E6%80%A7%E7%9A%84%E6%9B%B4%E5%85%A8%E9%9D%A2%E7%9A%84%E8%B0%83%E7%A0%94/2025-12-30-18-06-59.png">
<meta property="article:published_time" content="2025-12-29T15:57:42.000Z">
<meta property="article:modified_time" content="2025-12-30T12:21:35.826Z">
<meta property="article:author" content="ycf">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://ycfywy.github.io/2025/12/29/%E5%AF%B9LLM%E8%BE%93%E5%87%BA%E5%A4%9A%E6%A0%B7%E6%80%A7%E7%9A%84%E6%9B%B4%E5%85%A8%E9%9D%A2%E7%9A%84%E8%B0%83%E7%A0%94/xxx.png">
  
  
  
  <title>对LLM输出多样性的更全面的调研 - ycf blog</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css">



<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1736178_k526ubmyhba.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"ycfywy.github.io","root":"/","version":"1.9.8","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false},"umami":{"src":null,"website_id":null,"domains":null,"start_time":"2024-01-01T00:00:00.000Z","token":null,"api_server":null}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 8.1.1"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>ycf blog</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/images/index.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="对LLM输出多样性的更全面的调研"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2025-12-29 23:57" pubdate>
          2025年12月29日 晚上
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          3.3k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          28 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">对LLM输出多样性的更全面的调研</h1>
            
            
              <div class="markdown-body">
                
                <h2 id="阅读总结">阅读总结</h2>
<p>  这是一篇来自NeurIPS2025的Best paper。该文章系统地讨论了LLM输出多样性的问题，提出Artificial Hivemind现象：在开放式问题中，同类模型的回答具有相似性；不同模型之间也有相似性。这种LLM同质化的现象值得我们警惕和研究。</p>
<p>  更重要的是，作者在oral talk中对LLM diversity这个领域做了很全面的综述，包括 具有多样性的数据、多样性的解码策略、在训练过程中引入多样性、更加严谨的评估模型输出多样性的指标。 <img src="./xxx.png" srcset="/img/loading.gif" lazyload /></p>
<p>值得注意的是，其中关于采样策略的几篇文章我们都有读过。虽然是自己寻找的论文，但能够不偏离主流研究，说明我们读的文章还是有价值的。</p>
<table>

<thead>
<tr class="header">
<th>分类</th>
<th>论文名称</th>
<th>核心研究方向</th>
<th>arXiv 链接</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>具有多样性的数据</strong></td>
<td><strong>SPARQ: Synthetic Problem Generation for Reasoning via Quality-Diversity Algorithms</strong></td>
<td>利用质量-多样性算法生成高难度、非重复的合成推理数据。</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2506.06499">2506.06499</a></td>
</tr>
<tr class="even">
<td></td>
<td><strong>Prismatic Synthesis: Gradient-based Data Diversification Boosts Generalization in LLM Reasoning</strong></td>
<td>提出 G-Vendi 指标，利用模型梯度熵来量化并提升训练数据的多样性。</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2505.20161">2505.20161</a></td>
</tr>
<tr class="odd">
<td></td>
<td><strong>Diverse, not Short: A Length-Controlled Data Selection Strategy for Improving Response Diversity</strong></td>
<td>解决多样性筛选中易偏向“短文本”的偏见，通过长度控制提升表达力。</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2505.16245">2505.16245</a></td>
</tr>
<tr class="even">
<td><strong>多样性的解码策略</strong></td>
<td><strong>TURNING UP THE HEAT: MIN- SAMPLING FOR CREATIVE AND COHERENT LLM OUTPUTS</strong></td>
<td>提出 Min-p 采样，通过动态阈值在保持连贯性的同时大幅提升创意多样性。</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2407.01082">2407.01082</a></td>
</tr>
<tr class="odd">
<td></td>
<td><strong>VERBALIZED SAMPLING: HOW TO MITIGATE MODE COLLAPSE AND UNLOCK LLM DIVERSITY</strong></td>
<td>通过“口语化”提示词在推理阶段解锁模型原本被对齐算法压缩的多样性。</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2510.01171">2510.01171</a></td>
</tr>
<tr class="even">
<td></td>
<td><strong>Negative Token Merging: Image-based Adversarial Feature Guidance</strong></td>
<td>虽然偏向图像生成，但其对抗性特征引导思路为减少生成内容的同质化提供了新策略。</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2412.01339">2412.01339</a></td>
</tr>
<tr class="odd">
<td><strong>在训练过程中引入多样性</strong></td>
<td><strong>Creative Preference Optimization (CrPO)</strong></td>
<td>将多个维度的创意指标直接注入偏好优化目标中，超越单一的质量指标。</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2505.14442">2505.14442</a></td>
</tr>
<tr class="even">
<td></td>
<td><strong>SPECTRUM TUNING: POST-TRAINING FOR DISTRIBUTIONAL COVERAGE AND STEERABILITY</strong></td>
<td>针对指令微调导致的多样性坍缩，通过频谱调优恢复分布覆盖面。</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2510.06084">2510.06084</a></td>
</tr>
<tr class="odd">
<td></td>
<td><strong>Modifying LLM Post-Training for Diverse Creative Writing</strong></td>
<td>修改 DPO/ORPO 算法逻辑，在提升生成质量的同时减少输出的重复感。</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2503.17126">2503.17126</a></td>
</tr>
<tr class="even">
<td></td>
<td><strong>Diverse Preference Optimization (DivPO)</strong></td>
<td>在偏好对选择中加入多样性准则，鼓励模型学习更稀有的高质量表达。</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2501.18101">2501.18101</a></td>
</tr>
<tr class="odd">
<td><strong>更加严谨的评估多样性</strong></td>
<td><strong>NOVELTYBENCH: Evaluating Language Models for Human-like Diversity</strong></td>
<td>构建全新基准，评估模型在主观/开放问题上是否能像人类一样提供多种解法。</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2504.05228">2504.05228</a></td>
</tr>
<tr class="even">
<td></td>
<td><strong>EVALUATING THE DIVERSITY AND QUALITY OF LLM GENERATED CONTENT</strong></td>
<td>提出“有效语义多样性”概念，剔除那些多样但低质（乱码）的输出干扰。</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2504.12522">2504.12522</a></td>
</tr>
<tr class="odd">
<td></td>
<td><strong>QUDSIM: Quantifying Discourse Similarities in LLM-Generated Text</strong></td>
<td>深入话语结构层面，量化模型在逻辑推进方式上的相似度（而非仅字面重复）。</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2504.09373">2504.09373</a></td>
</tr>
<tr class="even">
<td></td>
<td><strong>CreativityPrism: A Holistic Benchmark for LLM Creativity</strong></td>
<td>借鉴三棱镜原理，从质量、新颖性、多样性三个维度拆解评估创造力。</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2510.20091">2510.20091</a></td>
</tr>
<tr class="odd">
<td></td>
<td><strong>DEATH OF THE NOVEL(TY): BEYOND -GRAM NOVELTY AS A METRIC</strong></td>
<td>指出传统的 -gram 评估法已过时，强调需结合“实用性”来衡量真正的创新。</td>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2509.22641">2509.22641</a></td>
</tr>
</tbody>
</table>
<hr />
<h2 id="研究背景">研究背景</h2>
<p>  对于单个LLM，在面对开放式问题时的输出具有同质化的现象。作者从Infinity-Chat100数据集中采样50个case，设置temperature=1.0，Top-p=0.9，让每个LLM生成50个回答。随后采用余弦相似度统计回答之间的相似性。如下图，对于单个LLM，余弦相似度&gt;=0.8的case占比很高。 <img src="./2025-12-30-18-34-00.png" srcset="/img/loading.gif" lazyload /></p>
<p>  对于不同的LLM，他们的回答也是高度相似的。如图DeepSeek-V3和gpt-4o的回答的相似度很高。 <img src="./2025-12-30-18-41-12.png" srcset="/img/loading.gif" lazyload /></p>
<p>  作者又做了一些实验，如：在“用一句话描述时间” 这个开放式问题中，用25个模型每个模型50个回答，绘制Embedding的图像。如下图，模型的回答有2个明显的聚类中心，左边的聚类基本把时间比喻成河流，右边的聚类基本把时间比喻成纺织工。 <img src="./2025-12-30-18-43-53.png" srcset="/img/loading.gif" lazyload /></p>
<p>  我们已经知道了LLM在输出的时候有高度同质化的现象。作者的逻辑是：生成内容的同质化，很可能是因为评价标准的僵化导致的。这种同质化背后隐含的是，在开放式问题中，LLM对同样质量的回答可能会有不同的偏好，导致他们只能回答特定的几种范式。现在的模型是通过 RLHF（基于人类反馈的强化学习）训练的，而 RLHF 极度依赖Reward model或LM Judge给出的分数。如果这些 AI 裁判在面对两个“同样好但风格不同”的回答时，无法像人类那样识别出细微的价值，或者在人类有分歧时只会盲目给某一个高分，那么模型在训练过程中就会被诱导去生成那种“保险、平庸、符合 AI 审美”的同质化内容。本文希望能够深入地分析LM Judge对回答的评分是否合理，是否与人类评估保持一致。</p>
<p>  本文的主要贡献在于：</p>
<ul>
<li>构建了INFINITY-CHAT，这是一个包含 26,000 条 真实世界开放式问答的大规模数据集。这些问答源自 WildChat，涵盖了自然发生的、多样化的用户提示词。这些开放式问题，为LLM多样性的研究奠定了基础。</li>
<li>发现了模型内重复，模型间同质化的现象。</li>
<li>在研究LM Judge与人类是否一致之前，本文贡献了一个大规模的人类偏好标注数据：包含人类对开放问题回答的绝对值评分和相对评分(which is better)。</li>
<li>发现了模型与人类偏好的失调，在答案质量相当或者人工标注分歧较大的情况下，LLM Judge往往无法准确反映人类评分。</li>
</ul>
<h2 id="infinity-chat的构建">INFINITY-CHAT的构建</h2>
<ol type="1">
<li><p>原始数据挖掘与初步筛选： 研究者首先从 WildChat（一个真实用户与大模型互动的对话数据集）中获取原始输入。从海量对话中筛选出 37,426 条 高质量的单轮 GPT-4 查询。语言：仅限英语。内容：无毒。长度：字符数限制在 15–200 之间，确保查询既有意义又不至于过于冗长。</p></li>
<li><p>自动化分类与精炼： 由于 WildChat 包含各种类型的互动，研究者利用 GPT-4o 对上述查询进行细化处理：判断查询是寻求实质性信息，还是简单的问候或对模型的询问。区分该查询是只允许单一正确答案，还是允许多个有效答案。对于表述模糊的查询，利用模型进行重写以确保意图清晰。最终提炼出 26,070 条开放式查询 和 8,817 条封闭式查询。</p></li>
<li><p>构建开放式查询分类体系 为了系统化理解这些开放式问题，研究者开发了一套细粒度的分类框架： 人工标注约 100 条查询，赋予初步标签。利用 GPT-4o 对全量 26K 条开放式查询进行自动标注，并由模型检测是否存在种子类别之外的“新类型”（最终发现了 314 个新颖的子类，如文化分析、伦理等）。通过不断的分组和提炼，形成层级结构。最终确定了 6 个高层级类别（如创意内容生成、脑暴与构思等）和 17 个细粒度子类。</p></li>
</ol>
<p>具体的分类如下： <img src="./2025-12-30-19-05-52.png" srcset="/img/loading.gif" lazyload /></p>
<h2 id="人工偏好数据的收集">人工偏好数据的收集</h2>
<p>  为了能够研究LM Judge对开放式问题的评估与人类是否一致，本文首先通过大规模的数据标注，捕捉人类偏好的分布。具体来说，本文收集了绝对评分（采用 1–5 分制衡量回复质量）和成对比对偏好评分（在同一查询的两个回复之间选择“强/弱偏好”）。</p>
<ul>
<li>绝对评分: 针对来自 INFINITY-CHAT100 的 50 个提示词，每个提示词采样 15 个回复，并对每个“查询-回复”对收集 25 份评分，总计获得 <span class="math inline">25 × 15 × 50 = 18, 750</span> 条标签。</li>
<li>成对比对偏好评分: 为每个提示词采样 10 组回复对，并对每个“查询-回复1-回复2”三元组收集 25 份标注，总计获得 <span class="math inline">25 × 10 × 50 = 12, 500</span> 条标签。</li>
</ul>
<p>  对每个case，会有25位标注者打分。这样我们就得到了一个打分的数据分布，然后计算该分布的香农熵。统计不同Entropy下的数据比例。第一张图是绝对评分的Entropy分布，第二张图是相对评分的Entropy分布。可以看到，人工标注的评分Entropy很高，说明了人类偏好的多样性。 <img src="./2025-12-30-16-56-48.png" srcset="/img/loading.gif" lazyload /> <img src="./2025-12-30-16-59-12.png" srcset="/img/loading.gif" lazyload /></p>
<h2 id="在开放式问题中-lm-judge与人类是否相似">在开放式问题中， LM Judge与人类是否相似</h2>
<h3 id="实验设置">实验设置</h3>
<p>作者将三类由模型生成的评分与人工标注进行对比：</p>
<ul>
<li>LM 评分 (LM scores)： 根据给定查询下回复的困惑度（Perplexity）推导得出。</li>
<li>奖励模型评分 (Reward model scores)： 基于标准化的标量奖励输出。</li>
<li>LM 裁判评分 (LM judge ratings)： 遵循标准提示词协议，采用两类评价准则：综合质量评分和 HHH 准则（有用性 Helpfulness、无害性 Harmlessness、诚实性 Honesty）。</li>
</ul>
<h3 id="实验一质量相近的回答llm-judge与人类评估的一致性差">实验一：质量相近的回答，LLM Judge与人类评估的一致性差</h3>
<p>该实验表明：对人类来说质量比较相近的案例，LLM Judge会给出不同的评分。</p>
<h4 id="绝对评分的一致性分析">绝对评分的一致性分析</h4>
<p>  作者对750个case进行Perplexity, Reward model scores, LM judge ratings的打分，并计算和人类打分的相关性。这地方比较绕，举个例子：LM judge会对750个case输出一个score list: [3, 7, 8, 9, …..]，25个人工打分也会对case计算一个average score list: [3, 7, 1, 3, …] 我们可以计算这两个score list的相关性，来分析LM Judges与人类是否相似。</p>
<p>  进一步的，作者对750个model output做了不同层次的过滤：使用Tukey’s fences 过滤法，作者将系数 <span class="math inline"><em>k</em></span> 从 0.5 逐渐调整到 3.0。<span class="math inline"><em>k</em></span> 越小（如 0.5）： 过滤越“激进”，只留下那些分数高度集中、质量极其接近的样本。<span class="math inline"><em>k</em></span> 越大（如 3.0）： 过滤越“保守”，包含的样本差异稍微大一些。举个例子：我们可以计算出750个cases的average score。然后使用该score和k过滤掉cases中分数太高和太低的case，这样就可以过滤掉一些离群样本。这样的话样本的分数就更加集中。</p>
<p>  图中随着样本的绝对评分越来越集中，LM Judge的评分和人类评分相关性越来越低，说明LM Judge不能区分质量比较接近的回答。 <img src="./2025-12-30-17-35-17.png" srcset="/img/loading.gif" lazyload /></p>
<h4 id="相对评分的一致性分析">相对评分的一致性分析</h4>
<p>  相对评分的数据一共是50个问题 * 10个Pair(每个pair是 model1 output和 model2 output) = 500条，每一条都有25个标注者标注1和2了两个回答哪个好。在数据分析中，作者根据25名标注员中，有多少人选择了“这两个回复质量”相似，构建子集。作者选取人工标注相似度最高的前 60%–95% 的示例构成子集，并进行实验。</p>
<p>  如下图，随着人工标注越来越相似，LM Judges的方法打出的分数和人类打出的分数相关性越来越低。换句话说：人类觉得差不多的回答，LM Judges打出的分数有高有低。 <img src="./2025-12-30-17-36-45.png" srcset="/img/loading.gif" lazyload /></p>
<h3 id="实验二-llm-judge-在标注员存在分歧时对齐度较低">实验二： LLM Judge 在标注员存在分歧时对齐度较低</h3>
<p>该实验表明：对人类来说分歧比较大的案例，LLM Judge和人类评估的相关性降低。 #### 绝对评分的情况</p>
<p>  通过计算 25 份人类标签的香农熵，对绝对评分数据进行排序。随后，选取熵值最高的前 2%、4%、6%、8%、10%、12%、14% 和 16% 的示例作为分歧子集。计算模型评分与人类评分之间的 Pearson 相关系数。结果发现，人工标注的分歧越大，LLM Judge和人工标注分数的相关性越低。 <img src="./2025-12-30-18-01-02.png" srcset="/img/loading.gif" lazyload /></p>
<h4 id="成对偏好评分的情况">成对偏好评分的情况：</h4>
<p>  作者利用“分歧百分比”（<span class="math inline"><em>P</em><sub><em>d</em><em>i</em><em>s</em><em>a</em><em>g</em><em>r</em><em>e</em><em>e</em></sub></span>）来量化每个“查询-回复1-回复2”三元组的分歧程度：<span class="math display">$$P_{disagree} = 1 - \frac{\max(C_{prefer 1}, C_{prefer 2}) + 0.5 \cdot C_{tie}}{C_{total}}$$</span>其中 <span class="math inline"><em>C</em></span> 代表每种偏好类型的标注数量。如果选回复 1 的人数和选回复 2 的人数旗鼓相当，这个数值就会变大。</p>
<p>  作者保留了分歧程度最高的前 60% 到 95% 的示例，并在他们上面计算作者保留了分歧程度最高的前 60% 到 95% 的示例，并在他们上面计算LLM Judge和人工标注分数的Pearson 相关系数。结果发现，人工标注的分歧越大，LLM Judge和人工标注分数的相关性越低。 <img src="./2025-12-30-18-06-59.png" srcset="/img/loading.gif" lazyload /></p>
<h2 id="总结">总结</h2>
<p>  这篇论文警告我们，AI 正在形成一种“集体思想”，这种开放式的同质化可能会像回声壁一样，在未来削弱人类社会的创造力和思想深度。未来的训练不应只追求迎合“平均人类偏好”，而应学会模拟和尊重人类偏好的分布，允许模型生成更具差异化的内容。</p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>对LLM输出多样性的更全面的调研</div>
      <div>https://ycfywy.github.io/2025/12/29/对LLM输出多样性的更全面的调研/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>ycf</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2025年12月29日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-cc-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2026/01/02/%E8%A7%86%E9%A2%91-%E5%9B%BE%E7%89%87%E7%94%9F%E6%88%90AI%E7%9A%84%E4%B8%80%E4%BA%9B%E6%8A%BD%E8%B1%A1%E4%BA%8B%E6%83%85/" title="视频/图片生成AI的一些抽象事情">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">视频/图片生成AI的一些抽象事情</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2025/12/28/An-Empirical-Study-of-Reasoning-Steps-in-Thinking-Code-LLMs/" title="An Empirical Study of Reasoning Steps in Thinking Code LLMs">
                        <span class="hidden-mobile">An Empirical Study of Reasoning Steps in Thinking Code LLMs</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  









    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/5.0.0/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        if (!window.MathJax) {
          window.MathJax = {
            tex    : {
              inlineMath: { '[+]': [['$', '$']] }
            },
            loader : {
              load: ['ui/lazy']
            },
            options: {
              renderActions: {
                insertedScript: [200, () => {
                  document.querySelectorAll('mjx-container').forEach(node => {
                    let target = node.parentNode;
                    if (target.nodeName.toLowerCase() === 'li') {
                      target.parentNode.classList.add('has-jax');
                    }
                  });
                }, '', false]
              }
            }
          };
        } else {
          MathJax.startup.document.state(0);
          MathJax.texReset();
          MathJax.typeset();
          MathJax.typesetPromise();
        }

        Fluid.events.registerRefreshCallback(function() {
          if ('MathJax' in window && MathJax.startup.document && typeof MathJax.startup.document.state === 'function') {
            MathJax.startup.document.state(0);
            MathJax.texReset();
            MathJax.typeset();
            MathJax.typesetPromise();
          }
        });
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js" ></script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
